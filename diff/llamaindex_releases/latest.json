{
  "schema_version": "1.2.0",
  "generated_at": "2026-02-09T04:44:01Z",
  "source_id": "llamaindex_releases",
  "hash": "sha256:171f58a5ed93aed71cfd457f3b41b3ee6d754072daea7407a250b9bc16cf8449",
  "prev_hash": "sha256:0000000000000000000000000000000000000000000000000000000000000000",
  "cursor": "sha256:fe5f69c4c442569b4233e6ab44892e873ca55f284b414483fe21fa7d07c13993",
  "prev_cursor": "sha256:0000000000000000000000000000000000000000000000000000000000000000",
  "changed": true,
  "ttl_sec": 3600,
  "sources_included": [
    "llamaindex_releases"
  ],
  "batch_narrative": "llamaindex_releases: 20 releases (20 stable, 2 security patches).",
  "buckets": {
    "new": [
      {
        "source": "llamaindex_releases",
        "id": "273313070",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.12",
        "published_at": "2025-12-30T01:07:03Z",
        "updated_at": "2025-12-30T01:07:03Z",
        "headline": "v0.14.12",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-12-30] ### llama-index-callbacks-agentops [0.4.1] - Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338)) ### llama-index-core [0.14.12] - Feat/async tool spec support ([#20338](https://github.com/run-llama/llama_index/pull/20338)) - Improve `MockFunctionCallingLLM` ([#20356](https://github.com/run-llama/llama_index/pull/20356)) - fix(openai): sanitize generic Pydantic model schema names...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.12"
          ],
          "content_hash": "sha256:0fc52f8157ef2e75dc25b6e651ae0328aca95364d1f18c11c9ef9901a6452c47"
        },
        "signals": {
          "release": {
            "version": "v0.14.12",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "267562449",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.10",
        "published_at": "2025-12-04T19:46:03Z",
        "updated_at": "2025-12-04T19:46:03Z",
        "headline": "v0.14.10",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-12-04] ### llama-index-core [0.14.10] - feat: add mock function calling llm ([#20331](https://github.com/run-llama/llama_index/pull/20331)) ### llama-index-llms-qianfan [0.4.1] - test: fix typo 'reponse' to 'response' in variable names ([#20329](https://github.com/run-llama/llama_index/pull/20329)) ### llama-index-tools-airweave [0.1.0] - feat: add Airweave tool integration with advanced search features ([#20111](https://github.com/run-llama/llama_index/pull/20111))...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.10"
          ],
          "content_hash": "sha256:7c47f725a6a0e5faae036fb1ff06ce2a3464d4356f1ea3cf9f22fc6cd87492c7"
        },
        "signals": {
          "release": {
            "version": "v0.14.10",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "261260437",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.8",
        "published_at": "2025-11-10T22:18:42Z",
        "updated_at": "2025-11-10T22:18:42Z",
        "headline": "v0.14.8",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-11-10] ### llama-index-core [0.14.8] - Fix ReActOutputParser getting stuck when \"Answer:\" contains \"Action:\" ([#20098](https://github.com/run-llama/llama_index/pull/20098)) - Add buffer to image, audio, video and document blocks ([#20153](https://github.com/run-llama/llama_index/pull/20153)) - fix(agent): Handle multi-block ChatMessage in ReActAgent ([#20196](https://github.com/run-llama/llama_index/pull/20196)) - Fix/20209...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.8"
          ],
          "content_hash": "sha256:f6114321d5f4eea41a534c427c62dece614249cad0f71ec60d191ac3482876ec"
        },
        "signals": {
          "release": {
            "version": "v0.14.8",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "258653518",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.7",
        "published_at": "2025-10-30T23:58:43Z",
        "updated_at": "2025-10-30T23:58:43Z",
        "headline": "v0.14.7",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-10-30] ### llama-index-core [0.14.7] - Feat/serpex tool integration ([#20141](https://github.com/run-llama/llama_index/pull/20141)) - Fix outdated error message about setting LLM ([#20157](https://github.com/run-llama/llama_index/pull/20157)) - Fixing some recently failing tests ([#20165](https://github.com/run-llama/llama_index/pull/20165)) - Fix: update lock to latest workflow and fix issues ([#20173](https://github.com/run-llama/llama_index/pull/20173)) - fix:...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.7"
          ],
          "content_hash": "sha256:cab9178757d1b40b3c499fd74df279c10f8d91e2b01fcf725365f972729c361f"
        },
        "signals": {
          "release": {
            "version": "v0.14.7",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "257271663",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.6",
        "published_at": "2025-10-26T03:01:31Z",
        "updated_at": "2025-10-26T03:01:31Z",
        "headline": "v0.14.6",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-10-26] ### llama-index-core [0.14.6] - Add allow_parallel_tool_calls for non-streaming ([#20117](https://github.com/run-llama/llama_index/pull/20117)) - Fix invalid use of field-specific metadata ([#20122](https://github.com/run-llama/llama_index/pull/20122)) - update doc for SemanticSplitterNodeParser ([#20125](https://github.com/run-llama/llama_index/pull/20125)) - fix rare cases when sentence splits are larger than chunk size...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.6"
          ],
          "content_hash": "sha256:8a3350ce839fffbc3d1419b2fb155a799421461dd208b97b9007de51c20500f0"
        },
        "signals": {
          "release": {
            "version": "v0.14.6",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "254801769",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.5",
        "published_at": "2025-10-15T19:10:56Z",
        "updated_at": "2025-10-15T19:10:57Z",
        "headline": "v0.14.5",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-10-15] ### llama-index-core [0.14.5] - Remove debug print ([#20000](https://github.com/run-llama/llama_index/pull/20000)) - safely initialize RefDocInfo in Docstore ([#20031](https://github.com/run-llama/llama_index/pull/20031)) - Add progress bar for multiprocess loading ([#20048](https://github.com/run-llama/llama_index/pull/20048)) - Fix duplicate node positions when identical text appears multiple times in document...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.5"
          ],
          "content_hash": "sha256:346d3ca0d22efb559ccff7c08d431e341b62fc3b62cd3ac75e3bda0a8c5941b0"
        },
        "signals": {
          "release": {
            "version": "v0.14.5",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "252069271",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.4",
        "published_at": "2025-10-03T17:52:07Z",
        "updated_at": "2025-10-03T17:52:41Z",
        "headline": "v0.14.4",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-09-24] ### llama-index-core [0.14.4] - fix pre-release installs ([#20010](https://github.com/run-llama/llama_index/pull/20010)) ### llama-index-embeddings-anyscale [0.4.2] - fix llm deps for openai ([#19944](https://github.com/run-llama/llama_index/pull/19944)) ### llama-index-embeddings-baseten [0.1.2] - fix llm deps for openai ([#19944](https://github.com/run-llama/llama_index/pull/19944)) ### llama-index-embeddings-fireworks [0.4.2] - fix llm deps for openai...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.4"
          ],
          "content_hash": "sha256:218f765aa87ddbf70e322e45680ae1f9b7a0ab588b1cfa1a598d50e472cdd828"
        },
        "signals": {
          "release": {
            "version": "v0.14.4",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "247501267",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.2",
        "published_at": "2025-09-16T05:11:05Z",
        "updated_at": "2025-09-16T05:11:06Z",
        "headline": "v0.14.2",
        "content": {
          "excerpt_text": "# Release Notes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.2"
          ],
          "content_hash": "sha256:1583341731c25e4591756c26816a4962c40d5f2d9ff3a700180031ead04d1081"
        },
        "signals": {
          "release": {
            "version": "v0.14.2",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "247172941",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.1.post1",
        "published_at": "2025-09-15T04:57:31Z",
        "updated_at": "2025-09-15T04:57:32Z",
        "headline": "v0.14.1.post1",
        "content": {
          "excerpt_text": "# Release Notes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.1.post1"
          ],
          "content_hash": "sha256:399a9caeea882a56cdce7bc1316632c6f1e5c4a35a5902eddc7954dc10cfa661"
        },
        "signals": {
          "release": {
            "version": "v0.14.1.post1",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "247163676",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.1",
        "published_at": "2025-09-15T03:53:15Z",
        "updated_at": "2025-09-15T03:53:15Z",
        "headline": "v0.14.1",
        "content": {
          "excerpt_text": "# Release Notes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.1"
          ],
          "content_hash": "sha256:877f41126d10c2f3ece871a115d675e3cd70374417174b9c75b5bb3125635f39"
        },
        "signals": {
          "release": {
            "version": "v0.14.1",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "245657880",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.0",
        "published_at": "2025-09-08T20:53:30Z",
        "updated_at": "2025-09-08T20:53:31Z",
        "headline": "v0.14.0",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-09-08] **NOTE:** All packages have been bumped to handle the latest llama-index-core version. ### `llama-index-core` [0.14.0] - breaking: bumped `llama-index-workflows` dependency to 2.0 - Improve stacktraces clarity by avoiding wrapping errors in WorkflowRuntimeError - Remove deprecated checkpointer feature - Remove deprecated sub-workflows feature - Remove deprecated `send_event` method from Workflow class (still existing on the Context class) - Remove deprecated...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.0"
          ],
          "content_hash": "sha256:7c015bf618080593f3f750b1a75f5a75318f78072449a35ab89c043865bbffdf"
        },
        "signals": {
          "release": {
            "version": "v0.14.0",
            "prerelease": false
          },
          "deprecation": {
            "type": "deprecated",
            "confidence": "high",
            "source": "keyword_scan"
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "245326200",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.6",
        "published_at": "2025-09-07T04:57:15Z",
        "updated_at": "2025-09-07T04:57:16Z",
        "headline": "v0.13.6",
        "content": {
          "excerpt_text": "# Release Notes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.6"
          ],
          "content_hash": "sha256:7a6852ecc8086b77079f734e256c4a1c977d3efbe385f942e3bbd25ff9b29258"
        },
        "signals": {
          "release": {
            "version": "v0.13.6",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "244939593",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.5",
        "published_at": "2025-09-04T23:14:59Z",
        "updated_at": "2025-09-04T23:15:00Z",
        "headline": "v0.13.5",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-09-04] ### `llama-index-core` [0.13.5] - feat: add thinking delta field to AgentStream events to expose from LLM responses (#19785) - fix: fix path handling in SimpleDirectoryReader and PDFReader path fix (#19794) ### `llama-index-llms-bedrock-converse` [0.9.0] - feat: add system prompt and tool caching config kwargs to BedrockConverse (#19737) ### `llama-index-llms-litellm` [0.6.2] - fix: Handle missing tool call IDs with UUID fallback (#19789) - fix: Fix critical...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.5"
          ],
          "content_hash": "sha256:c76b052ca173a27810e9d8eadc8ce7d0ff99fc1d2cb230f48c5f7744168370de"
        },
        "signals": {
          "release": {
            "version": "v0.13.5",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "244001918",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.4",
        "published_at": "2025-09-02T05:09:02Z",
        "updated_at": "2025-09-02T05:13:27Z",
        "headline": "v0.13.4",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-09-01] ### `llama-index-core` [0.13.4] - feat: Add PostgreSQL schema support to Memory and SQLAlchemyChatStore (#19741) - feat: add missing sync wrapper of put_messages in memory (#19746) - feat: add option for an initial tool choice in FunctionAgent (#19738) - fix: Calling ContextChatEngine with a QueryBundle (instead of a string) (#19714) ### `llama-index-embeddings-baseten` [0.1.0] - feat: baseten integration (#19710) ### `llama-index-embeddings-ibm` [0.5.0] -...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.4"
          ],
          "content_hash": "sha256:e51dbb90a14b446b47589be517eb6068837a6f54430d9842d84188a11086028c"
        },
        "signals": {
          "release": {
            "version": "v0.13.4",
            "prerelease": false
          },
          "deprecation": {
            "type": "deprecated",
            "confidence": "high",
            "source": "keyword_scan"
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "243478217",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.3.post1",
        "published_at": "2025-08-29T13:26:33Z",
        "updated_at": "2025-08-29T13:26:34Z",
        "headline": "v0.13.3.post1",
        "content": {
          "excerpt_text": "# Release Notes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.3.post1"
          ],
          "content_hash": "sha256:fd8dfc7986c33b620b60469c86e00b45c17354d18d59287cb34533fe792f40a8"
        },
        "signals": {
          "release": {
            "version": "v0.13.3.post1",
            "prerelease": false
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "241939837",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.3",
        "published_at": "2025-08-22T20:07:14Z",
        "updated_at": "2025-08-22T20:07:15Z",
        "headline": "v0.13.3",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-08-22] ### `llama-index-core` [0.13.3] - fix: add timeouts on image `.get()` requests (#19723) - fix: fix StreamingAgentChatResponse losses message bug (#19674) - fix: Fixing crashing when retrieving from empty vector store index (#19706) - fix: Calling ContextChatEngine with a QueryBundle (instead of a string) (#19714) - fix: Fix faithfulness evaluate crash when no images provided (#19686) ### `llama-index-embeddings-heroku` [0.1.0] - feat: Adds support for...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.3"
          ],
          "content_hash": "sha256:7c13357d2e7d61431c1d92a0b118ca6ff9db996fa531a6ed1485e7ffd6ab342d"
        },
        "signals": {
          "release": {
            "version": "v0.13.3",
            "prerelease": false
          },
          "deprecation": {
            "type": "deprecated",
            "confidence": "low",
            "source": "keyword_scan"
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "240109269",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.13.2.post1",
        "published_at": "2025-08-14T22:40:36Z",
        "updated_at": "2025-08-14T22:41:33Z",
        "headline": "v0.13.2.post1",
        "content": {
          "excerpt_text": "# Release Notes - docs fixes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.13.2.post1"
          ],
          "content_hash": "sha256:1045763a1f914e1220f8eac5e9e65a39458f010046c84e01544a243c447e7ded"
        },
        "signals": {
          "release": {
            "version": "v0.13.2.post1",
            "prerelease": false
          }
        }
      }
    ],
    "updated": [],
    "removed": [],
    "flagged": [
      {
        "source": "llamaindex_releases",
        "id": "278780918",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.13",
        "published_at": "2026-01-21T20:44:52Z",
        "updated_at": "2026-01-21T20:44:52Z",
        "headline": "v0.14.13",
        "content": {
          "excerpt_text": "# Release Notes ## [2026-01-21] ### llama-index-core [0.14.13] - feat: add early_stopping_method parameter to agent workflows ([#20389](https://github.com/run-llama/llama_index/pull/20389)) - feat: Add token-based code splitting support to CodeSplitter ([#20438](https://github.com/run-llama/llama_index/pull/20438)) - Add RayIngestionPipeline integration for distributed data ingestion ([#20443](https://github.com/run-llama/llama_index/pull/20443)) - Added the multi-modal version of the...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.13"
          ],
          "content_hash": "sha256:dfee40679e4f7b3e620050dd6c6a70143eec42573e4a5d7395364267086b037d"
        },
        "signals": {
          "release": {
            "version": "v0.14.13",
            "prerelease": false,
            "security_patch": true
          },
          "deprecation": {
            "type": "deprecated",
            "affects": [
              "extraneous",
              "llama-index-llms-gemini",
              "exposed"
            ],
            "confidence": "low",
            "source": "keyword_scan"
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "266892119",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.9",
        "published_at": "2025-12-02T21:31:18Z",
        "updated_at": "2025-12-02T21:31:18Z",
        "headline": "v0.14.9",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-12-02] ### llama-index-agent-azure [0.2.1] - fix: Pin azure-ai-projects version to prevent breaking changes ([#20255](https://github.com/run-llama/llama_index/pull/20255)) ### llama-index-core [0.14.9] - MultiModalVectorStoreIndex now returns a multi-modal ContextChatEngine. ([#20265](https://github.com/run-llama/llama_index/pull/20265)) - Ingestion to vector store now ensures that \\_node-content is readable...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.9"
          ],
          "content_hash": "sha256:392ee4f9f992725e0c0c97a31f2a818d5c5ede705ad5ae6d63398021a8961474"
        },
        "signals": {
          "release": {
            "version": "v0.14.9",
            "prerelease": false
          },
          "deprecation": {
            "type": "breaking_change",
            "affects": [
              "requirements.txt"
            ],
            "confidence": "low",
            "source": "keyword_scan"
          }
        }
      },
      {
        "source": "llamaindex_releases",
        "id": "249814736",
        "url": "https://github.com/run-llama/llama_index/releases/tag/v0.14.3",
        "published_at": "2025-09-24T21:02:46Z",
        "updated_at": "2025-09-24T21:02:47Z",
        "headline": "v0.14.3",
        "content": {
          "excerpt_text": "# Release Notes ## [2025-09-24] ### llama-index-core [0.14.3] - Fix Gemini thought signature serialization ([#19891](https://github.com/run-llama/llama_index/pull/19891)) - Adding a ThinkingBlock among content blocks ([#19919](https://github.com/run-llama/llama_index/pull/19919)) ### llama-index-llms-anthropic [0.9.0] - Adding a ThinkingBlock among content blocks ([#19919](https://github.com/run-llama/llama_index/pull/19919)) ### llama-index-llms-baseten [0.1.4] - added kimik2 0905 and...",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-09T04:44:01Z",
          "evidence_urls": [
            "https://github.com/run-llama/llama_index/releases/tag/v0.14.3"
          ],
          "content_hash": "sha256:f75a30dc95be9888e7adb1eec27bf964d0062827c9f1e912769a43c291a12dcf"
        },
        "signals": {
          "release": {
            "version": "v0.14.3",
            "prerelease": false,
            "security_patch": true
          }
        }
      }
    ]
  },
  "counts": {
    "new": 17,
    "updated": 0,
    "removed": 0,
    "flagged": 3
  },
  "integrity_reset": true,
  "archive_url": "/archive/llamaindex_releases/2026/02/09/20260209T044401Z_171f58a5ed93aed7.json"
}