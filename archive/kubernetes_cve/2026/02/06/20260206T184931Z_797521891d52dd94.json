{
  "schema_version": "1.2.0",
  "generated_at": "2026-02-06T18:49:31Z",
  "source_id": "kubernetes_cve",
  "hash": "sha256:797521891d52dd94bd50deade51eb905cb05d2ffb5692045f8b353c9773e04a6",
  "prev_hash": "sha256:323db889c91d240c0349dfb5024f07de7911d0b9f6fb05f5bb32db30d2c33187",
  "cursor": "sha256:126b1f638c68f4ad0bcf7f4762f20af170dadd52e05d9855c59b21ed06d6a5cf",
  "prev_cursor": "sha256:0da04efedd16d2590624123de01c3e953f61417f502e11692b5ca0dcd05a5660",
  "changed": true,
  "ttl_sec": 3600,
  "sources_included": [
    "kubernetes_cve"
  ],
  "batch_narrative": "kubernetes_cve: 87 changes (87 new).",
  "buckets": {
    "new": [
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-15566",
        "url": "https://github.com/kubernetes/kubernetes/issues/136789",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx auth-proxy-set-headers nginx configuration injection",
        "content": {
          "excerpt_text": "ingress-nginx auth-proxy-set-headers nginx configuration injection",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/136789"
          ],
          "content_hash": "sha256:0cb875f67aa455e251a61c71f6502dbf443dd4d3bb0f534f0e79d9e25dbe8f9f"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx auth-proxy-set-headers nginx configuration injection",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-15566",
            "issue_number": 136789
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)\n\nA security issue was discovered in ingress-nginx where the nginx.ingress.kubernetes.io/auth-proxy-set-headers Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get pods --all-namespaces --selector app.kubernetes.io/name=ingress-nginx`.\n\n#### Affected Versions\n\n- ingress-nginx: v1.12.5\n- ingress-nginx: v1.13.1\n\n### How do I mitigate this vulnerability?\n\nACTION REQUIRED: The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.12.5, v1.13.1, or any later version.\n\n#### How to upgrade?\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within a configmap passed to the `nginx.ingress.kubernetes.io/auth-proxy-set-headers` annotation of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\nIf you find evidence that this vulnerability has been exploited, please contact **security@kubernetes.io**\n\n#### Acknowledgements\n\nThis issue was discovered **and patched** by Jan-Otto Kröpke.\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig network\n\n<details>\n<summary>OSV format</summary>\n\n```json osv\n{\n  \"schema_version\": \"1.6.0\",\n  \"id\": \"CVE-2025-15566\",\n  \"modified\": \"2026-02-06T02:46:50Z\",\n  \"summary\": \"ingress-nginx auth-proxy-set-headers nginx configuration injection\",\n  \"details\": \"A security issue was discovered in ingress-nginx where the nginx.ingress.kubernetes.io/auth-proxy-set-headers Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\",\n  \"severity\": [\n    {\n      \"type\": \"CVSS_V3\",\n      \"score\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ],\n  \"affected\": [\n    {\n      \"package\": {\n        \"ecosystem\": \"Kubernetes\",\n        \"name\": \"ingress-nginx\"\n      },\n      \"ranges\": [\n        {\n          \"type\": \"SEMVER\",\n          \"events\": [\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.12.5\"\n            },\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.13.1\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"references\": [\n    {\n      \"type\": \"WEB\",\n      \"url\": \"https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ],\n  \"credits\": [\n    {\n      \"name\": \"This issue was discoverd **and patched** by Jan-Otto Kröpke.\",\n      \"type\": \"FINDER\"\n    }\n  ]\n}\n```\n\n</details>\n\n<!-- generated by srctl v1.0.0 (2665728667a5-dirty, 2026-01-31T19:18:07Z, go1.25.6) -->\n",
          "date_published": "2026-02-06T02:54:24Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-15566",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2026-24514",
        "url": "https://github.com/kubernetes/kubernetes/issues/136680",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx Admission Controller denial of service",
        "content": {
          "excerpt_text": "ingress-nginx Admission Controller denial of service",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/136680"
          ],
          "content_hash": "sha256:26365bb66747c53ef335256c2c0ab080416231c1f3b5c7b68c556d966ea753c1"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx Admission Controller denial of service",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2026-24514",
            "issue_number": 136680
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the validating admission controller feature is subject to a denial of service condition. By sending large requests to the validating admission controller, an attacker can cause memory consumption, which may result in the ingress-nginx controller pod being killed or the node running out of memory.\n\n### Am I vulnerable?\n\n* This issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector [app.kubernetes.io/name=ingress-nginx](http://app.kubernetes.io/name=ingress-nginx)\\`.\n\n#### Affected Versions\n\n- ingress-nginx: < 1.13.7\n- ingress-nginx: < 1.14.3\n\n### How do I mitigate this vulnerability?\n\nACTION REQUIRED: The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.13.7, v1.14.3, or any later version.\n\n#### How to upgrade?\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nRequests larger than a few megabytes being sent to the ingress-nginx admission controller may indicate an attempt to exploit this vulnerability.\n\n### Acknowledgements\n\nThis issue was discovered by Matan Shabtay.\nThe issue was fixed and coordinated by Steven Jin, Marco Ebert, and Tabitha Sable\n\nIf you find evidence that this vulnerability has been exploited, please contact **security@kubernetes.io**\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig network\n\n<details>\n<summary>OSV format</summary>\n\n```json osv\n{\n  \"schema_version\": \"1.6.0\",\n  \"id\": \"CVE-2026-24514\",\n  \"modified\": \"2026-02-02T16:00:10Z\",\n  \"summary\": \"ingress-nginx Admission Controller denial of service\",\n  \"details\": \"A security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the validating admission controller feature is subject to a denial of service condition. By sending large requests to the validating admission controller, an attacker can cause memory consumption, which may result in the ingress-nginx controller pod being killed or the node running out of memory.\",\n  \"severity\": [\n    {\n      \"type\": \"CVSS_V3\",\n      \"score\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H\"\n    }\n  ],\n  \"affected\": [\n    {\n      \"package\": {\n        \"ecosystem\": \"Kubernetes\",\n        \"name\": \"ingress-nginx\"\n      },\n      \"ranges\": [\n        {\n          \"type\": \"SEMVER\",\n          \"events\": [\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"1.13.7\"\n            },\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"1.14.3\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"references\": [\n    {\n      \"type\": \"WEB\",\n      \"url\": \"https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H\"\n    }\n  ]\n}\n```\n\n</details>\n\n<!-- generated by srctl v1.0.0 (2665728667a5-dirty, 2026-01-31T19:18:07Z, go1.25.6) -->\n",
          "date_published": "2026-02-02T03:06:14Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2026-24514",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2026-24513",
        "url": "https://github.com/kubernetes/kubernetes/issues/136679",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx auth-url protection bypass",
        "content": {
          "excerpt_text": "ingress-nginx auth-url protection bypass",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/136679"
          ],
          "content_hash": "sha256:e5eda97a9e77e70b3600f0c686bc34c9f639ad1ca0713a910963c5fb0da201f8"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx auth-url protection bypass",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2026-24513",
            "issue_number": 136679
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the protection afforded by the `auth-url` Ingress annotation may not be effective in the presence of a specific misconfiguration.\n\nIf the ingress-nginx controller is configured with a default custom-errors configuration that includes HTTP errors 401 or 403, and if the configured default custom-errors backend is defective and fails to respect the X-Code HTTP header, then an Ingress with the `auth-url` annotation may be accessed even when authentication fails.\n\nNote that the built-in custom-errors backend works correctly. To trigger this issue requires an administrator to specifically configure ingress-nginx with a broken external component.\n\n### Am I vulnerable?\n\n* This issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector [app.kubernetes.io/name=ingress-nginx](http://app.kubernetes.io/name=ingress-nginx)\\`.\n* This issue only affects Ingresses using the `auth-url` annotation. If you are not adding authentication to your Ingresses using the `auth-url` annotation, then you are not at risk.\n* This issue only affects ingress-nginx controllers that have been configured with default custom-errors settings via editing the controller command-line arguments and configuration map. If you are using per-Ingress custom-errors set via Ingress annotations, then you are not at risk.\n\n#### Affected Versions\n\n- ingress-nginx: < 1.13.7\n- ingress-nginx: < 1.14.3\n\n### How do I mitigate this vulnerability?\n\nACTION REQUIRED: The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.13.7, v1.14.3, or any later version.\n\nPrior to upgrading, this vulnerability can be mitigated by checking to confirm your custom errors backend correctly respects the `X-Code` HTTP header.\n\n#### How to upgrade?\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nIf you are able to load a URL protected by the `auth-url` annotation despite failing authentication, then you are affected by this vulnerability.\n\n### Acknowledgements\nThis issue was discovered by Aurelia Schittler.\nThe issue was fixed and coordinated by Tabitha Sable and Marco Ebert.\n\nIf you find evidence that this vulnerability has been exploited, please contact **security@kubernetes.io**\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig network\n\n<details>\n<summary>OSV format</summary>\n\n```json osv\n{\n  \"schema_version\": \"1.6.0\",\n  \"id\": \"CVE-2026-24513\",\n  \"modified\": \"2026-02-02T16:00:06Z\",\n  \"summary\": \"ingress-nginx auth-url protection bypass\",\n  \"details\": \"A security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the protection afforded by the `auth-url` Ingress annotation may not be effective in the presence of a specific misconfiguration.\\n\\nIf the ingress-nginx controller is configured with a default custom-errors configuration that includes HTTP errors 401 or 403, and if the configured default custom-errors backend is defective and fails to respect the X-Code HTTP header, then an Ingress with the `auth-url` annotation may be accessed even when authentication fails.\\n\\nNote that the built-in custom-errors backend works correctly. To trigger this issue requires an administrator to specifically configure ingress-nginx with a broken external component.\",\n  \"severity\": [\n    {\n      \"type\": \"CVSS_V3\",\n      \"score\": \"CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N\"\n    }\n  ],\n  \"affected\": [\n    {\n      \"package\": {\n        \"ecosystem\": \"Kubernetes\",\n        \"name\": \"ingress-nginx\"\n      },\n      \"ranges\": [\n        {\n          \"type\": \"SEMVER\",\n          \"events\": [\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"1.13.7\"\n            },\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"1.14.3\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"references\": [\n    {\n      \"type\": \"WEB\",\n      \"url\": \"https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N\"\n    }\n  ]\n}\n```\n\n</details>\n\n<!-- generated by srctl v1.0.0 (2665728667a5-dirty, 2026-01-31T19:18:07Z, go1.25.6) -->\n",
          "date_published": "2026-02-02T03:06:04Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2026-24513",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2026-24512",
        "url": "https://github.com/kubernetes/kubernetes/issues/136678",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx rules.http.paths.path nginx configuration injection",
        "content": {
          "excerpt_text": "ingress-nginx rules.http.paths.path nginx configuration injection",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/136678"
          ],
          "content_hash": "sha256:a72726c2fd15bea25c590e4d4adfc5935094893d22e1e52275bb74fc91741b9d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx rules.http.paths.path nginx configuration injection",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2026-24512",
            "issue_number": 136678
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the `rules.http.paths.path` Ingress field can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- ingress-nginx: < v1.13.7\n- ingress-nginx: < v1.14.3\n\n### How do I mitigate this vulnerability?\n\nACTION REQUIRED: The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.13.7, v1.14.3, or any later version.\n\nPrior to upgrading, this vulnerability can be mitigated by using a validating admission controller to reject Ingress resources with the `ImplementationSpecific` path type.\n\n#### How to upgrade?\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within the rules.http.paths.path field of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\n### Acknowledgements\nThis issue was discovered by Maxime Escourbiac and Yassine Bengana (Michelin CERT).\nThe issue was fixed and coordinated by Steven Jin, Tabitha Sable, and Marco Ebert.\n\nIf you find evidence that this vulnerability has been exploited, please contact **security@kubernetes.io**\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig network\n\n<details>\n<summary>OSV format</summary>\n\n```json osv\n{\n  \"schema_version\": \"1.6.0\",\n  \"id\": \"CVE-2026-24512\",\n  \"modified\": \"2026-02-02T16:00:01Z\",\n  \"summary\": \"ingress-nginx rules.http.paths.path nginx configuration injection\",\n  \"details\": \"A security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the `rules.http.paths.path` Ingress field can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\",\n  \"severity\": [\n    {\n      \"type\": \"CVSS_V3\",\n      \"score\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ],\n  \"affected\": [\n    {\n      \"package\": {\n        \"ecosystem\": \"Kubernetes\",\n        \"name\": \"ingress-nginx\"\n      },\n      \"ranges\": [\n        {\n          \"type\": \"SEMVER\",\n          \"events\": [\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.13.7\"\n            },\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.14.3\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"references\": [\n    {\n      \"type\": \"WEB\",\n      \"url\": \"https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ]\n}\n```\n\n</details>\n\n<!-- generated by srctl v1.0.0 (2665728667a5-dirty, 2026-01-31T19:18:07Z, go1.25.6) -->\n",
          "date_published": "2026-02-02T03:05:54Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2026-24512",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2026-1580",
        "url": "https://github.com/kubernetes/kubernetes/issues/136677",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx auth-method nginx configuration injection",
        "content": {
          "excerpt_text": "ingress-nginx auth-method nginx configuration injection",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/136677"
          ],
          "content_hash": "sha256:0b688abaf559063ef31f3fad69bab075b54b2433125566e554e523577e045437"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx auth-method nginx configuration injection",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2026-1580",
            "issue_number": 136677
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the `nginx.ingress.kubernetes.io/auth-method` Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- ingress-nginx: < v1.13.7\n- ingress-nginx: < v1.14.3\n\n### How do I mitigate this vulnerability?\n\nACTION REQUIRED: The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.13.7, v1.14.3, or any later version.\n\nPrior to upgrading, this vulnerability can be mitigated by using a validating admission controller to reject Ingress resources with the `nginx.ingress.kubernetes.io/auth-method` annotation.\n\n#### How to upgrade?\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within the `nginx.ingress.kubernetes.io/auth-method` annotation of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\n### Acknowledgements\nThis issue was discovered by Volcengine Security Team.\nThe issue was fixed and coordinated by Steven Jin, Marco Ebert, and Tabitha Sable.\n\nIf you find evidence that this vulnerability has been exploited, please contact **security@kubernetes.io**\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig network\n<details>\n<summary>OSV format</summary>\n\n```json osv\n{\n  \"schema_version\": \"1.6.0\",\n  \"id\": \"CVE-2026-1580\",\n  \"modified\": \"2026-02-02T15:59:49Z\",\n  \"summary\": \"ingress-nginx auth-method nginx configuration injection\",\n  \"details\": \"A security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the `nginx.ingress.kubernetes.io/auth-method` Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\",\n  \"severity\": [\n    {\n      \"type\": \"CVSS_V3\",\n      \"score\": \"CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ],\n  \"affected\": [\n    {\n      \"package\": {\n        \"ecosystem\": \"Kubernetes\",\n        \"name\": \"ingress-nginx\"\n      },\n      \"ranges\": [\n        {\n          \"type\": \"SEMVER\",\n          \"events\": [\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.13.7\"\n            },\n            {\n              \"introduced\": \"0\"\n            },\n            {\n              \"fixed\": \"v1.14.3\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"references\": [\n    {\n      \"type\": \"WEB\",\n      \"url\": \"https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\"\n    }\n  ]\n}\n```\n\n</details>\n\n<!-- generated by srctl v1.0.0 (2665728667a5-dirty, 2026-01-31T19:18:07Z, go1.25.6) -->\n",
          "date_published": "2026-02-02T03:05:43Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2026-1580",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-14269",
        "url": "https://github.com/kubernetes/kubernetes/issues/135798",
        "published_at": null,
        "updated_at": null,
        "headline": "Credential caching in Headlamp with Helm enabled",
        "content": {
          "excerpt_text": "Credential caching in Headlamp with Helm enabled",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/135798"
          ],
          "content_hash": "sha256:2ba255d2107967cbb26228474820ac33502d0e4cb75eaf3aa58324bd4b3fe1c7"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Credential caching in Headlamp with Helm enabled",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-14269",
            "issue_number": 135798
          },
          "content_text": "Original tracking issue: https://github.com/kubernetes-sigs/headlamp/issues/4282\n\nCVSS Rating: High (8.8) [CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3-1#CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H)\n\n_Description of vulnerability_\n\nA security issue was discovered in the in-cluster version of Headlamp where unauthenticated users may be able to reuse cached credentials to access Helm functionality through the Headlamp UI. Kubernetes clusters are only affected if Headlamp is installed, is configured with config.enableHelm: true, and an authorized user has previously accessed the Helm functionality.\n\n### Am I vulnerable?\n\nKubernetes clusters with an in-cluster installation of Headlamp <= v0.38.0 and config.enableHelm set to true are affected. The Headlamp desktop version is not affected.\n\n#### Affected Versions\n\n- Headlamp <= v0.38.0\n\n### How do I mitigate this vulnerability?\n\nUpgrade to the fixed version. Prior to upgrading, this vulnerability can be mitigated by ensuring Headlamp is not publicly exposed with an ingress server to limit exposure.\n\n\n#### Fixed Versions\n\n- Headlamp v0.39.0 https://github.com/kubernetes-sigs/headlamp/releases/tag/v0.39.0 \n\nTo upgrade, refer to the documentation: https://headlamp.dev/docs/latest/ \n\n### Detection\n\nReview logs for unexpected access to clusters/main/helm/releases/list and other Helm related endpoints.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by [brndstrp](https://hackerone.com/brndstrp).\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n\n",
          "date_published": "2025-12-17T19:23:10Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-14269",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-13281",
        "url": "https://github.com/kubernetes/kubernetes/issues/135525",
        "published_at": null,
        "updated_at": null,
        "headline": "Portworx Half-Blind SSRF in kube-controller-manager",
        "content": {
          "excerpt_text": "Portworx Half-Blind SSRF in kube-controller-manager",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/135525"
          ],
          "content_hash": "sha256:9de4eb94dd3adaa51b7fa1db1fd6af9203e0146a299910f1a0b14d7c584dc898"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Portworx Half-Blind SSRF in kube-controller-manager",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-13281",
            "issue_number": 135525
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3-1#CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:C/C:H/I:N/A:N) - Medium (5.8)\n\nA half-blind Server Side Request Forgery (SSRF) vulnerability exists in kube-controller-manager when using the in-tree Portworx StorageClass. This was patched for other in-tree StorageClasses (GlusterFS, Quobyte, StorageOS, and ScaleIO) as part of[ CVE-2020-8555](https://github.com/kubernetes/kubernetes/issues/91542). This vulnerability allows authorized users to leak arbitrary information from unprotected endpoints in the control plane’s host network (including link-local or loopback services). \n\nAn attacker with permissions to create a pod using the built-in Portworx StorageClass can cause kube-controller-manager to make GET requests (without an attacker controlled request body) from within the control plane’s host network and make the corresponding HTTP response body visible as part of event objects created by kube-controller-manager.\n\nThe in-tree Portworx StorageClass has been disabled by default starting in version v1.31 from the CSIMigrationPortworx feature gate. As a result, currently supported versions greater than or equal to v1.32 are not impacted unless the CSIMigrationPortworx feature gate is disabled with an override.\n\n### Am I vulnerable?\n\nYou may be vulnerable if all of the following are true:\n- You are running a vulnerable version and have manually disabled the CSIMigrationPortworx feature gate.\n- There are unprotected endpoints normally only visible from the control plane’s host network (including link-local metadata endpoints, unauthenticated services listening on localhost, or other services in the control plane’s private network).\n- Untrusted users can create pods with the affected Portworx volume type.\n\n#### Affected Versions\n\nThe CSIMigrationPortworx feature gate was enabled by default starting on version v1.31. As a result, EOL versions <= v1.30 are more likely to be vulnerable because the CSIMigrationPortworx feature is disabled by default.\n- kube-controller-manager: <= v1.30.14\n- kube-controller-manager: <= v1.31.14 \n- kube-controller-manager: <= v1.32.9 \n- kube-controller-manager: <= v1.33.5 \n- kube-controller-manager: <= v1.34.1 \n\n\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by upgrading to a fixed kube-controller-manager version or by enabling the CSIMigrationPortworx feature gate (if it was overridden from its default value in versions greater than equal to v1.31).\n\n#### Fixed Versions\n- kube-controller-manager: >= v1.32.10\n- kube-controller-manager: >= v1.33.6\n- kube-controller-manager: >= v1.34.2\n\n### Detection\n\nThis issue can be detected on clusters which have the CSIMigrationPortworx feature gate disabled on impacted versions by analyzing ProvisioningFailed events from kube-controller-manager which may contain sensitive information from the control plane’s host network.\n\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\n\n#### Acknowledgements\nThis vulnerability was reported by:\n- Xingyu Liu (xingyu@stu.xidian.edu.cn)\n-  Jinku Li (jkli@xidian.edu.cn)\n\nThe issue was fixed and coordinated by:\n- Ankit Gohil @gohilankit",
          "date_published": "2025-11-30T23:08:37Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-13281",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-9708",
        "url": "https://github.com/kubernetes/kubernetes/issues/134063",
        "published_at": null,
        "updated_at": null,
        "headline": "Kubernetes C# Client: improper certificate validation in custom CA mode may lead to man-in-the-middle attacks",
        "content": {
          "excerpt_text": "Kubernetes C# Client: improper certificate validation in custom CA mode may lead to man-in-the-middle attacks",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/134063"
          ],
          "content_hash": "sha256:683a120e1997c84820ee960b0fa2c7c2a244045cbc676103dc8eb6906b50bf9d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Kubernetes C# Client: improper certificate validation in custom CA mode may lead to man-in-the-middle attacks",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-9708",
            "issue_number": 134063
          },
          "content_text": "**CVSS Rating:**  \n[CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3-1#CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:N) — **Medium (6.8)**\n\n\nA vulnerability exists in the Kubernetes C# client where the certificate validation logic accepts properly constructed certificates from any Certificate Authority (CA) without properly verifying the trust chain. This flaw allows a malicious actor to present a forged certificate and potentially intercept or manipulate communication with the Kubernetes API server, leading to possible man-in-the-middle attacks and API impersonation.\n\n### Am I vulnerable?\n\nYou are vulnerable if:\n- You use the Kubernetes C# client to connect to a Kubernetes API server over TLS/HTTPS  with custom CA certificates in your kubeconfig file and your connection occurs over an untrusted network.\n\n#### Affected Versions\n- All versions of the Kubernetes C# client prior to the next release <=17.0.13\n\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by:\n- Deploy the patch version of the Kubernetes C# client as soon as possible.\n- Moving the CA certificates into the system trust store instead of specifying them in the kubeconfig file. Note: This approach may introduce new risks, as all processes on the system will begin to trust certificates signed by that CA. If you must use an affected version, you can disable custom CA and add the CA to the machine's trusted root.\n\n\n#### Fixed Versions\n\n- Kubernetes C# client >= v17.0.14\n\n### Detection\n\nTo determine if your applications are affected:\n- Review your usage of the Kubernetes C# client and inspect certificate validation logic.\n- Review your kubeconfig files and determine if you use a custom CA certificate (the certificate-authority field in the clusters section).\n- Review client logs for unexpected or untrusted certificate connections.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by @elliott-beach\n\nThe issue was fixed and coordinated by: \n\nBoshi Lian @tg123\nBrendan Burns @brendandburns\nRita Zhang @ritazh\n",
          "date_published": "2025-09-15T04:59:12Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-9708",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-7445",
        "url": "https://github.com/kubernetes/kubernetes/issues/133897",
        "published_at": null,
        "updated_at": null,
        "headline": "secrets-store-sync-controller discloses service account tokens in logs",
        "content": {
          "excerpt_text": "secrets-store-sync-controller discloses service account tokens in logs",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/133897"
          ],
          "content_hash": "sha256:91a4ad0db2a6b92e364b4df48a28dc2fefdba019c03e73d14c9d08a35228c77b"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "secrets-store-sync-controller discloses service account tokens in logs",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-7445",
            "issue_number": 133897
          },
          "content_text": "A security issue was discovered in [secrets-store-sync-controller](https://github.com/kubernetes-sigs/secrets-store-sync-controller) where an actor with access to the controller logs could observe service account tokens.  These tokens could then potentially be exchanged with external cloud providers to access secrets stored in cloud vault solutions.  Tokens are only logged when there is a specific error marshaling the `parameters` sent to the providers.\n\nThis issue has been rated MEDIUM [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N) (6.5), and assigned CVE-2025-7445\n\n### Am I vulnerable?\n\nTo check if tokens are being logged, examine the manager container log:\n\n```bash\nkubectl logs -l 'app.kubernetes.io/part-of=secrets-store-sync-controller' -c manager -f | grep --line-buffered \"csi.storage.k8s.io/serviceAccount.tokens\"\n```\n\n### Affected Versions\n\n- secrets-store-sync-controller < v0.0.2\n\n### How do I mitigate this vulnerability?\n\nUpgrade to secrets-store-sync-controller v0.0.2+\n\n### Fixed Versions\n\n- secrets-store-sync-controller >= v0.0.2\n\n\n### Detection\n\nExamine cloud provider logs for unexpected token exchanges, as well as unexpected access to cloud vault secrets.\n\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](https://groups.google.com/)\n\n### Acknowledgements\n\nThis vulnerability was reported by Reem Rotenberg and [Kas Dekel](https://github.com/privmickas) from Microsoft.\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig auth\n\n/triage accepted",
          "date_published": "2025-09-04T21:40:42Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-7445",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-5187",
        "url": "https://github.com/kubernetes/kubernetes/issues/133471",
        "published_at": null,
        "updated_at": null,
        "headline": "Nodes can delete themselves by adding an OwnerReference",
        "content": {
          "excerpt_text": "Nodes can delete themselves by adding an OwnerReference",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/133471"
          ],
          "content_hash": "sha256:778ece452f441d2afe1830913576f900cd6eaa61934db4c3a5764d0949e66b6b"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Nodes can delete themselves by adding an OwnerReference",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-5187",
            "issue_number": 133471
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:L](https://www.first.org/cvss/calculator/3-1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:L) - Medium (6.7)\n\nA vulnerability exists in the NodeRestriction admission controller where node users can delete their corresponding node object by patching themselves with an OwnerReference to a cluster-scoped resource. If the OwnerReference resource does not exist or is subsequently deleted, the given node object will be deleted via garbage collection. By default, node users are authorized for create and patch requests but not delete requests against their node object. Since the NodeRestriction admission controller does not prevent patching OwnerReferences, a compromised node could leverage this vulnerability to delete and then recreate its node object. This would permit the node object to be recreated with modified taints or labels which are normally rejected by this plugin. Modifying taints or labels on a node could allow an attacker to control which pods are running on the compromised node.\n\n### Am I vulnerable?\n\nAll clusters that have enabled the NodeRestriction but not the OwnerReferencesPermissionEnforcement admission controller are vulnerable. The OwnerReferencesPermissionEnforcement controller protects access to the OwnerReferences of an object so that only users with delete permission to the object can change it.\n\n#### Affected Versions\nkube-apiserver: <= v1.31.11\nkube-apiserver: <= v1.32.7\nkube-apiserver: <= v1.33.3\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by upgrading to a kube-apiserver binary running one of patched minor versions for 1.31 through 1.33 listed below. These fixed versions have added functionality to the NodeRestriction admission controller to prevent node users from modifying their own OwnerReferences. \n\nAlternatively, this vulnerability can be mitigated by enabling the OwnerReferencesPermissionEnforcement admission controller, which will prevent any user without delete permissions on an object from modifying the OwnerReferences on that object. Note that this admission controller will apply to all users and object types.\n\n#### Fixed Versions\nkube-apiserver: >= v1.31.12\nkube-apiserver: >= v1.32.8\nkube-apiserver: >= v1.33.4\n\n### Detection\n\nThis issue can be detected on clusters which have NodeRestriction but not OwnerReferencesPermissionEnforcement enabled by analyzing API audit logs for node patch requests issued by node users which modify OwnerReferences. In normal operation, a Kubelet will never issue a patch request which modifies its own OwnerReferences.\n\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\n\n#### Acknowledgements\n\nThis vulnerability was reported by Paul Viossat.\n\nThe issue was fixed and coordinated by: \n\nSergey Kanzhelev @SergeyKanzhelev\nJordan Liggitt @liggitt\nMarko Mudrinić @xmudrii",
          "date_published": "2025-08-11T16:29:36Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-5187",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-7342",
        "url": "https://github.com/kubernetes/kubernetes/issues/133115",
        "published_at": null,
        "updated_at": null,
        "headline": "VM images built with Kubernetes Image Builder Nutanix or OVA providers use default credentials for Windows images if user did not override",
        "content": {
          "excerpt_text": "VM images built with Kubernetes Image Builder Nutanix or OVA providers use default credentials for Windows images if user did not override",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/133115"
          ],
          "content_hash": "sha256:5032503a620f2540ddffa0ccd7bec18f7373c417dc4d60b6efb6a3a3c6d2cc62"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "VM images built with Kubernetes Image Builder Nutanix or OVA providers use default credentials for Windows images if user did not override",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-7342",
            "issue_number": 133115
          },
          "content_text": "CVSS Rating High 7.5: [CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H)\n\nA security issue was discovered in the Kubernetes Image Builder where default credentials are enabled during the Windows image build process when using the Nutanix or VMware OVA providers. These credentials, which allow root access, are disabled at the conclusion of the build. Kubernetes clusters are only affected if their nodes use VM images created via the Image Builder project and the vulnerability was exploited during the build process, which requires an attacker to access the build VM and modify the image while the build is in progress.\n\n### Am I vulnerable?\n\nClusters using virtual machine Windows images built with Kubernetes Image Builder (https://github.com/kubernetes-sigs/image-builder) version v0.1.44 or earlier are affected if built with the Nutanix or OVA provider.\n\nVMs using images built with all other providers are not affected by this issue.\n\nTo determine the version of Image Builder you are using, use one of the following methods:\n- For git clones of the image builder repository:\n```\n    cd <local path to image builder repo>\n    make version\n```\n- For installations using a tarball download:\n```\n    cd <local path to install location>\n    grep -o v0\\\\.[0-9.]* RELEASE.md | head -1\n```\n- For a container image release:\n    `docker run --rm <image pull spec> version`\n  or\n    `podman run --rm <image pull spec> version`\n  or look at the image tag specified, in the case of an official image such as `registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.44`\n\n\n#### Affected Versions\n\n- Kubernetes Image Builder versions <= v0.1.44\n\n### How do I mitigate this vulnerability?\nRebuild any affected images using a fixed version of Image Builder. Fixed in Kubernetes Image Builder release v0.1.45\nRe-deploy the fixed images to any affected VMs or use image-builder v0.1.41 (February 2025) or later, and set the `admin_password` JSON variable.\nPrior to upgrading, this vulnerability can be mitigated by changing the password of the Administrator account on affected VMs:\n`net user Administrator <new-password>`\n\n#### Fixed Versions\n\nFixed in Kubernetes Image Builder release v0.1.45 https://github.com/kubernetes-sigs/image-builder/pull/1800\n\n\n### Detection\n\n`Get-LocalUser -Name Administrator | Select-Object Name,Enabled,SID,Lastlogon | Format-List`\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n## Additional Details\n\nThe fixed version requires users to specify a password in the WINDOWS_ADMIN_PASSWORD environment variable or in the `admin_password` JSON variable. If both are empty, then the image builder would not build the image and return an error.\n\n#### Acknowledgements\n\nThis vulnerability was reported by Abdel Adim Oisfi, Davide Silvetti, Nicolò Daprelà, Paolo Cavaglià, Pietro Tirenna from Shielder.\n\nThe issue was fixed and coordinated by Matt Boersma of the Image Builder project.\n\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig cluster-lifecycle\n",
          "date_published": "2025-07-21T23:22:19Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-7342",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-4563",
        "url": "https://github.com/kubernetes/kubernetes/issues/132151",
        "published_at": null,
        "updated_at": null,
        "headline": "Nodes can bypass dynamic resource allocation authorization checks",
        "content": {
          "excerpt_text": "Nodes can bypass dynamic resource allocation authorization checks",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/132151"
          ],
          "content_hash": "sha256:c0d9a914cb4d5749bedd586e8f2f4989788155c91e8e4da536b265346d8aea32"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Nodes can bypass dynamic resource allocation authorization checks",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-4563",
            "issue_number": 132151
          },
          "content_text": "CVSS Rating:\n[CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:N/A:L](https://www.first.org/cvss/calculator/3-1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:N/A:L) - **Low** (2.7)\n\nA vulnerability exists in the NodeRestriction admission controller where nodes can bypass dynamic resource allocation authorization checks. When the DynamicResourceAllocation feature gate is enabled, the controller properly validates resource claim statuses during pod status updates but fails to perform equivalent validation during pod creation. This allows a compromised node to create mirror pods that access unauthorized dynamic resources, potentially leading to privilege escalation. In practice, sanity checks in the kubelet prevent starting those mirror pods after they have been created. Even if they were started, an attacker probably already has gained full access to the node and with most dynamic resources won’t be able to gain additional privileges.\n\n### Am I vulnerable?\n\nAll clusters that are using the DynamicResourceAllocation feature (disabled by default) and static pods together may be vulnerable.\n\n#### Affected Versions\n\nkube-apiserver: v1.32.0 - v1.32.5\nkube-apiserver: v1.33.0 - 1.33.1\n\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by:\nIf you're not actively using the DynamicResourceAllocation features, the safest and simplest action is to turn off the feature on the API server.\n\n\n#### Fixed Versions\n\nkube-apiserver >= v1.32.6 \nkube-apiserver >= v1.33.2\n\n### Detection\n\nAll clusters that are using the DynamicResourceAllocation feature and static pods may be vulnerable.  Run the following command to see if the feature is in use:\n\n`kubectl get ResourceClaim --all-namespaces`\n\nand \n\n`kubectl get pods --all-namespaces -o json | jq -r '\n  .items[] \n  | select(.metadata.annotations[\"kubernetes.io/config.mirror\"] == \"true\") \n  | \"\\(.metadata.namespace)/\\(.metadata.name)\"'`\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Amit Schendel @amitschendel ARMO\n\nThe issue was fixed and coordinated by: \n\nPatrick Ohly @pohly\nJordan Liggitt @liggitt\nBalaji @SaranBalaji90\nRita Zhang @ritazh\nMarko Mudrinić @xmudrii\n\n\n/triage accepted\n/lifecycle frozen",
          "date_published": "2025-06-06T15:48:26Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-4563",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-1974",
        "url": "https://github.com/kubernetes/kubernetes/issues/131009",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx admission controller RCE escalation",
        "content": {
          "excerpt_text": "ingress-nginx admission controller RCE escalation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/131009"
          ],
          "content_hash": "sha256:03e03029e35f52caa191ac6ffebe0669a1330d6a69b21589bf09dddc846529de"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx admission controller RCE escalation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-1974",
            "issue_number": 131009
          },
          "content_text": "CVSS Rating: ([CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)) (Score: 9.8, Critical)\n\nA security issue was discovered in Kubernetes where under certain conditions, an unauthenticated attacker with access to the pod network can achieve arbitrary code execution in the context of the ingress-nginx controller. This can lead to disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- < v1.11.0\n- v1.11.0 \\- 1.11.4  \n- v1.12.0\n\n### How do I mitigate this vulnerability?\n\n**ACTION REQUIRED:** The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.11.5, v1.12.1, or any later version.\n\nBefore applying the patch, this issue can be mitigated by disabling the Validating Admission Controller functionality of ingress-nginx.\n\n#### Fixed Versions\n\n- ingress-nginx [main@0ccf4ca](https://github.com/kubernetes/ingress-nginx/pull/13068/commits/0ccf4caaadec919680c455d221e53d97970d527d)\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nThere are no known indicators of compromise that prove this vulnerability has been exploited.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Nir Ohfeld, Ronen Shustin, Sagi Tzadik, and Hillai Ben Sasson from Wiz\n\nThe issue was fixed and coordinated by Marco Ebert, James Strong, Tabitha Sable, and the Kubernetes Security Response Committee\n",
          "date_published": "2025-03-23T17:38:57Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-1974",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-1098",
        "url": "https://github.com/kubernetes/kubernetes/issues/131008",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx controller configuration injection via unsanitized mirror annotations",
        "content": {
          "excerpt_text": "ingress-nginx controller configuration injection via unsanitized mirror annotations",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/131008"
          ],
          "content_hash": "sha256:28776c6669975395fe572777015144e4825276989efdd219737b043cf08b6474"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx controller configuration injection via unsanitized mirror annotations",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-1098",
            "issue_number": 131008
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) (Score: 8.8, High)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the \\`mirror-target\\` and \\`mirror-host\\` Ingress annotations can be used to inject arbitrary configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- < v1.11.0\n- v1.11.0 \\- 1.11.4  \n- v1.12.0\n\n### How do I mitigate this vulnerability?\n\n**ACTION REQUIRED:** The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.11.5, v1.12.1, or any later version.\n\n#### Fixed Versions\n\n- ingress-nginx [main@2e9f373](https://github.com/kubernetes/ingress-nginx/pull/13068/commits/2e9f37380afb7853fa6daa1c3e6659550aadfd90)\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within the \\`mirror-target\\` or \\`mirror-host\\` annotations of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Nir Ohfeld, Ronen Shustin, Sagi Tzadik and Hillai Ben Sasson from Wiz\n\nThe issue was fixed and coordinated by Marco Ebert, James Strong, Tabitha Sable, and the Kubernetes Security Response Committee\n",
          "date_published": "2025-03-23T17:38:53Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-1098",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-1097",
        "url": "https://github.com/kubernetes/kubernetes/issues/131007",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx controller configuration injection via unsanitized auth-tls-match-cn annotation",
        "content": {
          "excerpt_text": "ingress-nginx controller configuration injection via unsanitized auth-tls-match-cn annotation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/131007"
          ],
          "content_hash": "sha256:bc61314dc2a9c1343b2d2a3d30889419537a6e80557bafc29e459ea6fd8157e6"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx controller configuration injection via unsanitized auth-tls-match-cn annotation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-1097",
            "issue_number": 131007
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) (Score: 8.8, High)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the \\`auth-tls-match-cn\\` Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- < v1.11.0\n- v1.11.0 \\- 1.11.4  \n- v1.12.0\n\n### How do I mitigate this vulnerability?\n\n**ACTION REQUIRED:** The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.11.5, v1.12.1, or any later version.\n\n#### Fixed Versions\n\n- ingress-nginx [main@06c992a](https://github.com/kubernetes/ingress-nginx/pull/13068/commits/06c992abd8eef9710359a236c443c613d29fdfad)\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within the \\`auth-tls-match-cn\\` annotation of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Nir Ohfeld, Ronen Shustin, Sagi Tzadik and Hillai Ben Sasson from Wiz\n\nThe issue was fixed and coordinated by Marco Ebert, James Strong, Tabitha Sable, and the Kubernetes Security Response Committee\n",
          "date_published": "2025-03-23T17:38:49Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-1097",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-24514",
        "url": "https://github.com/kubernetes/kubernetes/issues/131006",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx controller configuration injection via unsanitized auth-url annotation",
        "content": {
          "excerpt_text": "ingress-nginx controller configuration injection via unsanitized auth-url annotation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/131006"
          ],
          "content_hash": "sha256:e766c6cc5b03b73549318b2bf031ce65711cd257966f9f3a72f1a180c7cd899e"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx controller configuration injection via unsanitized auth-url annotation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-24514",
            "issue_number": 131006
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) (Score: 8.8, High)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the \\`auth-url\\` Ingress annotation can be used to inject configuration into nginx. This can lead to arbitrary code execution in the context of the ingress-nginx controller, and disclosure of Secrets accessible to the controller. (Note that in the default installation, the controller can access all Secrets cluster-wide.)\n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\nThis issue does not affect you if you have the \\`enable-annotation-validation\\` CLI argument enabled. (This option is enabled by default starting from ingress-nginx v1.12.0.)\n\n#### Affected Versions\n\n- < v1.11.0\n- v1.11.0 \\- 1.11.4  \n- v1.12.0\n\n### How do I mitigate this vulnerability?\n\n**ACTION REQUIRED:** The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.11.5, v1.12.1, or any later version.\n\nPrior to upgrading, this vulnerability can be mitigated by setting the \\`enable-annotation-validation\\` CLI argument to “true”.\n\n#### Fixed Versions\n\n- ingress-nginx [main@ab470eb](https://github.com/kubernetes/ingress-nginx/pull/13068/commits/ab470eb920924d62a197ebddd8a4cc3031a77ddf)\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nSuspicious data within the \\`auth-url\\` annotation of an Ingress resource could indicate an attempt to exploit this vulnerability.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Nir Ohfeld, Ronen Shustin and Sagi Tzadik from Wiz\n\nThe issue was fixed and coordinated by Marco Ebert, James Strong, Tabitha Sable, and the Kubernetes Security Response Committee\n",
          "date_published": "2025-03-23T17:38:44Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-24514",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-24513",
        "url": "https://github.com/kubernetes/kubernetes/issues/131005",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx controller auth secret file path traversal vulnerability",
        "content": {
          "excerpt_text": "ingress-nginx controller auth secret file path traversal vulnerability",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/131005"
          ],
          "content_hash": "sha256:80762f4ab246c11cc14ab72b5d4649406d4edbd05abb14d9d71b2b5235859448"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx controller auth secret file path traversal vulnerability",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-24513",
            "issue_number": 131005
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:L)) (Score: 4.8, Medium)\n\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where attacker-provided data are included in a filename by the ingress-nginx Admission Controller feature, resulting in directory traversal within the container. This could result in denial of service, or when combined with other vulnerabilities, limited disclosure of Secret objects from the cluster. \n\n### Am I vulnerable?\n\nThis issue affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running \\`kubectl get pods \\--all-namespaces \\--selector app.kubernetes.io/name=ingress-nginx\\`.\n\n#### Affected Versions\n\n- < v1.11.0\n- v1.11.0 \\- 1.11.4  \n- v1.12.0\n\n### How do I mitigate this vulnerability?\n\n**ACTION REQUIRED:** The following steps must be taken to mitigate this vulnerability: Upgrade ingress-nginx to v1.11.5, v1.12.1, or any later version.\n\nBefore applying the patch, this issue can be mitigated by disabling the Validating Admission Controller functionality of ingress-nginx.  \n\n#### Fixed Versions\n\n- ingress-nginx [main@cbc1590](https://github.com/kubernetes/ingress-nginx/pull/13068/commits/cbc159094f6d1b1bf8cf1761eb119138d1f95df1)\n\nTo upgrade, refer to the documentation: [Upgrading Ingress-nginx](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\n\n### Detection\n\nThere are no known indicators of compromise that prove this vulnerability has been exploited.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by Nir Ohfeld and Ronen Shustin from Wiz\n\nThe issue was fixed and coordinated by Marco Ebert, James Strong, Tabitha Sable, and the Kubernetes Security Response Committee",
          "date_published": "2025-03-23T17:38:28Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-24513",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-1767",
        "url": "https://github.com/kubernetes/kubernetes/issues/130786",
        "published_at": null,
        "updated_at": null,
        "headline": "GitRepo Volume Inadvertent Local Repository Access",
        "content": {
          "excerpt_text": "GitRepo Volume Inadvertent Local Repository Access",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/130786"
          ],
          "content_hash": "sha256:f11577530d11a900d78057a68329b183255a8483a109ee3107425858974266bf"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "GitRepo Volume Inadvertent Local Repository Access",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-1767",
            "issue_number": 130786
          },
          "content_text": "**Issue Details**\nA security vulnerability was discovered in Kubernetes that could allow a user with create pod permission to exploit gitRepo volumes to access local git repositories belonging to other pods on the same node.\nThis issue has been rated Medium ([CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N)) (score: 6.5), and assigned CVE-2025-1767.\n\n**Am I vulnerable?**\n\nThis CVE only affects Kubernetes clusters that utilize the in-tree gitRepo volume to clone git repositories from other pods within the same node. Since the in-tree gitRepo volume feature has been deprecated and will not receive security updates upstream, any cluster still using this feature remains vulnerable. \nAffected Components\nkubelet\n\n**Affected Versions**\nAll versions of Kubernetes\n\n**How do I mitigate this vulnerability?**\n\nTo mitigate this vulnerability, you must use an init container to perform git clone operation and then mount the directory into the Pod's container. An example of this approach is provided [here](https://gist.github.com/tallclair/849601a16cebeee581ef2be50c351841).\n\nNote: You can also restrict the use of gitRepo volumes in your cluster using policies such as ValidatingAdmissionPolicy or through Restricted pod security standard policy. You can use the following Common Expression Language (CEL) expression as part of a policy to reject use of gitRepo volumes: `has(object.spec.volumes) || !object.spec.volumes.exists(v, has(v.gitRepo))`\n\n**Detection**\n\nTo detect whether this vulnerability has been exploited, you can use the following command to list all pods that use the in-tree gitRepo volume and clones to a .git subdirectory. \n`kubectl get pods --all-namespaces -o json | jq '.items[] | select(.spec.volumes[].gitRepo.repository | test(\"^/\")) | {name: .metadata.name, namespace: .metadata.namespace, repository: (.spec.volumes[] | select(.gitRepo) | .gitRepo.repository)}'`\n\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io) \n\n**Acknowledgements**\nThis vulnerability was reported by Christophe Hauquiert.\n",
          "date_published": "2025-03-13T16:08:20Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-1767",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2025-0426",
        "url": "https://github.com/kubernetes/kubernetes/issues/130016",
        "published_at": null,
        "updated_at": null,
        "headline": "Node Denial of Service via kubelet Checkpoint API",
        "content": {
          "excerpt_text": "Node Denial of Service via kubelet Checkpoint API",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/130016"
          ],
          "content_hash": "sha256:f892332c9edbbf26ec13489dd1fd61a1e3958827647c4da12b5a7ab609e43bc0"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Node Denial of Service via kubelet Checkpoint API",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2025-0426",
            "issue_number": 130016
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)\n\nA security issue was discovered in Kubernetes where a large number of container checkpoint requests made to the unauthenticated kubelet read-only HTTP endpoint may cause a Node Denial of Service by filling the Node's disk. \n\n### Am I vulnerable?\n\nAll clusters running an affected version listed below with the kubelet read-only HTTP port enabled and using a container runtime that supports the container checkpointing feature, such as CRI-O v1.25.0+ (with `enable_criu_support` set to true) or containerd v2.0+ with `criu` installed, are affected.\n\n#### Affected Versions\n\n- kubelet v1.32.0 to v1.32.1\n- kubelet v1.31.0 to v1.31.5\n- kubelet v1.30.0 to v1.30.9\n\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by setting the `ContainerCheckpoint` feature gate to `false` in your kubelet configuration, disabling the kubelet read-only port, and limiting access to the kubelet API, or upgrading to a fixed version listed below, which enforces authentication for the kubelet Checkpoint API.\n\n#### Fixed Versions\n\n- kubelet master - fixed by #129739\n- kubelet v1.32.2 - fixed by #130010\n- kubelet v1.31.6 - fixed by #130011\n- kubelet v1.30.10 - fixed by #130012\n- kubelet v1.29.14 - fixed by #130014\n  - Note: Container checkpoint support was an off by default Alpha feature in v1.25-v1.29\n\n### Detection\n\nA large number of requests to the kubelet read-only HTTP server's `/checkpoint` endpoint, or a large number of checkpoints stored (by default) under `/var/lib/kubelet/checkpoints` on a Node may indicate an attempted Denial of Service attack using this bug.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported and fixed by Tim Allclair @tallclair from Google.\n\nThe issue was coordinated by: \n\nTim Allclair @tallclair\nSascha Grunert saschagrunert@\nCraig Ingram @cji\nJordan Liggitt liggitt@\n\n/triage accepted\n/lifecycle frozen\n/area security\n/kind bug\n/committee security-response\n/label official-cve-feed\n/sig node\n/area kubelet",
          "date_published": "2025-02-06T20:03:44Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2025-0426",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-9042",
        "url": "https://github.com/kubernetes/kubernetes/issues/129654",
        "published_at": null,
        "updated_at": null,
        "headline": "Command Injection affecting Windows nodes via nodes/*/logs/query API",
        "content": {
          "excerpt_text": "Command Injection affecting Windows nodes via nodes/*/logs/query API",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/129654"
          ],
          "content_hash": "sha256:d959b33fc62b7904f2510302d0bb90760e69e94ec5f0bf77135fd14c26d08a84"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Command Injection affecting Windows nodes via nodes/*/logs/query API",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-9042",
            "issue_number": 129654
          },
          "content_text": "Hello Kubernetes Community,\n\nA security vulnerability has been discovered in Kubernetes windows nodes that could allow a user with the ability to query a node's '/logs' endpoint to execute arbitrary commands on the host. \n \nThis issue has been rated Medium with a CVSS v3.1 score of 5.9 ([CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:H/I:H/A:N)) and assigned CVE-2024-9042.\n \n### Am I vulnerable?\nThis CVE affects only Windows worker nodes. Your worker node is vulnerable to this issue if it is running one of the affected versions listed below.\n \n#### Affected Components\nKubelet\n \n#### Affected Versions\nv1.32.0\nv1.31.0 to v1.31.4\nv1.30.0 to v1.30.8\n<=v1.29.12\n \n### How do I mitigate this vulnerability?\nTo mitigate this vulnerability, you need to upgrade the Kubelet on your Windows worker nodes to one of the fixed versions listed below.\n \n### Fixed Versions\nv1.32.1\nv1.31.5\nv1.30.9\nv1.29.13\n \n### Detection\nTo detect whether this vulnerability has been exploited, you can examine your cluster's audit logs to search for node 'logs' queries with suspicious inputs.\n \nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io) \n \n### Acknowledgements\nThis vulnerability was reported by Peled, Tomer and mitigated by Aravindh Puthiyaprambil.",
          "date_published": "2025-01-15T22:28:29Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-9042",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-10220",
        "url": "https://github.com/kubernetes/kubernetes/issues/128885",
        "published_at": null,
        "updated_at": null,
        "headline": "Arbitrary command execution through gitRepo volume",
        "content": {
          "excerpt_text": "Arbitrary command execution through gitRepo volume",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/128885"
          ],
          "content_hash": "sha256:7b9869aaa60ae2cf2a5f83e776c5dd526d8c6baf830964e8ada5a6ffa79dca02"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Arbitrary command execution through gitRepo volume",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-10220",
            "issue_number": 128885
          },
          "content_text": "A security vulnerability was discovered in Kubernetes that could allow a user with the ability to create a pod and associate a gitRepo volume to execute arbitrary commands beyond the container boundary. This vulnerability leverages the hooks folder in the target repository to run arbitrary commands outside of the container's boundary.\r\n\r\nPlease note that this issue was originally publicly disclosed with a fix in July (#124531), and we are retroactively assigning it a CVE to assist in awareness and tracking.\r\n\r\nThis issue has been rated High ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N)) (score: 8.1), and assigned CVE-2024-10220.\r\n\r\n### Am I vulnerable?\r\n\r\nThis CVE affects Kubernetes clusters where pods use the in-tree gitRepo volume to clone a repository to a subdirectory. If the Kubernetes cluster is running one of the affected versions listed below, then it is vulnerable to this issue.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet v1.30.0 to v1.30.2\r\n- kubelet v1.29.0 to v1.29.6\r\n- kubelet <= v1.28.11\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nTo mitigate this vulnerability, you must upgrade your Kubernetes cluster to one of the fixed versions listed below. \r\n\r\nAdditionally, since the gitRepo volume has been deprecated, the recommended solution is to perform the Git clone operation using an init container and then mount the directory into the Pod's container. An example of this approach is provided [here](https://gist.github.com/tallclair/849601a16cebeee581ef2be50c351841).\r\n\r\n#### Fixed Versions\r\n\r\n* kubelet master/v1.31.0  - fixed by #124531\r\n* kubelet v1.30.3  - fixed by #125988\r\n* kubelet v1.29.7 - fixed by #125989\r\n* kubelet v1.28.12 - fixed by #125990\r\n\r\n### Detection\r\n\r\nTo detect whether this vulnerability has been exploited, you can use the following command to list all pods that use the in-tree gitRepo volume and clones to a .git subdirectory. \r\n\r\n```\r\nkubectl get pods --all-namespaces -o json | jq '.items[] | select(.spec.volumes[].gitRepo.directory | endswith(\"/.git\")) | {name: .metadata.name, namespace: .metadata.namespace}\r\n```\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported and mitigated by Imre Rad.\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig node\r\n/area kubelet",
          "date_published": "2024-11-20T15:30:44Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-10220",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-9594",
        "url": "https://github.com/kubernetes/kubernetes/issues/128007",
        "published_at": null,
        "updated_at": null,
        "headline": "VM images built with Image Builder with some providers use default credentials during builds",
        "content": {
          "excerpt_text": "VM images built with Image Builder with some providers use default credentials during builds",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/128007"
          ],
          "content_hash": "sha256:3dc76b12f014a8d4d8bf2a6bdb167d368d9730c78abbf2ce2319199a873716cf"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "VM images built with Image Builder with some providers use default credentials during builds",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-9594",
            "issue_number": 128007
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:A/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:A/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H)\r\n\r\nA security issue was discovered in the Kubernetes Image Builder where default credentials are enabled during the image build process when using the Nutanix, OVA, QEMU or raw providers. The credentials can be used to gain root access. The credentials are disabled at the conclusion of the image build process. Kubernetes clusters are only affected if their nodes use VM images created via the Image Builder project. \r\n\r\n### Am I vulnerable?\r\n\r\nClusters using virtual machine images built with Kubernetes Image Builder (https://github.com/kubernetes-sigs/image-builder) version v0.1.37 or earlier are affected if built with the Nutanix, OVA, QEMU or raw providers. These images were vulnerable during the image build process and are affected only if an attacker was able to reach the VM where the image build was happening and used the vulnerability to modify the image at the time the image build was occurring.\r\n\r\nVMs using images built with the Proxmox provider are affected by a related, but much more serious vulnerability (see #128006).\r\n\r\nVMs using images built with all other providers are not affected by this issue.\r\n\r\nTo determine the version of Image Builder you are using, use one of the following methods:\r\n- For git clones of the image builder repository:\r\n```\r\n    cd <local path to image builder repo>\r\n    make version\r\n```\r\n- For installations using a tarball download:\r\n```\r\n    cd <local path to install location>\r\n    grep -o v0\\\\.[0-9.]* RELEASE.md | head -1\r\n```\r\n- For a container image release:\r\n    `docker run --rm <image pull spec> version`\r\n  or\r\n    `podman run --rm <image pull spec> version`\r\n  or look at the image tag specified, in the case of an official image such as `registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.37`\r\n\r\n\r\n#### Affected Versions\r\n\r\n- Kubernetes Image Builder versions <= v0.1.37\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nRebuild any affected images using a fixed version of Image Builder. Re-deploy the fixed images to any affected VMs.\r\n\r\n#### Fixed Versions\r\n\r\n- Kubernetes Image Builder master - fixed by https://github.com/kubernetes-sigs/image-builder/pull/1596\r\n- Fixed in Kubernetes Image Builder release v0.1.38\r\n\r\n### Detection\r\n\r\nThe linux command `last builder` can be used to view logins to the affected `builder` account.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n## Additional Details\r\n\r\nThe fixed version sets a randomly-generated password for the duration of the image build\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Nicolai Rybnikar @rybnico from Rybnikar Enterprises GmbH.\r\n\r\nThe issue was fixed and coordinated by Marcus Noble of the Image Builder project.\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig cluster-lifecycle",
          "date_published": "2024-10-11T18:04:50Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-9594",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-9486",
        "url": "https://github.com/kubernetes/kubernetes/issues/128006",
        "published_at": null,
        "updated_at": null,
        "headline": "VM images built with Image Builder and Proxmox provider use default credentials",
        "content": {
          "excerpt_text": "VM images built with Image Builder and Proxmox provider use default credentials",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/128006"
          ],
          "content_hash": "sha256:aa36e6a97d84cf34c57065189cc6248ac684db9b68326bfde26494459952e404"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "VM images built with Image Builder and Proxmox provider use default credentials",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-9486",
            "issue_number": 128006
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\r\n\r\nA security issue was discovered in the Kubernetes Image Builder where default credentials are enabled during the image build process. Additionally, virtual machine images built using the Proxmox provider do not disable these default credentials, and nodes using the resulting images may be accessible via these default credentials. The credentials can be used to gain root access. Kubernetes clusters are only affected if their nodes use VM images created via the Image Builder project with its Proxmox provider. \r\n\r\n### Am I vulnerable?\r\n\r\nClusters using virtual machine images built with Kubernetes Image Builder (https://github.com/kubernetes-sigs/image-builder) version v0.1.37 or earlier are affected if built with the Proxmox provider.\r\n\r\nVMs using images built with all other providers are not affected by this issue.  See #128007 for a related issue which affects some other providers.\r\n\r\nTo determine the version of Image Builder you are using, use one of the following methods:\r\n- For git clones of the image builder repository:\r\n```\r\n    cd <local path to image builder repo>\r\n    make version\r\n```\r\n- For installations using a tarball download:\r\n```\r\n    cd <local path to install location>\r\n    grep -o v0\\\\.[0-9.]* RELEASE.md | head -1\r\n```\r\n- For a container image release:\r\n    `docker run --rm <image pull spec> version`\r\n  or\r\n    `podman run --rm <image pull spec> version`\r\n  or look at the image tag specified, in the case of an official image such as `registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.37`\r\n\r\n\r\n#### Affected Versions\r\n\r\n- Kubernetes Image Builder versions <= v0.1.37\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nRebuild any affected images using a fixed version of Image Builder. Re-deploy the fixed images to any affected VMs.\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by disabling the builder account on affected VMs:\r\nusermod -L builder\r\n\r\n#### Fixed Versions\r\n\r\n- Kubernetes Image Builder master - fixed by https://github.com/kubernetes-sigs/image-builder/pull/1595\r\n- Fixed in Kubernetes Image Builder release v0.1.38\r\n\r\n### Detection\r\n\r\nThe linux command `last builder` can be used to view logins to the affected `builder` account.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n## Additional Details\r\n\r\nThe fixed version makes two changes to remedy this bug:\r\n- It sets a randomly-generated password for the duration of the image build\r\n- It disables the builder account at the conclusion of the image build\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Nicolai Rybnikar @rybnico from Rybnikar Enterprises GmbH.\r\n\r\nThe issue was fixed and coordinated by Marcus Noble of the Image Builder project.\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig cluster-lifecycle\r\n",
          "date_published": "2024-10-11T18:04:31Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-9486",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-7646",
        "url": "https://github.com/kubernetes/kubernetes/issues/126744",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress-nginx Annotation Validation Bypass",
        "content": {
          "excerpt_text": "Ingress-nginx Annotation Validation Bypass",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126744"
          ],
          "content_hash": "sha256:b684f92d2c9fcf9a3710f917e18d3fd9a93a92e70e739b4a35d335538e29b5d5"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress-nginx Annotation Validation Bypass",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-7646",
            "issue_number": 126744
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)\r\n\r\nA security issue was discovered in ingress-nginx where an actor with permission to create Ingress objects (in the `networking.k8s.io` or `extensions` API group) can bypass annotation validation to inject arbitrary commands and obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** (8.8) [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) and assigned **CVE-2024-7646**.\r\n\r\n### Am I vulnerable?\r\n\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -A` and looking for `ingress-nginx-controller`.\r\n\r\nMulti-tenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n### Affected Versions\r\n\r\ningress-nginx controller < v1.11.2\r\ningress-nginx controller < v1.10.4\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThis issue can be mitigated by upgrading to the fixed version. \r\n\r\n### Fixed Versions\r\n\r\ningress-nginx controller v1.11.2 - fixed by https://github.com/kubernetes/ingress-nginx/pull/11719 and https://github.com/kubernetes/ingress-nginx/pull/11721\r\ningress-nginx controller v1.10.4 - fixed by https://github.com/kubernetes/ingress-nginx/pull/11718 and https://github.com/kubernetes/ingress-nginx/pull/11722\r\n\r\n### Detection\r\n\r\nReview your Kubernetes audit logs for Ingress objects created with annotations (e.g. `nginx.ingress.kubernetes.io/auth-tls-verify-client`) that contain carriage returns (`\\r`).\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\n\r\nSee the GitHub issue for more details: \r\nhttps://github.com/kubernetes/kubernetes/issues/126744 \r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by André Storfjord Kristiansen @dev-bio. \r\n\r\nThe issue was fixed and coordinated by the fix team:\r\nAndré Storfjord Kristiansen @dev-bio\r\nJintao Zhang @tao12345666333\r\nMarco Ebert @Gacko\r\n\r\n/triage accepted\r\n/lifecycle frozen\r\n/area security\r\n/kind bug\r\n/committee security-response",
          "date_published": "2024-08-16T16:10:31Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-7646",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-7598",
        "url": "https://github.com/kubernetes/kubernetes/issues/126587",
        "published_at": null,
        "updated_at": null,
        "headline": "Network restriction bypass via race condition during namespace termination",
        "content": {
          "excerpt_text": "Network restriction bypass via race condition during namespace termination",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126587"
          ],
          "content_hash": "sha256:51b35152a6a2c3c617165aecbccfcd48e0ecba2ac3314608e925e4461158dc1e"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Network restriction bypass via race condition during namespace termination",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-7598",
            "issue_number": 126587
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:A/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:A/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:N) - **Low** (3.1)\n\nA security issue was discovered in Kubernetes where a malicious or compromised pod could bypass network restrictions enforced by network policies during namespace deletion. The order in which objects are deleted during namespace termination is not defined, and it is possible for network policies to be deleted before the pods that they protect.  This can lead to a brief period in which the pods are running and accepting network connections, but the network policies restrictions are not applied.\n\n### Am I vulnerable?\n\nAll clusters that rely on network policies may be vulnerable.  Run the following command to see if network policies are in use:\n\n```\nkubectl get networkpolicies.networking.k8s.io --all-namespaces\n```\n\n#### Affected Versions\n\nkube-apiserver >= v1.3\n\n### How do I mitigate this vulnerability?\n\nThis issue can be mitigated by:\n\n- Manually deleting pods and workload resources that orchestrate pods before starting namespace deletion\n\n- Adding finalizers to network policies to prevent them from being deleted until the pods that they protect have been deleted first. The following proof-of-concept controller automates this process:\n\nhttps://github.com/kubernetes-sigs/network-policy-finalizer \n\n#### Fixed Versions\n\n- None. A longer term comprehensive fix is proposed in the following KEP: https://github.com/kubernetes/enhancements/pull/5095 \n\n### Detection\n\nUsers of network policies may be able to detect abuse via network logs.  The exact details of this process are environment specific.\n\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\n\n#### Acknowledgements\n\nThis vulnerability was reported by John McGuinness @s1xtw03 and Aaron Coffey @aaroncoffey.\n\nThe issue was coordinated by: \n\nAntonio Ojea @aojea\nTim Hockin @thockin\nDan Winship @danwinship\nShane Utt @shaneutt\nDavid Eads @deads2k\nClayton Colemon @smarterclayton\nMo Khan @enj\nCraig Ingram @cji\n\n/label official-cve-feed\n/triage accepted\n/lifecycle frozen\n/area security\n/kind bug\n/committee security-response",
          "date_published": "2024-08-07T21:30:11Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-7598",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-5321",
        "url": "https://github.com/kubernetes/kubernetes/issues/126161",
        "published_at": null,
        "updated_at": null,
        "headline": "Incorrect permissions on Windows containers logs",
        "content": {
          "excerpt_text": "Incorrect permissions on Windows containers logs",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126161"
          ],
          "content_hash": "sha256:b766106212662a2c65c9a7c163dacc739cdeb6db57d084cbf53ff1c1153ba907"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Incorrect permissions on Windows containers logs",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-5321",
            "issue_number": 126161
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:N) - **MEDIUM** (6.1)\r\n\r\nA security issue was discovered in Kubernetes clusters with Windows nodes where `BUILTIN\\Users` may be able to read container logs and `NT AUTHORITY\\Authenticated Users` may be able to modify container logs.\r\n\r\nThis issue has been rated **Medium** ([CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:N)), and assigned **CVE-2024-5321**.\r\n\r\n### Am I vulnerable?\r\n\r\nAny Kubernetes environment with Windows nodes is affected. Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet <= 1.27.15\r\n- kubelet <= 1.28.11\r\n- kubelet <= 1.29.6\r\n- kubelet <= 1.30.2 \r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThis issue can be mitigated by applying the patch provided. The patch includes changes to `pkg/util/filesystem` that set file permissions on Windows and hardens the permissions for container logs for containers running on Windows.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet 1.27.16\r\n- kubelet 1.28.12\r\n- kubelet 1.29.7\r\n- kubelet 1.30.3 \r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/ \r\n\r\n### Detection\r\n\r\nAny Kubernetes environment with Windows nodes is affected. Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Paulo Gomes @pjbgf from SUSE.\r\n\r\nThe issue was fixed and coordinated by the fix team: \r\nMark Rossetti @marosset \r\nJames Sturtevant @jsturtevant \r\nCraig Ingram @cji \r\nRita Zhang @ritazh\r\n\r\nand release managers:\r\nSascha Grunert @saschagrunert\r\nJeremy Rickard @jeremyrickard\r\nCarlos Panato @cpanato\r\nJim Angel @jimangel\r\n\r\n<!-- labels -->\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/sig windows\r\n/area kubelet\r\n/triage accepted\r\n/lifecycle frozen\r\n",
          "date_published": "2024-07-17T13:06:48Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-5321",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-3744",
        "url": "https://github.com/kubernetes/kubernetes/issues/124759",
        "published_at": null,
        "updated_at": null,
        "headline": "azure-file-csi-driver discloses service account tokens in logs",
        "content": {
          "excerpt_text": "azure-file-csi-driver discloses service account tokens in logs",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/124759"
          ],
          "content_hash": "sha256:ea11cf030650c49db0c295a6680f5317562c6b3705ea34a21f6dd68658655669"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "azure-file-csi-driver discloses service account tokens in logs",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-3744",
            "issue_number": 124759
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N) - **MEDIUM** (6.5)\r\n\r\nA security issue was discovered in azure-file-csi-driver where an actor with access to the driver logs could observe service account tokens. These tokens could then potentially be exchanged with external cloud providers to access secrets stored in cloud vault solutions.  Tokens are only logged when [TokenRequests is configured in the CSIDriver object](https://kubernetes-csi.github.io/docs/token-requests.html) and the driver is set to run at log level 2 or greater via the -v flag.\r\n\r\nThis issue has been rated **MEDIUM** [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N) (6.5), and assigned **CVE-2024-3744**\r\n\r\n### Am I vulnerable?\r\n\r\nYou may be vulnerable if [TokenRequests is configured in the CSIDriver object](https://kubernetes-csi.github.io/docs/token-requests.html) and the driver is set to run at log level 2 or greater via the -v flag.\r\n\r\nTo check if token requests are configured, run the following command:\r\n\r\nkubectl get csidriver file.csi.azure.com -o jsonpath=\"{.spec.tokenRequests}\"\r\n\r\nTo check if tokens are being logged, examine the secrets-store container log:\r\n\r\nkubectl logs csi-azurefile-controller-56bfddd689-dh5tk -c azurefile -f | grep --line-buffered \"csi.storage.k8s.io/serviceAccount.tokens\"\r\n\r\n#### Affected Versions\r\n\r\n- azure-file-csi-driver <= v1.29.3\r\n- azure-file-csi-driver v1.30.0\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by running azure-file-csi-driver at log level 0 or 1 via the -v flag.\r\n\r\n#### Fixed Versions\r\n\r\n- azure-file-csi-driver v1.29.4\r\n- azure-file-csi-driver v1.30.1\r\n\r\nTo upgrade, refer to the documentation: https://github.com/kubernetes-sigs/azurefile-csi-driver?tab=readme-ov-file#install-driver-on-a-kubernetes-cluster \r\n\r\n### Detection\r\n\r\nExamine cloud provider logs for unexpected token exchanges, as well as unexpected access to cloud resources.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was patched by Weizhi Chen @cvvz from Microsoft.\r\n\r\nThank You,\r\nRita Zhang on behalf of the Kubernetes Security Response Committee\r\n\r\n/triage accepted\r\n/lifecycle frozen\r\n/area security\r\n/kind bug\r\n/committee security-response",
          "date_published": "2024-05-08T16:02:57Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-3744",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2024-3177",
        "url": "https://github.com/kubernetes/kubernetes/issues/124336",
        "published_at": null,
        "updated_at": null,
        "headline": "Bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
        "content": {
          "excerpt_text": "Bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/124336"
          ],
          "content_hash": "sha256:7e4917ae0384c7fb3c5d27b4f3b609723db3b685bb1eb79189f18bae7aeb7f06"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2024-3177",
            "issue_number": 124336
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:L/I:N/A:N) - **Low** (2.7)\r\n\r\nA security issue was discovered in Kubernetes where users may be able to launch containers that bypass the mountable secrets policy enforced by the ServiceAccount admission plugin when using containers, init containers, and ephemeral containers with the envFrom field populated. The policy ensures pods running with a service account may only reference secrets specified in the service account’s secrets field. Kubernetes clusters are only affected if the ServiceAccount admission plugin and the `kubernetes.io/enforce-mountable-secrets` annotation are used together with containers, init containers, and ephemeral containers with the envFrom field populated. \r\n\r\n### Am I vulnerable?\r\n\r\nThe ServiceAccount admission plugin is used. Most cluster should have this on by default as recommended in  https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#serviceaccount\r\nThe kubernetes.io/enforce-mountable-secrets annotation is used by a service account. This annotation is not added by default. Pods using containers, init containers, and ephemeral containers with the envFrom field populated.\r\n\r\n#### Affected Versions\r\n\r\nkube-apiserver v1.29.0 - v1.29.3\r\nkube-apiserver v1.28.0 - v1.28.8\r\nkube-apiserver <= v1.27.12\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThis issue can be mitigated by applying the patch provided for the kube-apiserver component. The patch prevents containers, init containers, and ephemeral containers with the envFrom field populated from bypassing the mountable secrets policy enforced by the ServiceAccount admission plugin.\r\n\r\nOutside of applying the provided patch, there are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kube-apiserver master - fixed by #124322\r\n- kube-apiserver v1.29.4 - fixed by #124325\r\n- kube-apiserver v1.28.9 - fixed by #124326\r\n- kube-apiserver v1.27.13 - fixed by #124327\r\n\r\nTo upgrade, refer to the documentation:\r\nhttps://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/ \r\n\r\n### Detection\r\n\r\nPod update requests using a container, init container, or ephemeral container with the envFrom field populated that exploits this vulnerability with unintended secret will be captured in API audit logs. You can also use the following kubectl command to find active pods using the `kubernetes.io/enforce-mountable-secrets` annotation. \r\n\r\n`kubectl get serviceaccounts --all-namespaces -o jsonpath=\"{range .items[?(@.metadata.annotations['kubernetes\\.io/enforce-mountable-secrets']=='true')]}{.metadata.namespace}{'\\t'}{.metadata.name}{'\\n'}{end}\"` \r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by tha3e1vl. \r\n\r\nThe issue was fixed and coordinated by the fix team: \r\n\r\nRita Zhang @ritazh\r\nJoel Smith @joelsmith\r\nMo Khan @enj\r\n\r\nand release managers:\r\nSascha Grunert @saschagrunert\r\nJeremy Rickard @jeremyrickard\r\n\r\n/triage accepted\r\n/lifecycle frozen\r\n/area security\r\n/kind bug\r\n/committee security-response",
          "date_published": "2024-04-16T14:04:09Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2024-3177",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-5528",
        "url": "https://github.com/kubernetes/kubernetes/issues/121879",
        "published_at": null,
        "updated_at": null,
        "headline": "Insufficient input sanitization in in-tree storage plugin leads to privilege escalation on Windows nodes",
        "content": {
          "excerpt_text": "Insufficient input sanitization in in-tree storage plugin leads to privilege escalation on Windows nodes",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/121879"
          ],
          "content_hash": "sha256:282cc27a123bb35ddf1f19d6c8b4a68263fdf80d956b67266411a09e1e4f4e5c"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Insufficient input sanitization in in-tree storage plugin leads to privilege escalation on Windows nodes",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-5528",
            "issue_number": 121879
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H) - **HIGH** (7.2)\r\n\r\nA security issue was discovered in Kubernetes where a user that can create pods and persistent volumes on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they are using an in-tree storage plugin for Windows nodes.\r\n\r\n### Am I vulnerable?\r\n\r\nAny kubernetes environment with Windows nodes is impacted.  Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet >= v1.8.0 (including all later minor versions)\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThe provided patch fully mitigates the vulnerability.\r\n\r\nOutside of applying the provided patch, there are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet master - fixed by #121881\r\n- kubelet v1.28.4 - fixed by #121882\r\n- kubelet v1.27.8 - fixed by #121883\r\n- kubelet v1.26.11 - fixed by #121884\r\n- kubelet v1.25.16 - fixed by #121885\r\n\r\nTo upgrade, refer to the documentation:\r\nhttps://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Detection\r\n\r\nKubernetes audit logs can be used to detect if this vulnerability is being exploited. Persistent Volume create events with local path fields containing special characters are a strong indication of exploitation.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Tomer Peled [@tomerpeled92](https://github.com/tomerpeled92)\r\n\r\nThe issue was fixed and coordinated by the fix team: \r\n\r\nJames Sturtevant @jsturtevant\r\nMark Rossetti @marosset\r\nMichelle Au @msau42 \r\nJan Šafránek @jsafrane \r\nMo Khan @enj \r\nRita Zhang @ritazh\r\nMicah Hausler @micahhausler\r\nSri Saran Balaji @SaranBalaji90\r\nCraig Ingram @cji \r\n\r\nand release managers:\r\nJeremy Rickard @jeremyrickard\r\nMarko Mudrinić @xmudrii \r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig windows\r\n/sig storage\r\n/area kubelet",
          "date_published": "2023-11-14T15:54:16Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-5528",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-5044",
        "url": "https://github.com/kubernetes/kubernetes/issues/126817",
        "published_at": null,
        "updated_at": null,
        "headline": "Code injection via nginx.ingress.kubernetes.io/permanent-redirect annotation",
        "content": {
          "excerpt_text": "Code injection via nginx.ingress.kubernetes.io/permanent-redirect annotation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126817"
          ],
          "content_hash": "sha256:328559fa319aa452a6cd239a0448bc4abb3b68d46f33e85844e7fd6114314256"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Code injection via nginx.ingress.kubernetes.io/permanent-redirect annotation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-5044",
            "issue_number": 126817
          },
          "content_text": "### Issue Details\r\nA security issue was identified in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the nginx.ingress.kubernetes.io/permanent-redirect annotation on an Ingress object (in the `networking.k8s.io` or `extensions` API group) can be used to inject arbitrary commands, and obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned **CVE-2023-5044**.\r\n\r\n### Affected Components and Configurations\r\n\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nIf you are running the “chrooted” ingress-nginx controller introduced in v1.2.0 (gcr.io/k8s-staging-ingress-nginx/controller-chroot), command execution is possible but credential extraction is not, so the High severity does not apply.\r\n\r\nMulti-tenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n\r\n- <v1.9.0\r\n\r\n#### Versions allowing mitigation\r\n\r\n- v1.9.0\r\n\r\n### Mitigation\r\n\r\nIngress Administrators should set the --enable-annotation-validation flag to enforce restrictions on the contents of ingress-nginx annotation fields.\r\n\r\n### Detection\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\n\r\nSee ingress-nginx Issue [#10572](https://github.com/kubernetes/kubernetes/issues/126817) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Jan-Otto Kröpke (Cloudeteer GmbH)\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2023-10-25T15:48:28Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-5044",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-5043",
        "url": "https://github.com/kubernetes/kubernetes/issues/126816",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress nginx annotation injection causes arbitrary command execution",
        "content": {
          "excerpt_text": "Ingress nginx annotation injection causes arbitrary command execution",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126816"
          ],
          "content_hash": "sha256:53bdb207cb8412108a569084a63cc74776ced5e5af619fd0c59c507d41ae1e29"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress nginx annotation injection causes arbitrary command execution",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-5043",
            "issue_number": 126816
          },
          "content_text": "### Issue Details\r\n\r\nA security issue was identified in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where the nginx.ingress.kubernetes.io/configuration-snippet annotation on an Ingress object (in the `networking.k8s.io` or `extensions` API group) can be used to inject arbitrary commands, and obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned **CVE-2023-5043**.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nIf you are running the “chrooted” ingress-nginx controller introduced in v1.2.0 (gcr.io/k8s-staging-ingress-nginx/controller-chroot), command execution is possible but credential extraction is not, so the High severity does not apply.\r\n\r\nMulti-tenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n\r\n- <v1.9.0\r\n\r\n#### Versions allowing mitigation\r\n\r\n- v1.9.0\r\n\r\n### Mitigation\r\nIngress Administrators should set the --enable-annotation-validation flag to enforce restrictions on the contents of ingress-nginx annotation fields.\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\nSee ingress-nginx Issue[ kubernetes/kubernetes#126816](https://github.com/kubernetes/kubernetes/issues/126816) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by suanve\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2023-10-25T15:48:20Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-5043",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2022-4886",
        "url": "https://github.com/kubernetes/kubernetes/issues/126815",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx path sanitization can be bypassed",
        "content": {
          "excerpt_text": "ingress-nginx path sanitization can be bypassed",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126815"
          ],
          "content_hash": "sha256:bc551f857bc8691b4c8cdb167007e7c05731e5a317339a75496ab164238aa1ab"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx path sanitization can be bypassed",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2022-4886",
            "issue_number": 126815
          },
          "content_text": "### Issue Details\r\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where a user that can create or update ingress objects can use directives to bypass the sanitization of the `spec.rules[].http.paths[].path` field of an Ingress object (in the `networking.k8s.io` or `extensions` API group) to obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)), and assigned CVE-2022-4886.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nIf you are running the “chrooted” ingress-nginx controller introduced in v1.2.0 (gcr.io/k8s-staging-ingress-nginx/controller-chroot), command execution is possible but credential extraction is not, so the High severity does not apply.\r\n\r\nMulti-tenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n\r\n- <v1.8.0\r\n\r\n#### Versions allowing mitigation\r\n\r\n- v1.8.0\r\n\r\n### Mitigation\r\nIngress objects contain a field called pathType that defines the proxy behavior. It can be Exact, Prefix and ImplementationSpecific.\r\n\r\nWhen pathType is configured as Exact or Prefix, there is more strict validation, allowing only paths starting with \"/\" and containing only alphanumeric characters and \"-\", \"_\" and additional \"/\".\r\n\r\nWhen this option is enabled, the validation happens in the Admission Webhook, denying creation of any Ingress containing invalid characters (unless pathType is ImplementationSpecific).\r\n\r\nhttps://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#strict-validate-path-type\r\n\r\nIngress Admins should enable this validation by default. If you still need to allow implementation specific paths due to the usage of features like Regex/rewrite on path, we recommend implementing countermeasures to allow just trusted users to consume this feature, as an example with OPA: https://kubernetes.github.io/ingress-nginx/examples/openpolicyagent/\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\nSee ingress-nginx Issue [#10570](https://github.com/kubernetes/kubernetes/issues/126815) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Ginoah, working with the DEVCORE Internship Program.\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2023-10-25T15:48:08Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2022-4886",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-3955",
        "url": "https://github.com/kubernetes/kubernetes/issues/119595",
        "published_at": null,
        "updated_at": null,
        "headline": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
        "content": {
          "excerpt_text": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/119595"
          ],
          "content_hash": "sha256:432e09d3f10ba51870691f4385a310ce2629e1a7b648610252718e87dbb8a997"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-3955",
            "issue_number": 119595
          },
          "content_text": "CVSS Rating: [CVSS:3.1/av:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) - **HIGH** (8.8)\r\n\r\nA security issue was discovered in Kubernetes where a user that can create pods on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they include Windows nodes.\r\n\r\n### Am I vulnerable?\r\n\r\nAny kubernetes environment with Windows nodes is impacted.  Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet <= v1.28.0\r\n- kubelet <= v1.27.4\r\n- kubelet <= v1.26.7\r\n- kubelet <= v1.25.12\r\n- kubelet <= v1.24.16\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThe provided patch fully mitigates the vulnerability (see fix impact below).  Full mitigation for this class of issues requires patches applied for CVE-2023-3676, CVE-2023-3955, and CVE-2023-3893.\r\n\r\nOutside of applying the provided patch, there are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet master - fixed by #120128\r\n- kubelet v1.28.1 - fixed by #120134\r\n- kubelet v1.27.5 - fixed by #120135\r\n- kubelet v1.26.8 - fixed by #120136\r\n- kubelet v1.25.13 - fixed by #120137\r\n- kubelet v1.24.17 - fixed by #120138\r\n\r\n**Fix impact:** Passing Windows Powershell disk format options to in-tree volume plugins will result in an error during volume provisioning on the node.  There are no known use cases for this functionality, nor is this functionality supported by any known out-of-tree CSI driver.\r\n\r\nTo upgrade, refer to the documentation:\r\nhttps://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/\r\n\r\n### Detection\r\n\r\nKubernetes audit logs can be used to detect if this vulnerability is being exploited. Pod create events with embedded powershell commands are a strong indication of exploitation.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was discovered by James Sturtevant @jsturtevant and Mark Rossetti @marosset during the process of fixing CVE-2023-3676 (that original CVE was reported by Tomer Peled @tomerpeled92)\r\n\r\nThe issue was fixed and coordinated by the fix team: \r\n\r\nJames Sturtevant @jsturtevant\r\nMark Rossetti @marosset\r\nAndy Zhang @andyzhangx\r\nJustin Terry @jterry75\r\nKulwant Singh @KlwntSingh\r\nMicah Hausler @micahhausler\r\nRita Zhang @ritazh\r\n\r\nand release managers:\r\n\r\nJeremy Rickard @jeremyrickard",
          "date_published": "2023-07-26T15:30:50Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-3955",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-3893",
        "url": "https://github.com/kubernetes/kubernetes/issues/119594",
        "published_at": null,
        "updated_at": null,
        "headline": "Insufficient input sanitization on kubernetes-csi-proxy leads to privilege escalation",
        "content": {
          "excerpt_text": "Insufficient input sanitization on kubernetes-csi-proxy leads to privilege escalation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/119594"
          ],
          "content_hash": "sha256:ecb6be9f89f12b5a9f00dabf417e179c861d2fa915c44d3d23c15215baf4e8e1"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Insufficient input sanitization on kubernetes-csi-proxy leads to privilege escalation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-3893",
            "issue_number": 119594
          },
          "content_text": "CVSS Rating: [CVSS:3.1/av:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) - **HIGH** (8.8)\r\n\r\nA security issue was discovered in Kubernetes where a user that can create pods on Windows nodes running kubernetes-csi-proxy may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they include Windows nodes running kubernetes-csi-proxy.\r\n\r\n### Am I vulnerable?\r\n\r\nAny kubernetes environment with Windows nodes that are running kubernetes-csi-proxy is impacted.  This is a common default configuration on Windows nodes.  Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\n#### Affected Versions\r\n\r\n- kubernetes-csi-proxy <= v2.0.0-alpha.0\r\n- kubernetes-csi-proxy <= v1.1.2\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThe provided patch fully mitigates the vulnerability and has no known side effects.  Full mitigation for this class of issues requires patches applied for CVE-2023-3676, CVE-2023-3955, and CVE-2023-3893.\r\n\r\nOutside of applying the provided patch, there are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kubernetes-csi-proxy master - fixed by https://github.com/kubernetes-csi/csi-proxy/pull/306\r\n- kubernetes-csi-proxy v2.0.0-alpha.1 - fixed by https://github.com/kubernetes-csi/csi-proxy/pull/307\r\n- kubernetes-csi-proxy v1.1.3 - fixed by https://github.com/kubernetes-csi/csi-proxy/pull/306\r\n\r\nTo upgrade: cordon the node, stop the associated Windows service, replace the csi-proxy.exe binary, restart the associated Windows service, and un-cordon the node.  See the installation docs for more details: https://github.com/kubernetes-csi/csi-proxy#installation\r\n\r\nIf a Windows host process daemon set is used to run kubernetes-csi-proxy such as https://github.com/kubernetes-csi/csi-driver-smb/blob/master/charts/latest/csi-driver-smb/templates/csi-proxy-windows.yaml, simply upgrade the image to a fixed version such as ghcr.io/kubernetes-sigs/sig-windows/csi-proxy:v1.1.3\r\n\r\n### Detection\r\n\r\nKubernetes audit logs can be used to detect if this vulnerability is being exploited. Pod create events with embedded powershell commands are a strong indication of exploitation.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was discovered by James Sturtevant @jsturtevant and Mark Rossetti @marosset during the process of fixing CVE-2023-3676 (that original CVE was reported by Tomer Peled @tomerpeled92)\r\n\r\nThe issue was fixed and coordinated by the fix team: \r\n\r\nJames Sturtevant @jsturtevant\r\nMark Rossetti @marosset\r\nAndy Zhang @andyzhangx\r\nJustin Terry @jterry75\r\nKulwant Singh @KlwntSingh\r\nMicah Hausler @micahhausler\r\nRita Zhang @ritazh\r\n\r\nand release managers:\r\n\r\nMauricio Poppe @mauriciopoppe",
          "date_published": "2023-07-26T15:30:26Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-3893",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-3676",
        "url": "https://github.com/kubernetes/kubernetes/issues/119339",
        "published_at": null,
        "updated_at": null,
        "headline": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
        "content": {
          "excerpt_text": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/119339"
          ],
          "content_hash": "sha256:a503a3db2e09b66153da934de10551249b7b97f6bc0ceb3165cecc1eefc83a2f"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Insufficient input sanitization on Windows nodes leads to privilege escalation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-3676",
            "issue_number": 119339
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H) - **HIGH** (8.8)\r\n\r\nA security issue was discovered in Kubernetes where a user that can create pods on Windows nodes may be able to escalate to admin privileges on those nodes. Kubernetes clusters are only affected if they include Windows nodes.\r\n\r\n### Am I vulnerable?\r\n\r\nAny kubernetes environment with Windows nodes is impacted.  Run `kubectl get nodes -l kubernetes.io/os=windows` to see if any Windows nodes are in use.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet <= v1.28.0\r\n- kubelet <= v1.27.4\r\n- kubelet <= v1.26.7\r\n- kubelet <= v1.25.12\r\n- kubelet <= v1.24.16\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThe provided patch fully mitigates the vulnerability and has no known side effects.  Full mitigation for this class of issues requires patches applied for CVE-2023-3676, CVE-2023-3955, and CVE-2023-3893.\r\n\r\nOutside of applying the provided patch, there are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet master - fixed by #120127\r\n- kubelet v1.28.1 - fixed by #120129\r\n- kubelet v1.27.5 - fixed by #120130\r\n- kubelet v1.26.8 - fixed by #120131\r\n- kubelet v1.25.13 - fixed by #120132\r\n- kubelet v1.24.17 - fixed by #120133\r\n\r\nTo upgrade, refer to the documentation:\r\nhttps://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/\r\n\r\n### Detection\r\n\r\nKubernetes audit logs can be used to detect if this vulnerability is being exploited. Pod create events with embedded powershell commands are a strong indication of exploitation. Config maps and secrets that contain embedded powershell commands and are mounted into pods are also a strong indication of exploitation.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Tomer Peled @tomerpeled92\r\n\r\nThe issue was fixed and coordinated by the fix team: \r\n\r\nJames Sturtevant @jsturtevant\r\nMark Rossetti @marosset\r\nAndy Zhang @andyzhangx\r\nJustin Terry @jterry75\r\nKulwant Singh @KlwntSingh\r\nMicah Hausler @micahhausler\r\nRita Zhang @ritazh\r\n\r\nand release managers:\r\n\r\nJeremy Rickard @jeremyrickard\r\n\r\n\r\n/triage accepted\r\n/lifecycle frozen\r\n/area security\r\n/kind bug\r\n/committee security-response",
          "date_published": "2023-07-14T18:27:48Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-3676",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-2431",
        "url": "https://github.com/kubernetes/kubernetes/issues/118690",
        "published_at": null,
        "updated_at": null,
        "headline": "Bypass of seccomp profile enforcement",
        "content": {
          "excerpt_text": "Bypass of seccomp profile enforcement",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/118690"
          ],
          "content_hash": "sha256:69a87b8b4dc658ffe18b91cd3513543bb941341942c221223c142037113a8f37"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bypass of seccomp profile enforcement",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-2431",
            "issue_number": 118690
          },
          "content_text": "### What happened?\r\n\r\nA security issue was discovered in Kubelet that allows pods to bypass the seccomp profile enforcement. This issue has been rated LOW ([CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:L/I:L/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:L/I:L/A:N)) (score: 3.4).\r\n\r\nIf you have pods in your cluster that use [localhost type](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#seccompprofile-v1-core) for seccomp profile but specify an empty profile field, then you are affected by this issue. In this scenario, this vulnerability allows the pod to run in “unconfined” (seccomp disabled) mode. This bug affects Kubelet.\r\n\r\n### How can we reproduce it (as minimally and precisely as possible)?\r\n\r\nThis can be reproduced by creating a pod with following sample seccomp Localhost profile - \r\n\r\n```\r\n          localhostProfile: \"\"\r\n```\r\n\r\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.27/#seccompprofile-v1-core\r\n\r\n### Kubernetes version\r\n\r\n**Affected Versions**\r\nv1.27.0 - v1.27.1\r\nv1.26.0 - v1.26.4\r\nv1.25.0 - v1.25.9\r\n<= v1.24.13\r\n\r\n**Fixed Versions**\r\nv1.27.2\r\nv1.26.5\r\nv1.25.10\r\nV1.24.14\r\n\r\n### Anything else we need to know?\r\n\r\nHow do I remediate this vulnerability?\r\nTo remediate this vulnerability you should upgrade your Kubelet to one of the below mentioned versions.\r\n\r\nAcknowledgements\r\nThis vulnerability was reported by Tim Allclair, and fixed by Craig Ingram.",
          "date_published": "2023-06-15T14:42:32Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-2431",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-2728",
        "url": "https://github.com/kubernetes/kubernetes/issues/118640",
        "published_at": null,
        "updated_at": null,
        "headline": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
        "content": {
          "excerpt_text": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/118640"
          ],
          "content_hash": "sha256:630f6d16585375f9594f0a99ecdfc0303f69e0769b9a043d0dfb0fecaa3f0372"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-2728",
            "issue_number": 118640
          },
          "content_text": "### CVE-2023-2727: Bypassing policies imposed by the ImagePolicyWebhook admission plugin\r\nCVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N)\r\n\r\nA security issue was discovered in Kubernetes where users may be able to launch containers using images that are restricted by ImagePolicyWebhook when using ephemeral containers. Kubernetes clusters are only affected if the ImagePolicyWebhook admission plugin is used together with ephemeral containers.\r\n\r\n### Am I vulnerable?\r\nClusters are impacted by this vulnerability if all of the following are true:\r\n\r\n1. The ImagePolicyWebhook admission plugin is used to restrict use of certain images\r\n2. Pods are using ephemeral containers.\r\n\r\n### Affected Versions\r\n\r\n- kube-apiserver v1.27.0 - v1.27.2\r\n- kube-apiserver v1.26.0 - v1.26.5\r\n- kube-apiserver v1.25.0 - v1.25.10\r\n- kube-apiserver <= v1.24.14\r\n\r\n### How do I mitigate this vulnerability?\r\nThis issue can be mitigated by applying the patch provided for the kube-apiserver component. This patch prevents ephemeral containers from using an image that is restricted by ImagePolicyWebhook. \r\n\r\nNote: Validation webhooks (such as [Gatekeeper](https://open-policy-agent.github.io/gatekeeper-library/website/validation/allowedrepos/) and [Kyverno](https://kyverno.io/policies/other/allowed-image-repos/allowed-image-repos/)) can also be used to enforce the same restrictions.\r\n\r\n### Fixed Versions\r\n\r\n- kube-apiserver v1.27.3\r\n- kube-apiserver v1.26.6\r\n- kube-apiserver v1.25.11\r\n- kube-apiserver v1.24.15\r\n\r\n### Detection\r\nPod update requests using an ephemeral container with an image that should have been restricted by an ImagePolicyWebhook will be captured in API audit logs. You can also use `kubectl get pods` to find active pods with ephemeral containers running an image that should have been restricted in your cluster with this issue.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Stanislav Láznička, and fixed by Rita Zhang.\r\n\r\n### CVE-2023-2728: Bypassing enforce mountable secrets policy imposed by the ServiceAccount admission plugin\r\nCVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N)\r\n\r\nA security issue was discovered in Kubernetes where users may be able to launch containers that bypass the mountable secrets policy enforced by the ServiceAccount admission plugin when using ephemeral containers. The policy ensures pods running with a service account may only reference secrets specified in the service account’s secrets field. Kubernetes clusters are only affected if the ServiceAccount admission plugin and the `kubernetes.io/enforce-mountable-secrets` annotation are used together with ephemeral containers.\r\n\r\n### Am I vulnerable?\r\nClusters are impacted by this vulnerability if all of the following are true:\r\n\r\n1. The ServiceAccount admission plugin is used. Most cluster should have this on by default as recommended in [https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#serviceaccount](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#serviceaccount)\r\n2. The `kubernetes.io/enforce-mountable-secrets` annotation is used by a service account. This annotation is not added by default.\r\n3. Pods are using ephemeral containers.\r\n\r\n### Affected Versions\r\n\r\n- kube-apiserver v1.27.0 - v1.27.2\r\n- kube-apiserver v1.26.0 - v1.26.5\r\n- kube-apiserver v1.25.0 - v1.25.10\r\n- kube-apiserver <= v1.24.14\r\n\r\n### How do I mitigate this vulnerability?\r\nThis issue can be mitigated by applying the patch provided for the kube-apiserver component. The patch prevents ephemeral containers from bypassing the mountable secrets policy enforced by the ServiceAccount admission plugin.\r\n\r\n### Fixed Versions\r\n- kube-apiserver v1.27.3\r\n- kube-apiserver v1.26.6\r\n- kube-apiserver v1.25.11\r\n- kube-apiserver v1.24.15\r\n\r\n### Detection\r\nPod update requests using an ephemeral container that exploits this vulnerability with unintended secret will be captured in API audit logs. You can also use kubectl get pods to find active pods with ephemeral containers running with a secret that is not referenced by the service account in your cluster.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Rita Zhang, and fixed by Rita Zhang.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig auth\r\n/area apiserver\r\n",
          "date_published": "2023-06-13T14:42:06Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-2728",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-2727",
        "url": "https://github.com/kubernetes/kubernetes/issues/118640",
        "published_at": null,
        "updated_at": null,
        "headline": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
        "content": {
          "excerpt_text": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/118640"
          ],
          "content_hash": "sha256:630f6d16585375f9594f0a99ecdfc0303f69e0769b9a043d0dfb0fecaa3f0372"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bypassing policies imposed by the ImagePolicyWebhook and bypassing mountable secrets policy imposed by the ServiceAccount admission plugin",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-2727",
            "issue_number": 118640
          },
          "content_text": "### CVE-2023-2727: Bypassing policies imposed by the ImagePolicyWebhook admission plugin\r\nCVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N)\r\n\r\nA security issue was discovered in Kubernetes where users may be able to launch containers using images that are restricted by ImagePolicyWebhook when using ephemeral containers. Kubernetes clusters are only affected if the ImagePolicyWebhook admission plugin is used together with ephemeral containers.\r\n\r\n### Am I vulnerable?\r\nClusters are impacted by this vulnerability if all of the following are true:\r\n\r\n1. The ImagePolicyWebhook admission plugin is used to restrict use of certain images\r\n2. Pods are using ephemeral containers.\r\n\r\n### Affected Versions\r\n\r\n- kube-apiserver v1.27.0 - v1.27.2\r\n- kube-apiserver v1.26.0 - v1.26.5\r\n- kube-apiserver v1.25.0 - v1.25.10\r\n- kube-apiserver <= v1.24.14\r\n\r\n### How do I mitigate this vulnerability?\r\nThis issue can be mitigated by applying the patch provided for the kube-apiserver component. This patch prevents ephemeral containers from using an image that is restricted by ImagePolicyWebhook. \r\n\r\nNote: Validation webhooks (such as [Gatekeeper](https://open-policy-agent.github.io/gatekeeper-library/website/validation/allowedrepos/) and [Kyverno](https://kyverno.io/policies/other/allowed-image-repos/allowed-image-repos/)) can also be used to enforce the same restrictions.\r\n\r\n### Fixed Versions\r\n\r\n- kube-apiserver v1.27.3\r\n- kube-apiserver v1.26.6\r\n- kube-apiserver v1.25.11\r\n- kube-apiserver v1.24.15\r\n\r\n### Detection\r\nPod update requests using an ephemeral container with an image that should have been restricted by an ImagePolicyWebhook will be captured in API audit logs. You can also use `kubectl get pods` to find active pods with ephemeral containers running an image that should have been restricted in your cluster with this issue.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Stanislav Láznička, and fixed by Rita Zhang.\r\n\r\n### CVE-2023-2728: Bypassing enforce mountable secrets policy imposed by the ServiceAccount admission plugin\r\nCVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:N)\r\n\r\nA security issue was discovered in Kubernetes where users may be able to launch containers that bypass the mountable secrets policy enforced by the ServiceAccount admission plugin when using ephemeral containers. The policy ensures pods running with a service account may only reference secrets specified in the service account’s secrets field. Kubernetes clusters are only affected if the ServiceAccount admission plugin and the `kubernetes.io/enforce-mountable-secrets` annotation are used together with ephemeral containers.\r\n\r\n### Am I vulnerable?\r\nClusters are impacted by this vulnerability if all of the following are true:\r\n\r\n1. The ServiceAccount admission plugin is used. Most cluster should have this on by default as recommended in [https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#serviceaccount](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#serviceaccount)\r\n2. The `kubernetes.io/enforce-mountable-secrets` annotation is used by a service account. This annotation is not added by default.\r\n3. Pods are using ephemeral containers.\r\n\r\n### Affected Versions\r\n\r\n- kube-apiserver v1.27.0 - v1.27.2\r\n- kube-apiserver v1.26.0 - v1.26.5\r\n- kube-apiserver v1.25.0 - v1.25.10\r\n- kube-apiserver <= v1.24.14\r\n\r\n### How do I mitigate this vulnerability?\r\nThis issue can be mitigated by applying the patch provided for the kube-apiserver component. The patch prevents ephemeral containers from bypassing the mountable secrets policy enforced by the ServiceAccount admission plugin.\r\n\r\n### Fixed Versions\r\n- kube-apiserver v1.27.3\r\n- kube-apiserver v1.26.6\r\n- kube-apiserver v1.25.11\r\n- kube-apiserver v1.24.15\r\n\r\n### Detection\r\nPod update requests using an ephemeral container that exploits this vulnerability with unintended secret will be captured in API audit logs. You can also use kubectl get pods to find active pods with ephemeral containers running with a secret that is not referenced by the service account in your cluster.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Rita Zhang, and fixed by Rita Zhang.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig auth\r\n/area apiserver\r\n",
          "date_published": "2023-06-13T14:42:06Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-2727",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2023-2878",
        "url": "https://github.com/kubernetes/kubernetes/issues/118419",
        "published_at": null,
        "updated_at": null,
        "headline": "secrets-store-csi-driver discloses service account tokens in logs",
        "content": {
          "excerpt_text": "secrets-store-csi-driver discloses service account tokens in logs",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/118419"
          ],
          "content_hash": "sha256:57438115dffbfb03db78bbe69d2411cf3e3162827942d7ec0055a2607e897a20"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "secrets-store-csi-driver discloses service account tokens in logs",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2023-2878",
            "issue_number": 118419
          },
          "content_text": "A security issue was discovered in [secrets-store-csi-driver](https://github.com/kubernetes-sigs/secrets-store-csi-driver) where an actor with access to the driver logs could observe service account tokens. These tokens could then potentially be exchanged with external cloud providers to access secrets stored in cloud vault solutions. Tokens are only logged when [TokenRequests is configured in the CSIDriver object](https://kubernetes-csi.github.io/docs/token-requests.html) and the driver is set to run at log level 2 or greater via the -v flag.\r\n\r\nThis issue has been rated **MEDIUM** [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:C/C:H/I:N/A:N) (6.5), and assigned **CVE-2023-2878**\r\n\r\n**Am I vulnerable?**\r\n\r\nYou may be vulnerable if [TokenRequests is configured in the CSIDriver object](https://kubernetes-csi.github.io/docs/token-requests.html) and the driver is set to run at log level 2 or greater via the -v flag.\r\n\r\nTo check if token requests are configured, run the following command:\r\n\r\n```shell\r\nkubectl get csidriver secrets-store.csi.k8s.io -o jsonpath=\"{.spec.tokenRequests}\"\r\n```\r\n\r\nTo check if tokens are being logged, examine the secrets-store container log:\r\n\r\n```shell\r\nkubectl logs -l app=secrets-store-csi-driver -c secrets-store -f | grep --line-buffered \"csi.storage.k8s.io/serviceAccount.tokens\"\r\n```\r\n\r\n**Affected Versions**\r\n\r\n- secrets-store-csi-driver < 1.3.3\r\n\r\n**How do I mitigate this vulnerability?**\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by running secrets-store-csi-driver at log level 0 or 1 via the -v flag.\r\n\r\n**Fixed Versions**\r\n\r\n- secrets-store-csi-driver >= 1.3.3\r\n\r\nTo upgrade, refer to the documentation: [https://secrets-store-csi-driver.sigs.k8s.io/getting-started/upgrades.html#upgrades](https://secrets-store-csi-driver.sigs.k8s.io/getting-started/upgrades.html#upgrades)\r\n\r\n**Detection**\r\n\r\nExamine cloud provider logs for unexpected token exchanges, as well as unexpected access to cloud vault secrets.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n**Acknowledgements**\r\n\r\nThis vulnerability was reported by Tomer Shaiman `@tshaiman` from Microsoft.\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig auth",
          "date_published": "2023-06-02T19:03:54Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2023-2878",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2022-3294",
        "url": "https://github.com/kubernetes/kubernetes/issues/113757",
        "published_at": null,
        "updated_at": null,
        "headline": "Node address isn't always verified when proxying",
        "content": {
          "excerpt_text": "Node address isn't always verified when proxying",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/113757"
          ],
          "content_hash": "sha256:0fdc00958d5c656274eae14d8bfc145665dc9bdf20e14748a973b79d0c44d1ad"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Node address isn't always verified when proxying",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2022-3294",
            "issue_number": 113757
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:H/I:H/A:H)\r\n\r\nA security issue was discovered in Kubernetes where users may have access to secure endpoints in the control plane network. Kubernetes clusters are only affected if an untrusted user can modify Node objects and send proxy requests to them.\r\n\r\nKubernetes supports node proxying, which allows clients of kube-apiserver to access endpoints of a Kubelet to establish connections to Pods, retrieve container logs, and more. While Kubernetes already validates the proxying address for Nodes, a bug in kube-apiserver made it possible to bypass this validation. Bypassing this validation could allow authenticated requests destined for Nodes to to the API server's private network.\r\n\r\n### Am I vulnerable?\r\n\r\nClusters are affected by this vulnerability if there are endpoints that the kube-apiserver has connectivity to that users should not be able to access. This includes:\r\n\r\n- kube-apiserver is in a separate network from worker nodes\r\n- localhost services\r\n\r\nmTLS services that accept the same client certificate as nodes may be affected. The severity of this issue depends on the privileges & sensitivity of the exploitable endpoints.\r\n\r\nClusters that configure the egress selector to use a proxy for cluster traffic may not be affected.\r\n\r\n\r\n#### Affected Versions\r\n\r\n- Kubernetes kube-apiserver <= v1.25.3\r\n- Kubernetes kube-apiserver <= v1.24.7\r\n- Kubernetes kube-apiserver <= v1.23.13\r\n- Kubernetes kube-apiserver <= v1.22.15\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nUpgrading the **kube-apiserver** to a fixed version mitigates this vulnerability.\r\n\r\nAside from upgrading, configuring an [egress proxy for egress to the cluster network](https://kubernetes.io/docs/tasks/extend-kubernetes/setup-konnectivity/) can mitigate this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- Kubernetes kube-apiserver v1.25.4\r\n- Kubernetes kube-apiserver v1.24.8\r\n- Kubernetes kube-apiserver v1.23.14\r\n- Kubernetes kube-apiserver v1.22.16\r\n\r\n**Fix impact:** In some cases, the fix can break clients that depend on the nodes/proxy subresource, specifically if a kubelet advertises a localhost or link-local address to the Kubernetes control plane.\r\n\r\n### Detection\r\n\r\nNode create & update requests may be included in the Kubernetes audit log, and can be used to identify requests for IP addresses that should not be permitted. Node proxy requests may also be included in audit logs.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Yuval Avrahami of Palo Alto Networks.\r\n\r\n<!-- labels -->\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig api-machinery\r\n/area apiserver",
          "date_published": "2022-11-08T21:33:26Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2022-3294",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2022-3162",
        "url": "https://github.com/kubernetes/kubernetes/issues/113756",
        "published_at": null,
        "updated_at": null,
        "headline": "Unauthorized read of Custom Resources",
        "content": {
          "excerpt_text": "Unauthorized read of Custom Resources",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/113756"
          ],
          "content_hash": "sha256:8663b9c93e485193adc415d163b016bf6053f0be0cd336e2acb79f57566ff804"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Unauthorized read of Custom Resources",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2022-3162",
            "issue_number": 113756
          },
          "content_text": "CVSS Rating: [CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N)\r\n\r\nA security issue was discovered in Kubernetes where users authorized to list or watch one type of namespaced custom resource cluster-wide can read custom resources of a different type in the same API group without authorization.\r\n\r\n### Am I vulnerable?\r\n\r\nClusters are impacted by this vulnerability if all of the following are true:\r\n- There are 2+ CustomResourceDefinitions sharing the same API group\r\n- Users have cluster-wide list or watch authorization on one of those custom resources.\r\n- The same users are not authorized to read another custom resource in the same API group.\r\n\r\n#### Affected Versions\r\n\r\n- Kubernetes kube-apiserver <= v1.25.3\r\n- Kubernetes kube-apiserver <= v1.24.7\r\n- Kubernetes kube-apiserver <= v1.23.13\r\n- Kubernetes kube-apiserver <= v1.22.15\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nUpgrading the kube-apiserver to a fixed version mitigates this vulnerability.\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by avoiding granting cluster-wide list and watch permissions.\r\n\r\n#### Fixed Versions\r\n\r\n- Kubernetes kube-apiserver v1.25.4\r\n- Kubernetes kube-apiserver v1.24.8\r\n- Kubernetes kube-apiserver v1.23.14\r\n- Kubernetes kube-apiserver v1.22.16\r\n\r\n### Detection\r\n\r\nRequests containing `..` in the request path are a likely indicator of exploitation. Request paths may be captured in API audit logs, or in kube-apiserver HTTP logs.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Richard Turnbull of NCC Group as part of the Kubernetes Audit.\r\n\r\n<!-- labels -->\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig api-machinery\r\n/area apiserver\r\n",
          "date_published": "2022-11-08T21:33:07Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2022-3162",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2022-3172",
        "url": "https://github.com/kubernetes/kubernetes/issues/112513",
        "published_at": null,
        "updated_at": null,
        "headline": "Aggregated API server can cause clients to be redirected (SSRF)",
        "content": {
          "excerpt_text": "Aggregated API server can cause clients to be redirected (SSRF)",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/112513"
          ],
          "content_hash": "sha256:c08ddae1323dc9a4afbf13f38937aa6a115032af1abc62814b704bc90cd8e3d6"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Aggregated API server can cause clients to be redirected (SSRF)",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2022-3172",
            "issue_number": 112513
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:H/UI:R/S:C/C:L/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:H/UI:R/S:C/C:L/I:L/A:L) (5.1, medium)\r\n\r\nA security issue was discovered in kube-apiserver that allows an aggregated API server to redirect client traffic to any URL.  This could lead to the client performing unexpected actions as well as forwarding the client's API server credentials to third parties.\r\n\r\nThis issue has been rated medium and assigned CVE-2022-3172\r\n\r\n### Am I vulnerable?\r\n\r\nAll Kubernetes clusters with the following versions that are running aggregated API servers are impacted.  To identify if you have aggregated API servers configured, run the following command:\r\n\r\n```shell\r\nkubectl get apiservices.apiregistration.k8s.io -o=jsonpath='{range .items[?(@.spec.service)]}{.metadata.name}{\"\\n\"}{end}'\r\n```\r\n\r\n#### Affected Versions\r\n\r\n- kube-apiserver v1.25.0\r\n- kube-apiserver v1.24.0 - v1.24.4\r\n- kube-apiserver v1.23.0 - v1.23.10\r\n- kube-apiserver v1.22.0 - v1.22.13\r\n- kube-apiserver <= v1.21.14\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nAside from upgrading, no direct mitigation is available.\r\n\r\nAggregated API servers are a trusted part of the Kubernetes control plane, and configuring them is a privileged administrative operation.  Ensure that only trusted cluster administrators are allowed to create or modify `APIService` configuration, and follow security best practices with any aggregated API servers that may be in use.\r\n\r\n#### Fixed Versions\r\n\r\n- kube-apiserver v1.25.1 - fixed by #112330\r\n- kube-apiserver v1.24.5 - fixed by #112331\r\n- kube-apiserver v1.23.11 - fixed by #112358\r\n- kube-apiserver v1.22.14 - fixed by #112359\r\n\r\n**Fix impact:** The fix blocks all 3XX responses from aggregated API servers by default.  This may disrupt an aggregated API server that relies on redirects as part of its normal function.  If all current and future aggregated API servers are considered trustworthy and redirect functionality is required, set the `--aggregator-reject-forwarding-redirect` Kubernetes API server flag to `false` to restore the previous behavior.\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade\r\n\r\n### Detection\r\n\r\nKubernetes audit log events indicate the HTTP status code sent to the client via the `responseStatus.code` field.  This can be used to detect if an aggregated API server is redirecting clients.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Nicolas Joly & Weinong Wang @weinong from Microsoft.\r\n\r\nThe issue was fixed and coordinated by Di Jin @jindijamie @enj @liggitt @lavalamp @deads2k and @puerco.\r\n\r\n/area security\r\n/kind bug\r\n/committee security-response\r\n/label official-cve-feed\r\n/sig api-machinery\r\n/area apiserver\r\n/triage accepted",
          "date_published": "2022-09-16T13:14:50Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2022-3172",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25749",
        "url": "https://github.com/kubernetes/kubernetes/issues/112192",
        "published_at": null,
        "updated_at": null,
        "headline": "`runAsNonRoot` logic bypass for Windows containers",
        "content": {
          "excerpt_text": "`runAsNonRoot` logic bypass for Windows containers",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/112192"
          ],
          "content_hash": "sha256:c9b8a368c2053714d55b7398d5862d25b763e6df6960ce317a75fda1814899b8"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "`runAsNonRoot` logic bypass for Windows containers",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25749",
            "issue_number": 112192
          },
          "content_text": "A security issue was discovered in Kubernetes that could allow  Windows workloads to run as `ContainerAdministrator` even when those workloads set the `runAsNonRoot` option to `true`.\r\n\r\nThis issue has been rated low and assigned CVE-2021-25749\r\n\r\n### Am I vulnerable?\r\n\r\nAll Kubernetes clusters with following versions, running Windows workloads with `runAsNonRoot` are impacted\r\n\r\n#### Affected Versions\r\n\r\n- kubelet v1.20 - v1.21\r\n- kubelet v1.22.0 - v1.22.13\r\n- kubelet v1.23.0 - v1.23.10\r\n- kubelet v1.24.0 - v1.24.4\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThere are no known mitigations to this vulnerability.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet v1.22.14\r\n- kubelet v1.23.11\r\n- kubelet v1.24.5\r\n- kubelet v1.25.0\r\n\r\n\r\nTo upgrade, refer to this documentation _For core Kubernetes:_ https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/\r\n\r\n### Detection\r\n\r\nKubernetes Audit logs may indicate if the user name was misspelled to bypass the restriction placed on which user is a pod allowed to run as.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Additional Details\r\n\r\nSee the GitHub issue for more details: https://github.com/kubernetes/kubernetes/issues/112192 \r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported and fixed by Mark Rosetti (@marosset)\r\n",
          "date_published": "2022-09-01T21:02:01Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25749",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25748",
        "url": "https://github.com/kubernetes/kubernetes/issues/126814",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress-nginx `path` sanitization can be bypassed with newline character",
        "content": {
          "excerpt_text": "Ingress-nginx `path` sanitization can be bypassed with newline character",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126814"
          ],
          "content_hash": "sha256:21f21ad418b889d7325bfd4806e5048682c7dea3cf7989ab65ad88b380310a6d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress-nginx `path` sanitization can be bypassed with newline character",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25748",
            "issue_number": 126814
          },
          "content_text": "### Issue Details\r\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where a user that can create or update ingress objects can use a newline character to bypass the sanitization of the `spec.rules[].http.paths[].path` field of an Ingress object (in the `networking.k8s.io` or `extensions` API group) to obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated High ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned CVE-2021-25748.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nIf you are running the “chrooted” ingress-nginx controller introduced in v1.2.0 (gcr.io/k8s-staging-ingress-nginx/controller-chroot), you are not affected.\r\n\r\nMultitenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n<v1.2.1\r\n\r\n#### Fixed Versions\r\nv1.2.1\r\n\r\n### Mitigation\r\nIf you are unable to roll out the fix, this vulnerability can be mitigated by implementing an admission policy that restricts the `spec.rules[].http.paths[].path` field on the networking.k8s.io/Ingress resource to known safe characters (see the newly added [rules](https://github.com/kubernetes/ingress-nginx/blame/main/internal/ingress/inspector/rules.go), or the suggested value for [annotation-value-word-blocklist](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#annotation-value-word-blocklist)).\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\nSee ingress-nginx Issue [#8686](https://github.com/kubernetes/kubernetes/issues/126814) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Gafnit Amiga.\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2022-06-10T16:01:41Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25748",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25746",
        "url": "https://github.com/kubernetes/kubernetes/issues/126813",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress-nginx directive injection via annotations",
        "content": {
          "excerpt_text": "Ingress-nginx directive injection via annotations",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126813"
          ],
          "content_hash": "sha256:c692eeaee9d3e8a6d5c62edfb921cdb734ad5fa6b4e72278e48a95075d05f24d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress-nginx directive injection via annotations",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25746",
            "issue_number": 126813
          },
          "content_text": "### Issue Details\r\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where a user that can create or update ingress objects can use `.metadata.annotations` in an Ingress object (in the `networking.k8s.io` or `extensions` API group) to obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned **CVE-2021-25746**.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nMultitenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n- <v1.2.0\r\n\r\n#### Fixed Versions\r\n- v1.2.0-beta.0\r\n- v1.2.0\r\n\r\n### Mitigation\r\nIf you are unable to roll out the fix, this vulnerability can be mitigated by implementing an admission policy that restricts the `metadata.annotations` values to known safe (see the newly added [rules](https://github.com/kubernetes/ingress-nginx/blame/main/internal/ingress/inspector/rules.go), or the suggested value for [annotation-value-word-blocklist](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#annotation-value-word-blocklist)).\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\n\r\n### Additional Details\r\nSee ingress-nginx Issue [#8503](https://github.com/kubernetes/kubernetes/issues/126813) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Anthony Weems, and separately by jeffrey&oliver.\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2022-04-22T16:18:27Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25746",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25745",
        "url": "https://github.com/kubernetes/kubernetes/issues/126812",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress-nginx `path` can be pointed to service account token file",
        "content": {
          "excerpt_text": "Ingress-nginx `path` can be pointed to service account token file",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126812"
          ],
          "content_hash": "sha256:ef0a5593fbcad323c884521c4e9b95b0288ba7253376e3ac896cf5bf4492c3b1"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress-nginx `path` can be pointed to service account token file",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25745",
            "issue_number": 126812
          },
          "content_text": "### Issue Details\r\nA security issue was discovered in [ingress-nginx](https://github.com/kubernetes/ingress-nginx) where a user that can create or update ingress objects can use the `spec.rules[].http.paths[].path` field of an Ingress object (in the `networking.k8s.io` or `extensions` API group) to obtain the credentials of the ingress-nginx controller. In the default configuration, that credential has access to all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned **CVE-2021-25745**.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx. If you do not have ingress-nginx installed on your cluster, you are not affected. You can check this by running `kubectl get po -n ingress-nginx`.\r\n\r\nMultitenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions\r\n- <v1.2.0\r\n\r\n#### Fixed Versions\r\n- v1.2.0-beta.0\r\n- v1.2.0\r\n\r\n### Mitigation\r\nIf you are unable to roll out the fix, this vulnerability can be mitigated by implementing an admission policy that restricts the `spec.rules[].http.paths[].path` field on the `networking.k8s.io/Ingress` resource to known safe characters (see the newly added [rules](https://github.com/kubernetes/ingress-nginx/blame/main/internal/ingress/inspector/rules.go), or the suggested value for [annotation-value-word-blocklist](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#annotation-value-word-blocklist)).\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact [security@kubernetes.io](mailto:security@kubernetes.io)\r\nAdditional Details\r\nSee ingress-nginx Issue [#8502](https://github.com/kubernetes/kubernetes/issues/126812) for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Gafnit Amiga.\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee",
          "date_published": "2022-04-22T16:18:21Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25745",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25742",
        "url": "https://github.com/kubernetes/kubernetes/issues/126811",
        "published_at": null,
        "updated_at": null,
        "headline": "Ingress-nginx custom snippets allows retrieval of ingress-nginx serviceaccount token and secrets across all namespaces",
        "content": {
          "excerpt_text": "Ingress-nginx custom snippets allows retrieval of ingress-nginx serviceaccount token and secrets across all namespaces",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126811"
          ],
          "content_hash": "sha256:19075ab82681b84656f6905471b3745618b863e64a95e127462defbaa18cd65f"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ingress-nginx custom snippets allows retrieval of ingress-nginx serviceaccount token and secrets across all namespaces",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25742",
            "issue_number": 126811
          },
          "content_text": "### Issue Details\r\nA security issue was discovered in ingress-nginx where a user that can create or update ingress objects can use the custom snippets feature to obtain all secrets in the cluster.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:L)), and assigned **CVE-2021-25742**.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects ingress-nginx.\r\n\r\nMultitenant environments where non-admin users have permissions to create Ingress objects are most affected by this issue.\r\n\r\n#### Affected Versions with no mitigation\r\n\r\n- v1.0.0\r\n- <= v0.49.0\r\n\r\n#### Versions allowing mitigation\r\nThis issue cannot be fixed solely by upgrading ingress-nginx. It can be mitigated in the following versions:\r\n- v1.0.1\r\n- v0.49.1\r\n\r\n### Mitigation\r\nTo mitigate this vulnerability:\r\n1. Upgrade to a version that allows mitigation, (>= v0.49.1 or >= v1.0.1)\r\n2. Set [allow-snippet-annotations](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#allow-snippet-annotations) to false in your ingress-nginx ConfigMap based on how you deploy ingress-nginx:\r\n\r\n    **Static Deploy Files** \r\n    Edit the ConfigMap for ingress-nginx **after** deployment:\r\n    ```\r\n    kubectl edit configmap -n ingress-nginx ingress-nginx-controller\r\n    ```\r\n    Add directive:\r\n    ````\r\n    data:\r\n      allow-snippet-annotations: “false”\r\n     ````\r\n    More information on the ConfigMap [here](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/) \r\n\r\n    **Deploying Via Helm**\r\n    Set `controller.allowSnippetAnnotations` to `false` in the Values.yaml or add the directive to the helm deploy:\r\n    ```\r\n    helm install [RELEASE_NAME] --set controller.allowSnippetAnnotations=false ingress-nginx/ingress-nginx\r\n    ````\r\n\r\n    [https://github.com/kubernetes/ingress-nginx/blob/controller-v1.0.1/charts/ingress-nginx/values.yaml#L76](https://github.com/kubernetes/ingress-nginx/blob/controller-v1.0.1/charts/ingress-nginx/values.yaml#L76)\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\nAdditional Details\r\nSee ingress-nginx Issue kubernetes/kubernetes#126811 for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Mitch Hulscher.\r\n\r\nThank You,\r\nCJ Cullen on behalf of the Kubernetes Security Response Committee\r\n",
          "date_published": "2021-10-21T16:08:21Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25742",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25741",
        "url": "https://github.com/kubernetes/kubernetes/issues/104980",
        "published_at": null,
        "updated_at": null,
        "headline": "Symlink Exchange Can Allow Host Filesystem Access",
        "content": {
          "excerpt_text": "Symlink Exchange Can Allow Host Filesystem Access",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/104980"
          ],
          "content_hash": "sha256:28b368444400a183677d37fbbf39acbcef865d26e016f5ca7416f8b0549a99a9"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Symlink Exchange Can Allow Host Filesystem Access",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25741",
            "issue_number": 104980
          },
          "content_text": "A security issue was discovered in Kubernetes where a user may be able to create a container with subpath volume mounts to access files & directories outside of the volume, including on the host filesystem.\r\n\r\nThis issue has been rated **High** ([CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)), and assigned **CVE-2021-25741**.\r\n\r\n### Affected Components and Configurations\r\nThis bug affects kubelet.\r\n\r\n\r\nEnvironments where cluster administrators have restricted the ability to create hostPath mounts are the most seriously affected. Exploitation allows hostPath-like access without use of the hostPath feature, thus bypassing the restriction. \r\n\r\n\r\nIn a default Kubernetes environment, exploitation could be used to obscure misuse of already-granted privileges.\r\n\r\n#### Affected Versions\r\nv1.22.0 - v1.22.1\r\n\r\nv1.21.0 - v1.21.4\r\n\r\nv1.20.0 - v1.20.10\r\n\r\n<= v1.19.14\r\n\r\n#### Fixed Versions\r\nThis issue is fixed in the following versions:\r\n\r\nv1.22.2\r\n\r\nv1.21.5\r\n\r\nv1.20.11\r\n\r\nv1.19.15\r\n\r\n### Mitigation\r\nTo mitigate this vulnerability without upgrading kubelet, you can disable the VolumeSubpath feature gate on kubelet and kube-apiserver, and remove any existing Pods making use of the feature.\r\n\r\n\r\nYou can also use admission control to prevent less-trusted users from running containers as root to reduce the impact of successful exploitation.\r\n\r\n### Detection\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n### Additional Details\r\nSee Kubernetes Issue #104980 for more details.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Fabricio Voznika and Mark Wolters of Google.\r\n\r\n\r\nThanks as well to Ian Coldwater, Duffie Cooley, Brad Geesaman, and Rory McCune for the thorough security research that led to the discovery of this vulnerability.",
          "date_published": "2021-09-13T20:58:56Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25741",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8561",
        "url": "https://github.com/kubernetes/kubernetes/issues/104720",
        "published_at": null,
        "updated_at": null,
        "headline": "Webhook redirect in kube-apiserver",
        "content": {
          "excerpt_text": "Webhook redirect in kube-apiserver",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/104720"
          ],
          "content_hash": "sha256:3cf221b022ed772a50150581400edf4f18cad98358b8f85956957f44c5222482"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Webhook redirect in kube-apiserver",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8561",
            "issue_number": 104720
          },
          "content_text": "A security issue was discovered in Kubernetes where actors that control the responses of MutatingWebhookConfiguration or ValidatingWebhookConfiguration requests are able to redirect kube-apiserver requests to private networks of the apiserver. If that user can view kube-apiserver logs when the log level is set to 10, they can view the redirected responses and headers in the logs.\r\n\r\nThis issue has been rated **Medium** (https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:C/C:L/I:N/A:N) (4.1), and assigned **CVE-2020-8561**\r\n\r\n### Am I vulnerable?\r\n\r\nYou may be vulnerable if `--profiling` is enabled on the kube-apiserver and actors who control a validating or mutating webhook can access the kube-apiserver process logs.\r\n\r\n#### Affected Versions\r\n\r\nThis issue affects all known versions of kube-apiserver. \r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nThis issue can be mitigated by not allowing kube-apiserver access to sensitive resources or networks, or to reduce the “-v” flag value to less than 10 and set the “--profiling” flag value to “false” (default value is “true”). Setting the profiling flag to “false” prevents users from dynamically modifying the kube-apiserver log level, and the flag value Webhook requests may still be redirected to private networks with a log level less than 10, but the response body will not be logged.\r\n\r\n### Fixed Versions\r\nThere is no fix for this issue at this time.\r\n\r\n### Detection\r\n\r\nExamining kube-apiserver log responses is the only known method of detection for this issue.\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by QiQi Xu\r\n\r\n\r\n/triage accepted\r\n/lifecycle frozen\r\n/area security\r\n/kind bug\r\n/committee security-response",
          "date_published": "2021-09-01T20:18:50Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8561",
          "status": "open"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25740",
        "url": "https://github.com/kubernetes/kubernetes/issues/103675",
        "published_at": null,
        "updated_at": null,
        "headline": "Endpoint & EndpointSlice permissions allow cross-Namespace forwarding",
        "content": {
          "excerpt_text": "Endpoint & EndpointSlice permissions allow cross-Namespace forwarding",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/103675"
          ],
          "content_hash": "sha256:18afc13e8c966868d5727578b8c12cf5d55967cf7bed672f8168b778e597edff"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Endpoint & EndpointSlice permissions allow cross-Namespace forwarding",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25740",
            "issue_number": 103675
          },
          "content_text": "A security issue was discovered with Kubernetes that could enable users to send network traffic to locations they would otherwise not have access to via a confused deputy attack. \r\n\r\nThis issue has been rated **Low** severity ([CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N)), and assigned **CVE-2021-25740**.\r\n### Am I vulnerable?\r\nIf a potential attacker can create or edit Endpoints or EndpointSlices in the Kubernetes API, they can potentially direct a LoadBalancer or Ingress implementation to expose backend IPs the attacker should not have access to.\r\nImportantly, if the target’s NetworkPolicy already trusts the Load Balancer or Ingress implementation, NetworkPolicy can not be used to prevent exposure from other namespaces, potentially bypassing any security controls such as LoadBalancerSourceRanges.\r\nThis issue is a design flaw that cannot be fully mitigated without user-facing changes. With this public announcement, we can begin conversations about a long-term fix.\r\n#### Affected Versions\r\nAll Kubernetes versions are affected. \r\n### How do I mitigate this vulnerability?\r\nThere is no patch for this issue, and it can currently only be mitigated by restricting access to the vulnerable features. To mitigate the exposure, we recommend restricting write access to Endpoints and EndpointSlices by updating the system:aggregate-to-edit role using the [attached file](https://github.com/kubernetes/kubernetes/files/6823580/aggregate_to_edit_no_endpoints.yaml.txt). This will remove write access to Endpoints from the admin and edit roles:\r\n\r\n```shell\r\n# Allow kubectl auth reconcile to work\r\nkubectl annotate --overwrite clusterrole/system:aggregate-to-edit rbac.authorization.kubernetes.io/autoupdate=true\r\n\r\n# Test reconcile, then run for real if happy\r\nkubectl auth reconcile --remove-extra-permissions -f aggregate_to_edit_no_endpoints.yaml.txt --dry-run\r\nkubectl auth reconcile --remove-extra-permissions -f aggregate_to_edit_no_endpoints.yaml.txt\r\n\r\n# Prevent autoreconciliation back to old state\r\nkubectl annotate --overwrite clusterrole/system:aggregate-to-edit rbac.authorization.kubernetes.io/autoupdate=false\r\n```\r\n\r\nNote: This will prevent new versions of Kubernetes from reconciling new default permissions to this role. No new default permissions have been added to this role since v1.14.0, but we recommend you remove the autoupdate=false annotation as soon as a fix or other mitigation is possible.\r\n\r\nFor use-cases that need to edit these resources, we recommend creating a new purpose-built Role with the desired permissions, and using it only for those cases.\r\n### Detection\r\nServices with an empty selector rely on custom endpoints and are vulnerable to the attack described above. We recommend manually auditing any such usage. The following kubectl command will list all Services in a cluster with their selector:\r\n```\r\nkubectl get svc --all-namespaces -o=custom-columns='NAME:metadata.name,NAMESPACE:metadata.namespace,SELECTOR:spec.selector'\r\n```\r\n\r\nNote: Some Services without selectors specified may have their Endpoints managed by other controllers or tools. For example, endpoints for the default/kubernetes Service are managed by the Kubernetes API Server. \r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io \r\n#### Additional Advisory\r\nA similar attack is possible using Ingress implementations that support forwarding to ExternalName Services. This can be used to forward to Services in other namespaces or, in some cases, sensitive endpoints within the Ingress implementation. If you are using the Ingress API, we recommend confirming that the implementation you’re using either does not support forwarding to ExternalName Services or supports disabling the functionality.\r\n#### Additional Details\r\nSee the GitHub issue for more updates: https://github.com/kubernetes/kubernetes/issues/103675 \r\n \r\nThank You,\r\nRob Scott on behalf of Kubernetes SIG Network and CJ Cullen on behalf of the Kubernetes Product Security Committee\r\n",
          "date_published": "2021-07-14T03:30:07Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25740",
          "status": "unknown"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25737",
        "url": "https://github.com/kubernetes/kubernetes/issues/102106",
        "published_at": null,
        "updated_at": null,
        "headline": "Holes in EndpointSlice Validation Enable Host Network Hijack",
        "content": {
          "excerpt_text": "Holes in EndpointSlice Validation Enable Host Network Hijack",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/102106"
          ],
          "content_hash": "sha256:0a5f9fbf7e3ff33a5cbe4cb31ad3c450ee5dd1c77f03da26062384f56369015e"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Holes in EndpointSlice Validation Enable Host Network Hijack",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25737",
            "issue_number": 102106
          },
          "content_text": "#### Issue Details\r\nA security issue was discovered in Kubernetes where a user may be able to redirect pod traffic to private networks on a Node. Kubernetes already prevents creation of Endpoint IPs in the localhost or link-local range, but the same validation was not performed on EndpointSlice IPs. \r\nThis issue has been rated Low ([CVSS:3.0/AV:N/AC:L/PR:H/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:H/UI:N/S:U/C:L/I:N/A:N)), and assigned CVE-2021-25737.\r\nAffected Component\r\nkube-apiserver\r\n\r\n#### Affected Versions\r\nv1.21.0\r\nv1.20.0 - v1.20.6\r\nv1.19.0 - v1.19.10\r\nv1.16.0 - v1.18.18 (Note: EndpointSlices were not enabled by default in 1.16-1.18)\r\n#### Fixed Versions\r\nThis issue is fixed in the following versions:\r\nv1.21.1\r\nv1.20.7\r\nv1.19.11\r\nv1.18.19\r\n#### Mitigation\r\nTo mitigate this vulnerability without upgrading kube-apiserver, you can create a validating admission webhook that prevents EndpointSlices with endpoint addresses in the 127.0.0.0/8 and 169.254.0.0/16 ranges. If you have an existing admission policy mechanism (like OPA Gatekeeper) you can create a policy that enforces this restriction.\r\n#### Detection\r\nTo detect whether this vulnerability has been exploited, you can list EndpointSlices and check for endpoint addresses in the 127.0.0.0/8 and 169.254.0.0/16 ranges.\r\n \r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n#### Acknowledgements\r\nThis vulnerability was reported by John Howard of Google.\r\n",
          "date_published": "2021-05-18T19:14:27Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25737",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8562",
        "url": "https://github.com/kubernetes/kubernetes/issues/101493",
        "published_at": null,
        "updated_at": null,
        "headline": "Bypass of Kubernetes API Server proxy TOCTOU",
        "content": {
          "excerpt_text": "Bypass of Kubernetes API Server proxy TOCTOU",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/101493"
          ],
          "content_hash": "sha256:8809a55dbf40581de079b0208449ae7cc699ff0fd21c9de87ec643c805f572fe"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bypass of Kubernetes API Server proxy TOCTOU",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8562",
            "issue_number": 101493
          },
          "content_text": "CVSS Rating: **Low** ([CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:L/I:N/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:L/I:N/A:N))\r\n\r\nA security issue was discovered in Kubernetes where an authorized user may be able to access private networks on the Kubernetes control plane components. Kubernetes clusters are only affected if an untrusted user can create or modify Node objects and proxy to them, or an untrusted user can create or modify StorageClass objects and access KubeControllerManager logs. \r\n\r\nThis issue has been rated Low (CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:L/I:N/A:N) and assigned CVE-2020-8562.\r\n \r\nAs mitigations to a report from 2019 and CVE-2020-8555, Kubernetes attempts to prevent proxied connections from accessing link-local or localhost networks when making user-driven connections to Services, Pods, Nodes, or StorageClass service providers. As part of this mitigation Kubernetes does a DNS name resolution check and validates that response IPs are not in the link-local (169.254.0.0/16) or localhost (127.0.0.0/8) range. Kubernetes then performs a second DNS resolution without validation for the actual connection. If a non-standard DNS server returns different non-cached responses, a user may be able to bypass the proxy IP restriction and access private networks on the control plane.\r\n\r\n### Affected Versions:\r\nAll versions of Kubernetes are affected\r\n\r\n### Fixed Versions\r\nThere is no fix for this issue at this time.\r\n\r\n### Mitigations\r\nIf this issue affects your clusters’ control planes, you can use dnsmasq for name resolution and configure the min-cache-ttl and neg-ttl parameters to a low non-zero value to enforce cached replies for proxied connections. \r\n\r\n### Detection\r\nThis issue is not known to be directly detectable, but proxied calls will appear in the Kubernetes API Audit log. Kubernetes will respond with “address not allowed” when the validation successfully prevents a connection.\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by Javier Provecho (Telefonica).\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/triage accepted",
          "date_published": "2021-04-26T19:18:04Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8562",
          "status": "unknown"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-3121",
        "url": "https://github.com/kubernetes/kubernetes/issues/101435",
        "published_at": null,
        "updated_at": null,
        "headline": "Processes may panic upon receipt of malicious protobuf messages",
        "content": {
          "excerpt_text": "Processes may panic upon receipt of malicious protobuf messages",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/101435"
          ],
          "content_hash": "sha256:8229c34135b74f35fe1d5454da9c333698550c8f0fb97b76c2208f7fc5a7c46d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Processes may panic upon receipt of malicious protobuf messages",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-3121",
            "issue_number": 101435
          },
          "content_text": "### Issue Details\r\n\r\nA security issue was discovered in code generated by the gogo protobuf compiler used by Kubernetes. The gogo protobuf compiler issue has been assigned CVE-2021-3121 and is also known as the “skippy peanut butter bug”.\r\n\r\nA program which uses affected code to handle a malicious protobuf message could panic.\r\nThe Kubernetes Product Security Committee has tested the API server using a malicious message, and we believe that **there is no security impact to Kubernetes**.  When an authenticated user sent the malicious message to the API server, a panic occurred. However, the panic handler recovered and the API server continued without interruption (except to the malicious requestor, who received no response).\r\n\r\nGenerated protobuf files are part of several Kubernetes repositories, and any downstream projects which vendor in these repos should evaluate whether there is any security impact to their project.\r\n\r\n### Affected Components and Configurations\r\n\r\nAny golang components which use handler code created by the gogo protbuf compiler, which accept protobuf messages and do not gracefully handle panics in the unmarshalling codepath may be affected.\r\n\r\nThe following Linux command can be used to detect affected generated code within a codebase:\r\n\r\n```\r\nfind . -name '*.pb.go' | \\\r\nxargs -r grep -l 'if skippy < 0' | \\\r\nxargs -r awk -e '/if skippy < 0/ {a=4} /if \\(iNdEx \\+ skippy\\) > postIndex/ &&' \\\r\n  \t  -e 'a>0 {print FILENAME \" \" FNR \": \" $0 \" // vulnerable to CVE-2021-3121\"} {a--}'\r\n```\r\n\r\nAlthough we do not believe there is any security impact to Kubernetes, we have updated all generated protobufs out of an abundance of caution and as a courtesy to any downstream consumers who may be affected. The following PRs addressed this issue in Kubernetes:\r\n\r\nMaster branch: #98477, #101306\r\n1.21 branch: #98477 (in 1.21.0), #101325 (in 1.21.1)\r\n1.20 branch: #100501 (in 1.20.6), #101326 (in 1.20.7)\r\n1.19 branch: #100515 (in 1.19.10), #101327 (in 1.19.11)\r\n1.18 branch: #100514 (in 1.18.18), #101335 (in 1.18.19)\r\n\r\nFor other generated protobuf go handlers, the issue can be remediated by upgrading the gogo protobuf compiler to a fixed version (v1.3.2 or later), then regenerating affected protobuf code with the updated protobuf compiler. \r\n\r\n### Mitigations\r\n\r\nDisabling support for protobuf messages may be one possible mitigation for any affected product.\r\n\r\nAlso, graceful panic handling in message handlers mitigates the bug.\r\n\r\n### Detection\r\n\r\nIf you use generated protobuf code in a product and you observe a process exiting with messages similar to the following, a malicious user may be exploiting this defect:\r\n\r\n```\r\npanic: runtime error: index out of range [-9223372036854775804]\r\n \r\ngoroutine 1 [running]:\r\nv1.(*MessageName).Unmarshal(0xc000057ef8, 0xc0000161a0, 0xa, 0x10, 0xc000057ec8, 0x1)\r\n        .../protofile.pb.go:250 +0xb86\r\n```\r\n\r\n### References\r\n- CVE-2021-3121: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3121\r\n- GoGo Protobuf v1.3.2: https://github.com/gogo/protobuf/releases/tag/v1.3.2\r\n",
          "date_published": "2021-04-23T18:07:32Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-3121",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2021-25735",
        "url": "https://github.com/kubernetes/kubernetes/issues/100096",
        "published_at": null,
        "updated_at": null,
        "headline": "Validating Admission Webhook does not observe some previous fields",
        "content": {
          "excerpt_text": "Validating Admission Webhook does not observe some previous fields",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/100096"
          ],
          "content_hash": "sha256:7d4dd7d6805c54d3c17b5a3092d1775efe39506026a58b6db21ddbe5cff088d1"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Validating Admission Webhook does not observe some previous fields",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2021-25735",
            "issue_number": 100096
          },
          "content_text": "A security issue was discovered in kube-apiserver that could allow node updates to bypass a Validating Admission Webhook. You are only affected by this vulnerability if you run a Validating Admission Webhook for Nodes that denies admission based at least partially on the old state of the Node object.\r\n\r\nThis issue has been rated **Medium** ([CVSS:3.0/AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:H/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:H/UI:N/S:U/C:N/I:H/A:H)), and assigned **CVE-2021-25735**.\r\n\r\n**Note:** This only impacts validating admission plugins that rely on old values in certain fields, and does not impact calls from kubelets that go through the built-in NodeRestriction admission plugin.\r\n\r\n#### Affected Versions\r\n\r\n- kube-apiserver v1.20.0 - v1.20.5\r\n- kube-apiserver v1.19.0 - v1.19.9\r\n- kube-apiserver <= v1.18.17\r\n\r\n#### Fixed Versions\r\n\r\nThis issue is fixed in the following versions:\r\n- kube-apiserver v1.21.0 - Fixed by https://github.com/kubernetes/kubernetes/pull/99946\r\n- kube-apiserver v1.20.6 - Fixed by https://github.com/kubernetes/kubernetes/pull/100315\r\n- kube-apiserver v1.19.10 - Fixed by https://github.com/kubernetes/kubernetes/pull/100316\r\n- kube-apiserver v1.18.18 - Fixed by https://github.com/kubernetes/kubernetes/pull/100317\r\n\r\n#### Detection\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Rogerio Bastos & Ari Lima from RedHat\r\n",
          "date_published": "2021-03-10T18:18:01Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2021-25735",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8554",
        "url": "https://github.com/kubernetes/kubernetes/issues/97076",
        "published_at": null,
        "updated_at": null,
        "headline": "Man in the middle using LoadBalancer or ExternalIPs",
        "content": {
          "excerpt_text": "Man in the middle using LoadBalancer or ExternalIPs",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/97076"
          ],
          "content_hash": "sha256:aee5002b8f6e1f9618fa6867966b4fbafad0c0c24b1ca744feb1652133d1307a"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Man in the middle using LoadBalancer or ExternalIPs",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8554",
            "issue_number": 97076
          },
          "content_text": "CVSS Rating: **Medium** ([CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L))\r\n \r\nThis issue affects multitenant clusters. If a potential attacker can already create or edit services and pods, then they may be able to intercept traffic from other pods (or nodes) in the cluster.\r\n \r\nAn attacker that is able to create a ClusterIP service and set the spec.externalIPs field can intercept traffic to that IP. An attacker that is able to patch the status (which is considered a privileged operation and should not typically be granted to users) of a LoadBalancer service can set the status.loadBalancer.ingress.ip to similar effect.\r\nThis issue is a design flaw that cannot be mitigated without user-facing changes.\r\n### Affected Components and Configurations\r\n\r\nAll Kubernetes versions are affected. Multi-tenant clusters that grant tenants the ability to create and update services and pods are most vulnerable.\r\n### Mitigations\r\n\r\nThere is no patch for this issue, and it can currently only be mitigated by restricting access to the vulnerable features. Because an in-tree fix would require a breaking change, we will open a conversation about a longer-term fix or built-in mitigation after the embargo is lifted\r\n\r\nTo restrict the use of external IPs we are providing an admission webhook container: k8s.gcr.io/multitenancy/externalip-webhook:v1.0.0. The source code and deployment instructions are published at https://github.com/kubernetes-sigs/externalip-webhook.\r\n\r\nAlternatively, external IPs can be restricted using [OPA Gatekeeper](https://github.com/open-policy-agent/gatekeeper). A sample ConstraintTemplate and Constraint can be found here: https://github.com/open-policy-agent/gatekeeper-library/tree/master/library/general/externalip.\r\n\r\nNo mitigations are provided for LoadBalancer IPs since we do not recommend granting users *patch service/status* permission. If LoadBalancer IP restrictions are required, the approach for the external IP mitigations can be copied.\r\n### Detection\r\n\r\nExternalIP services are not widely used, so we recommend manually auditing any external IP usage. Users should not patch service status, so audit events for patch service status requests authenticated to a user may be suspicious.\r\n \r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Etienne Champetier (@champtar) of Anevia.\r\n \r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig network\r\n",
          "date_published": "2020-12-04T20:02:15Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8554",
          "status": "unknown"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8566",
        "url": "https://github.com/kubernetes/kubernetes/issues/95624",
        "published_at": null,
        "updated_at": null,
        "headline": "Ceph RBD adminSecrets exposed in logs when loglevel >= 4",
        "content": {
          "excerpt_text": "Ceph RBD adminSecrets exposed in logs when loglevel >= 4",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/95624"
          ],
          "content_hash": "sha256:41668d49edc40c741f5854a4221a78833d0120967a61063d83509e84d359afd6"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Ceph RBD adminSecrets exposed in logs when loglevel >= 4",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8566",
            "issue_number": 95624
          },
          "content_text": "CVSS Rating: 4.7 CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N (Medium)\r\n\r\nIn Kubernetes clusters using Ceph RBD as a storage provisioner, with logging level of at least 4,  Ceph RBD admin secrets can be written to logs. This occurs in kube-controller-manager's logs during provisioning of Ceph RBD persistent claims.\r\n\r\n### Am I vulnerable?\r\nIf Ceph RBD volumes are in use and kube-controller-manager is using a log level of at least 4.\r\n\r\n#### Affected Versions\r\nkubernetes v1.19.0 - v1.19.2\r\nkubernetes v1.18.0 - v1.18.9\r\nkubernetes v1.17.0 - v1.17.12\r\n\r\n### How do I mitigate this vulnerability?\r\nDo not enable verbose logging in production, limit access to logs.\r\n\r\n#### Fixed Versions\r\nv1.19.3\r\nv1.18.10\r\nv1.17.13\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by: Kaizhe Huang (derek0405)\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n",
          "date_published": "2020-10-15T22:07:53Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8566",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8565",
        "url": "https://github.com/kubernetes/kubernetes/issues/95623",
        "published_at": null,
        "updated_at": null,
        "headline": "Incomplete fix for CVE-2019-11250 allows for token leak in logs when logLevel >= 9",
        "content": {
          "excerpt_text": "Incomplete fix for CVE-2019-11250 allows for token leak in logs when logLevel >= 9",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/95623"
          ],
          "content_hash": "sha256:529fbfba587fbaef8ae8211ad8029b63e9ef22b3673743ad63d690fd6781d015"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Incomplete fix for CVE-2019-11250 allows for token leak in logs when logLevel >= 9",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8565",
            "issue_number": 95623
          },
          "content_text": "CVSS Rating: 4.7 CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N (Medium)\r\n\r\nIn Kubernetes, if the logging level is to at least 9, authorization and bearer tokens will be written to log files. This can occur both in API server logs and client tool output like `kubectl`.\r\n\r\n### Am I vulnerable?\r\nIf kube-apiserver is using a log level of at least 9.\r\n\r\n#### Affected Versions\r\nkubernetes v1.19.0 - v1.19.5\r\nkubernetes v1.18.0 - v1.18.13\r\nkubernetes v1.17.0 - v1.17.15\r\n\r\n### How do I mitigate this vulnerability?\r\nDo not enable verbose logging in production, limit access to logs.\r\n\r\n#### Fixed Versions\r\nkubernetes v1.20.0\r\nkubernetes v1.19.6 \r\nkubernetes v1.18.14 \r\nkubernetes v1.17.16\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by: Patrick Rhomberg (purelyapplied)\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n",
          "date_published": "2020-10-15T22:05:32Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8565",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8564",
        "url": "https://github.com/kubernetes/kubernetes/issues/95622",
        "published_at": null,
        "updated_at": null,
        "headline": "Docker config secrets leaked when file is malformed and log level >= 4",
        "content": {
          "excerpt_text": "Docker config secrets leaked when file is malformed and log level >= 4",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/95622"
          ],
          "content_hash": "sha256:c1789f5db2f331356ad6580b8e7712c78ddaf08829246e018e5ca0a657605f71"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Docker config secrets leaked when file is malformed and log level >= 4",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8564",
            "issue_number": 95622
          },
          "content_text": "CVSS Rating: 4.7 CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N (Medium)\r\n\r\nIn Kubernetes clusters using a logging level of at least 4, processing a malformed docker config file will result in the contents of the docker config file being leaked, which can include pull secrets or other registry credentials.\r\n\r\n### Am I vulnerable?\r\nIf kubernetes.io/dockerconfigjson type secrets are used, and a log level of 4 or higher is used. Third party tools using k8s.io/kubernetes/pkg/credentialprovider to read docker config files may also be vulnerable.\r\n\r\n#### Affected Versions\r\nkubernetes v1.19.0 - v1.19.2\r\nkubernetes v1.18.0 - v1.18.9\r\nkubernetes v1.17.0 - v1.17.12\r\n\r\n### How do I mitigate this vulnerability?\r\nDo not enable verbose logging in production, limit access to logs.\r\n\r\n#### Fixed Versions\r\nv1.19.3\r\nv1.18.10\r\nv1.17.13\r\n\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n#### Acknowledgements\r\nThis vulnerability was reported by: Nikolaos Moraitis (Red Hat)\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n",
          "date_published": "2020-10-15T22:03:19Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8564",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8563",
        "url": "https://github.com/kubernetes/kubernetes/issues/95621",
        "published_at": null,
        "updated_at": null,
        "headline": "Secret leaks in kube-controller-manager when using vSphere provider",
        "content": {
          "excerpt_text": "Secret leaks in kube-controller-manager when using vSphere provider",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/95621"
          ],
          "content_hash": "sha256:a921625e8096fdf655919b45fa3c06623b09693eb7917afe2895ee391c74f96b"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Secret leaks in kube-controller-manager when using vSphere provider",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8563",
            "issue_number": 95621
          },
          "content_text": "CVSS Rating: 5.6 CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:C/C:H/I:N/A:N (Medium)\r\n\r\nIn Kubernetes clusters using VSphere as a cloud provider, with a logging level set to 4 or above, VSphere cloud credentials will be leaked in the cloud controller manager's log.\r\n\r\n### Am I vulnerable?\r\nIf you are using VSphere as a cloud provider, have verbose logging enabled, and an attacker can access cluster logs, then you may be vulnerable to this.\r\n\r\n#### Affected Versions\r\nkube-controller-manager v1.19.0 - v1.19.2\r\n\r\n#### How do I mitigate this vulnerability?\r\nDo not enable verbose logging in production, limit access to cluster logs.\r\n\r\n#### Fixed Versions\r\nv1.19.3\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Acknowledgements\r\nThis vulnerability was reported by: Kaizhe Huang (derek0405)\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n",
          "date_published": "2020-10-15T22:00:44Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8563",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8557",
        "url": "https://github.com/kubernetes/kubernetes/issues/93032",
        "published_at": null,
        "updated_at": null,
        "headline": "Node disk DOS by writing to container /etc/hosts",
        "content": {
          "excerpt_text": "Node disk DOS by writing to container /etc/hosts",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/93032"
          ],
          "content_hash": "sha256:e4e3c123f98522a8c0d7cb113a7c9152b7dfa9c7fac3eb0adfbce9e322b9ffb6"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Node disk DOS by writing to container /etc/hosts",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8557",
            "issue_number": 93032
          },
          "content_text": "CVSS Rating: Medium (5.5)  [CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/CR:H/IR:H/AR:M](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/CR:H/IR:H/AR:M)\r\n\r\nThe `/etc/hosts` file mounted in a pod by kubelet is not included by the kubelet eviction manager when calculating ephemeral storage usage by a pod. If a pod writes a large amount of data to the `/etc/hosts` file, it could fill the storage space of the node and cause the node to fail.\r\n\r\n### Am I vulnerable?\r\n\r\nAny clusters allowing pods with sufficient privileges to write to their own `/etc/hosts` files are affected. This includes containers running with `CAP_DAC_OVERRIDE` in their capabilities bounding set (true by default) and either UID 0 (root) or a security context with `allowPrivilegeEscalation: true` (true by default).\r\n\r\n#### Affected Versions\r\n\r\n- kubelet v1.18.0-1.18.5\r\n- kubelet v1.17.0-1.17.8\r\n- kubelet < v1.16.13\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by using PodSecurityPolicies or other admission webhooks to force containers to drop CAP_DAC_OVERRIDE or to prohibit privilege escalation and running as root, but these measures may break existing workloads that rely upon these privileges to function properly.\r\n\r\n#### Fixed Versions\r\n\r\n- kubelet master - fixed by #92916\r\n- kubelet v1.18.6 - fixed by #92921\r\n- kubelet v1.17.9 - fixed by #92923\r\n- kubelet v1.16.13 - fixed by #92924\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Detection\r\n\r\nLarge pod `etc-hosts` files may indicate that a pod is attempting to perform a Denial of Service attack using this bug. A command such as\r\n\r\n```\r\nfind /var/lib/kubelet/pods/*/etc-hosts -size +1M\r\n```\r\n\r\nrun on a node can be used to find abnormally large pod etc-hosts files.\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Kebe Liu of DaoCloud, via the Kubernetes bug bounty program.\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig node\r\n/area kubelet",
          "date_published": "2020-07-13T18:39:08Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8557",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8559",
        "url": "https://github.com/kubernetes/kubernetes/issues/92914",
        "published_at": null,
        "updated_at": null,
        "headline": "Privilege escalation from compromised node to cluster",
        "content": {
          "excerpt_text": "Privilege escalation from compromised node to cluster",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/92914"
          ],
          "content_hash": "sha256:f74e3f064386f47ef976b6a3b9a250ff4d1632bf6916e7484f1b9a0f3329ef33"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Privilege escalation from compromised node to cluster",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8559",
            "issue_number": 92914
          },
          "content_text": "CVSS Rating: Medium (6.4) [CVSS:3.1/AV:N/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H)\r\n\r\nIf an attacker is able to intercept certain requests to the Kubelet, they can send a redirect response that may be followed by a client using the credentials from the original request. This can lead to compromise of other nodes.\r\n\r\nIf multiple clusters share the same certificate authority trusted by the client, and the same authentication credentials, this vulnerability may allow an attacker to redirect the client to another cluster. In this configuration, this vulnerability should be considered **High** severity.\r\n\r\n### Am I vulnerable?\r\n\r\nYou are only affected by this vulnerability if you treat the node as a security boundary, or if clusters share certificate authorities and authentication credentials.\r\n\r\nNote that this vulnerability requires an attacker to first compromise a node through separate means.\r\n\r\n#### Affected Versions\r\n\r\n- kube-apiserver v1.18.0-1.18.5\r\n- kube-apiserver v1.17.0-1.17.8\r\n- kube-apiserver v1.16.0-1.16.12\r\n- all kube-apiserver versions prior to v1.16.0\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nTo mitigate this vulnerability you must upgrade the kube-apiserver to a patched version.\r\n\r\n#### Fixed Versions\r\n\r\n- kube-apiserver master - fixed by https://github.com/kubernetes/kubernetes/pull/92941\r\n- kube-apiserver v1.18.6 - fixed by https://github.com/kubernetes/kubernetes/pull/92969\r\n- kube-apiserver v1.17.9 - fixed by https://github.com/kubernetes/kubernetes/pull/92970\r\n- kube-apiserver v1.16.13 - fixed by https://github.com/kubernetes/kubernetes/pull/92971\r\n\r\n\r\n**Fix impact:** Proxied backends (such as an extension API server) that respond to upgrade requests with a non-101 response code may be broken by this patch.\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n### Detection\r\n\r\nUpgrade requests should never respond with a redirect. If any of the following requests have a response code in the 300-399 range, it may be evidence of exploitation. This information can be found in the Kubernetes audit logs.\r\n\r\n- pods/exec\r\n- pods/attach\r\n- pods/portforward\r\n- any resource: proxy\r\n\r\nIf you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Wouter ter Maat of Offensi, via the Kubernetes bug bounty.\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig api-machinery\r\n/area apiserver",
          "date_published": "2020-07-08T17:03:16Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8559",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8558",
        "url": "https://github.com/kubernetes/kubernetes/issues/92315",
        "published_at": null,
        "updated_at": null,
        "headline": "Node setting allows for neighboring hosts to bypass localhost boundary",
        "content": {
          "excerpt_text": "Node setting allows for neighboring hosts to bypass localhost boundary",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/92315"
          ],
          "content_hash": "sha256:7f73c01de4e12476c62f879d31f83c369765b81bccd55debd87525cf867ad0aa"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Node setting allows for neighboring hosts to bypass localhost boundary",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8558",
            "issue_number": 92315
          },
          "content_text": "CVSS Rating:\r\n\r\nIn typical clusters: medium (5.4) [CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N)\r\n\r\nIn clusters where API server insecure port has not been disabled: high (8.8) [CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)\r\n\r\nA security issue was discovered in `kube-proxy` which allows adjacent hosts to reach TCP and UDP services bound to `127.0.0.1` running on the node or in the node's network namespace. For example, if a cluster administrator runs a TCP service on a node that listens on `127.0.0.1:1234`, because of this bug, that service would be potentially reachable by other hosts on the same LAN as the node, or by containers running on the same node as the service. If the example service on port `1234` required no additional authentication (because it assumed that only other localhost processes could reach it), then it could be vulnerable to attacks that make use of this bug.\r\n\r\nThe Kubernetes API Server's default insecure port setting causes the API server to listen on `127.0.0.1:8080` where it will accept requests without authentication. Many Kubernetes installers explicitly disable the API Server's insecure port, but in clusters where it is not disabled, an attacker with access to another system on the same LAN or with control of a container running on the master may be able to reach the API server and execute arbitrary API requests on the cluster. This port is deprecated, and will be removed in Kubernetes v1.20.\r\n\r\n### Am I vulnerable?\r\n\r\nYou may be vulnerable if:\r\n\r\n- You are running a vulnerable version (see below)\r\n- Your cluster nodes run in an environment where untrusted hosts share the same layer 2 domain (i.e. same LAN) as nodes\r\n- Your cluster allows untrusted pods to run containers with `CAP_NET_RAW` (the Kubernetes default is to allow this capability).\r\n- Your nodes (or hostnetwork pods) run any localhost-only services which do not require any further authentication. To list services that are potentially affected, run the following commands on nodes:\r\n    - `lsof +c 15 -P -n -i4TCP@127.0.0.1 -sTCP:LISTEN`\r\n    - `lsof +c 15 -P -n -i4UDP@127.0.0.1`\r\n\r\n    On a master node, an lsof entry like this indicates that the API server may be listening with an insecure port:\r\n\r\n```\r\nCOMMAND        PID  USER FD   TYPE DEVICE SIZE/OFF NODE NAME\r\nkube-apiserver 123  root  7u  IPv4  26799      0t0  TCP 127.0.0.1:8080 (LISTEN)\r\n```\r\n\r\n#### Affected Versions\r\n- kubelet/kube-proxy v1.18.0-1.18.3\r\n- kubelet/kube-proxy v1.17.0-1.17.6\r\n- kubelet/kube-proxy <=1.16.10\r\n\r\n### How do I mitigate this vulnerability?\r\nPrior to upgrading, this vulnerability can be mitigated by manually adding an iptables rule on nodes. This rule will reject traffic to 127.0.0.1 which does not originate on the node.\r\n\r\n` iptables -I INPUT --dst 127.0.0.0/8 ! --src 127.0.0.0/8 -m conntrack ! --ctstate RELATED,ESTABLISHED,DNAT -j DROP`\r\n\r\nAdditionally, if your cluster does not already have the API Server insecure port disabled, we strongly suggest that you disable it. Add the following flag to your kubernetes API server command line: `--insecure-port=0`\r\n#### Detection\r\nPackets on the wire with an IPv4 destination in the range 127.0.0.0/8 and a layer-2 destination MAC address of a node may indicate that an attack is targeting this vulnerability.\r\n\r\n#### Fixed Versions\r\nAlthough the issue is caused by `kube-proxy`, the current fix for the issue is in `kubelet` (although future versions may have the fix in `kube-proxy` instead). We recommend  updating both `kubelet` and `kube-proxy` to be sure the issue is addressed.\r\n\r\nThe following versions contain the fix:\r\n  \r\n- kubelet/kube-proxy master - fixed by #91569\r\n- kubelet/kube-proxy v1.18.4+ - fixed by #92038\r\n- kubelet/kube-proxy v1.17.7+ - fixed by #92039\r\n- kubelet/kube-proxy v1.16.11+ - fixed by #92040\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n\r\n## Additional Details\r\nThis issue was originally raised in issue #90259 which details how the `kube-proxy` sets `net.ipv4.conf.all.route_localnet=1` which causes the system not to reject traffic to localhost which originates on other hosts.\r\n\r\nIPv6-only services that bind to a `localhost` address are not affected. \r\n\r\nThere may be additional attack vectors possible in addition to those fixed by #91569 and its cherry-picks. For those attacks to succeed, the target service would need to be UDP and the attack could only rely upon sending UDP datagrams since it wouldn't receive any replies. Finally, the target node would need to have reverse-path filtering disabled for an attack to have any effect. Work is ongoing to determine whether and how this issue should be fixed. See #91666 for up-to-date status on this issue.  \r\n\r\n#### Acknowledgements\r\nThis vulnerability was reported by János Kövér, Ericsson with additional impacts reported by Rory McCune, NCC Group and Yuval Avrahami and Ariel Zelivansky, Palo Alto Networks.\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig network\r\n/sig node\r\n/area kubelet",
          "date_published": "2020-06-19T18:38:58Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8558",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8555",
        "url": "https://github.com/kubernetes/kubernetes/issues/91542",
        "published_at": null,
        "updated_at": null,
        "headline": "Half-Blind SSRF in kube-controller-manager",
        "content": {
          "excerpt_text": "Half-Blind SSRF in kube-controller-manager",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/91542"
          ],
          "content_hash": "sha256:9e0901f2edd8bf530f4926d78c2df680fde0725702e19d717885a345a2792f36"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Half-Blind SSRF in kube-controller-manager",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8555",
            "issue_number": 91542
          },
          "content_text": "CVSS Rating: [CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:N/A:N](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:N/A:N)\r\n\r\nThere exists a Server Side Request Forgery (SSRF) vulnerability in kube-controller-manager that allows certain authorized users to leak up to 500 bytes of arbitrary information from unprotected endpoints within the master's host network (such as link-local or loopback services).\r\n \r\nAn attacker with permissions to create a pod with certain built-in Volume types (GlusterFS, Quobyte, StorageOS, ScaleIO) or permissions to create a StorageClass can cause kube-controller-manager to make GET requests or POST requests without an attacker controlled request body from the master's host network.\r\n \r\n### Am I vulnerable?\r\n\r\nYou may be vulnerable if:\r\n\r\n- You are running a vulnerable version (see below)\r\n- There are unprotected endpoints normally only visible from the Kubernetes master (including link-local metadata endpoints, unauthenticated services listening on localhost, or other services in the master's private network)\r\n- Untrusted users can create pods with an affected volume type or modify storage classes.\r\n\r\n#### Affected Versions\r\n\r\n- kube-controller-manager v1.18.0\r\n- kube-controller-manager v1.17.0 - v1.17.4\r\n- kube-controller-manager v1.16.0 - v1.16.8\r\n- kube-controller-manager <= v1.15.11\r\n \r\nThe affected volume types are: GlusterFS, Quobyte, StorageOS, ScaleIO\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by adding endpoint protections on the master or restricting usage of the vulnerable volume types (for example by constraining usage with a [PodSecurityPolicy](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems) or third-party admission controller such as [Gatekeeper](https://github.com/open-policy-agent/gatekeeper)) and restricting StorageClass write permissions through RBAC.\r\n\r\n#### Fixed Versions\r\n\r\nThe information leak was patched in the following versions:\r\n\r\n- kube-controller-manager master - fixed by https://github.com/kubernetes/kubernetes/pull/89794\r\n- kube-controller-manager v1.18.1+ - fixed by https://github.com/kubernetes/kubernetes/pull/89796\r\n- kube-controller-manager v1.17.5+ - fixed by https://github.com/kubernetes/kubernetes/pull/89837\r\n- kube-controller-manager v1.16.9+ - fixed by https://github.com/kubernetes/kubernetes/pull/89838\r\n- kube-controller-manager v1.15.12+ - fixed by https://github.com/kubernetes/kubernetes/pull/89839\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n## Additional Details\r\n\r\nExploitation of this vulnerability causes the kube-controller-manager to make a request to a user-supplied, unvalidated URL. The request does not include any kube-controller-manager client credentials.\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Brice Augras from Groupe-Asten and Christophe Hauquiert from Nokia.\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig storage\r\n/area controller-manager",
          "date_published": "2020-05-28T16:13:34Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8555",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-10749",
        "url": "https://github.com/kubernetes/kubernetes/issues/91507",
        "published_at": null,
        "updated_at": null,
        "headline": "IPv4 only clusters susceptible to MitM attacks via IPv6 rogue router advertisements",
        "content": {
          "excerpt_text": "IPv4 only clusters susceptible to MitM attacks via IPv6 rogue router advertisements",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/91507"
          ],
          "content_hash": "sha256:ea05fb8a576826e5f614f1a3cb71a13d0f666ace79aa0dd65f11754377f2fd81"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "IPv4 only clusters susceptible to MitM attacks via IPv6 rogue router advertisements",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-10749",
            "issue_number": 91507
          },
          "content_text": "CVSS Rating: [CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:C/C:L/I:L/A:L](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:C/C:L/I:L/A:L) (6.0 Medium)\r\n\r\nA cluster configured to use an affected container networking implementation is susceptible to man-in-the-middle (MitM) attacks. By sending “rogue” router advertisements, a malicious container can reconfigure the host to redirect part or all of the IPv6 traffic of the host to the attacker-controlled container. Even if there was no IPv6 traffic before, if the DNS returns A (IPv4) and AAAA (IPv6) records, many HTTP libraries will try to connect via IPv6 first then fallback to IPv4, giving an opportunity to the attacker to respond.\r\n\r\n### Am I vulnerable?\r\n\r\nKubernetes itself is not vulnerable. A Kubernetes cluster using an affected networking implementation is vulnerable.\r\n\r\nBinary releases of the kubelet installed from upstream Kubernetes Community repositories hosted at https://packages.cloud.google.com/ may have also installed the `kubernetes-cni` package containing the [containernetworking CNI plugins](https://github.com/containernetworking/plugins), which are affected by CVE-2020-10749.\r\n\r\n#### Affected Versions\r\nThe following official kubelet package versions have an affected `kubernetes-cni` package as a dependency: \r\n- kubelet v1.18.0-v1.18.3\r\n- kubelet v1.17.0-v1.17.6\r\n- kubelet < v1.16.11\r\n\r\nA cluster having an affected `kubernetes-cni` package installed is only affected if configured to use it.\r\n#### Third-party components and versions\r\nMany container networking implementations are affected, including:\r\n\r\n- CNI Plugins maintained by the containernetworking team, prior to version 0.8.6 (CVE-2020-10749) (See https://github.com/containernetworking/plugins/pull/484)\r\n- Calico and Calico Enterprise (CVE-2020-13597)  Please refer to the Tigera Advisory TTA-2020-001 at https://www.projectcalico.org/security-bulletins/ for details\r\n- Docker versions prior to 19.03.11 (see https://github.com/docker/docker-ce/releases/v19.03.11) (CVE-2020-13401)\r\n- Flannel, all current versions\r\n- Weave Net, prior to version 2.6.3\r\n\r\nIt is believed that the following are not affected:\r\n\r\n- Cilium\r\n- Juniper Contrail Networking\r\n- OpenShift SDN\r\n- OVN-Kubernetes\r\n- Tungsten Fabric\r\n\r\nInformation about the vulnerability status of any plugins or implementations not listed above is currently unavailable. Please contact the provider directly with questions about their implementation.\r\n\r\n### How do I mitigate this vulnerability?\r\n- Set the host default to reject router advertisements. This should prevent attacks from succeeding, but may break legitimate traffic, depending upon the networking implementation and the network where the cluster is running. To change this setting, set the sysctl `net.ipv6.conf.all.accept_ra` to 0.\r\n- Use TLS with proper certificate validation\r\n- Disallow `CAP_NET_RAW` for untrusted workloads or users. For example, a Pod Security Policy with a `RequiredDropCapabilities` that includes `NET_RAW` will prevent this attack for controlled workloads.\r\n\r\n#### Fixed Versions\r\n\r\nThe following packages will bundle fixed versions of the containernetworking CNI plugins that were formerly installed via the `kubernetes-cni` package.\r\n- kubelet v1.19.0+ (master branch #91370)\r\n- kubelet v1.18.4+ (#91387)\r\n- kubelet v1.17.7+ (#91386)\r\n- kubelet v1.16.11+ (#91388)\r\n\r\nBecause these versions are not yet available, cluster administrators using packages from the Kubernetes repositories may choose to manually upgrade CNI plugins by retrieving the relevant arch tarball from the containernetworking/plugins [v0.8.6 release](https://github.com/containernetworking/plugins/releases/tag/v0.8.6). The patch versions are [expected to be released on June 17th](https://github.com/kubernetes/sig-release/blob/master/releases/patch-releases.md#timelines), subject to change.\r\n\r\n## Additional Details\r\n#### Detection\r\n\r\n- The IPv6 routing table on nodes will show any attacker-created entries. For example, a host with IPv6 disabled might show no default route when running `ip -6 route` but the same host with an attack in progress might show an updated default route or a route to the target address(es). Any IPv6 route with a destination interface of a host-side container network interface should be investigated.\r\n- The host-side of a container network interface may show additional configured IPv6 addresses after receiving a rogue RA packet. For example, given a host-side interface of `cbr0` which might normally have no IPv6 address, a dynamic-configured address on the interface may signal an attack in progress. Use this command to view interface addresses: `ip a show dynamic cbr0`\r\n\r\n#### Affected configurations\r\n\r\n- Clusters using an affected networking implementation and allowing workloads to run with `CAP_NET_RAW privileges`. The default Kubernetes security context runs workloads with a capabilities bounding set that includes `CAP_NET_RAW`. \r\n\r\n#### Vulnerability impact\r\n\r\n- A user able to create containers with `CAP_NET_RAW` privileges on an affected cluster can intercept traffic from other containers on the host or from the host itself.\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Etienne Champetier (@champtar).\r\n\r\nThe issue was fixed by Casey Callendrello (@squeed) and maintainers of various container networking implementations. Updates to Kubernetes builds were coordinated by Stephen Augustus (@justaugustus) and Tim Pepper (@tpepper).\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig network\r\n",
          "date_published": "2020-05-27T19:32:29Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-10749",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11254",
        "url": "https://github.com/kubernetes/kubernetes/issues/89535",
        "published_at": null,
        "updated_at": null,
        "headline": "kube-apiserver Denial of Service vulnerability from malicious YAML payloads",
        "content": {
          "excerpt_text": "kube-apiserver Denial of Service vulnerability from malicious YAML payloads",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/89535"
          ],
          "content_hash": "sha256:9792b451a3f69e743bac03f9a2f7beb58b97b0b7da88287bab300c2ada578c7e"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "kube-apiserver Denial of Service vulnerability from malicious YAML payloads",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11254",
            "issue_number": 89535
          },
          "content_text": "CVE-2019-11254 is a denial of service vulnerability in the kube-apiserver, allowing authorized users sending malicious YAML payloads to cause kube-apiserver to consume excessive CPU cycles while parsing YAML.\r\n \r\nThe issue was discovered via the fuzz test kubernetes/kubernetes#83750.\r\n \r\n**Affected components:**\r\nKubernetes API server\r\n \r\n**Affected versions:**\r\n<= v1.15.9, resolved in 1.15.10 by https://github.com/kubernetes/kubernetes/pull/87640\r\nv1.16.0-v1.16.7, resolved in 1.16.8 by https://github.com/kubernetes/kubernetes/pull/87639\r\nv1.17.0-v1.17.2, resolved in 1.17.3 by https://github.com/kubernetes/kubernetes/pull/87637\r\nFixed in master by https://github.com/kubernetes/kubernetes/pull/87467\r\n \r\n**How do I mitigate this vulnerability?**\r\nPrior to upgrading, these vulnerabilities can be mitigated by preventing unauthenticated or unauthorized access to kube-apiserver.",
          "date_published": "2020-03-26T18:55:26Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11254",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8552",
        "url": "https://github.com/kubernetes/kubernetes/issues/89378",
        "published_at": null,
        "updated_at": null,
        "headline": "apiserver DoS (oom)",
        "content": {
          "excerpt_text": "apiserver DoS (oom)",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/89378"
          ],
          "content_hash": "sha256:0bd2c2d502f91184b110ace3466649a3916d7958a68ef521db456b2d4c646a4b"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "apiserver DoS (oom)",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8552",
            "issue_number": 89378
          },
          "content_text": "CVSS Rating: [CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L) (Medium)\r\n\r\nThe Kubernetes API server has been found to be vulnerable to a denial of service attack via authorized API requests.\r\n\r\n### Am I vulnerable?\r\n\r\nIf an attacker that can make an authorized resource request to an unpatched API server (see below), then you are vulnerable to this. Prior to v1.14, this was possible via unauthenticated requests by default.\r\n\r\n#### Affected Versions\r\n\r\n- kube-apiserver v1.17.0 - v1.17.2\r\n- kube-apiserver v1.16.0 - v1.16.6\r\n- kube-apiserver < v1.15.10\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nPrior to upgrading, this vulnerability can be mitigated by:\r\n- Preventing unauthenticated or unauthorized access to all apis\r\n- The apiserver should auto restart if it OOMs\r\n\r\n#### Fixed Versions\r\n\r\n- v1.17.3\r\n- v1.16.7\r\n- v1.15.10\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by: Gus Lees (Amazon)\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig api-machinery",
          "date_published": "2020-03-23T18:35:34Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8552",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8551",
        "url": "https://github.com/kubernetes/kubernetes/issues/89377",
        "published_at": null,
        "updated_at": null,
        "headline": "Kubelet DoS via API",
        "content": {
          "excerpt_text": "Kubelet DoS via API",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/89377"
          ],
          "content_hash": "sha256:966418a8bfe30de528c0b313506a1415e9548be7fbdf4d13b7147c30f8a7c2fa"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Kubelet DoS via API",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8551",
            "issue_number": 89377
          },
          "content_text": "CVSS Rating: [CVSS:3.0/AV:A/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:A/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L) (Medium)\r\n\r\nThe Kubelet has been found to be vulnerable to a denial of service attack via the kubelet API, including the unauthenticated HTTP read-only API typically served on port 10255, and the authenticated HTTPS API typically served on port 10250.\r\n\r\n### Am I vulnerable?\r\n\r\nIf an attacker can make a request to an unpatched kubelet, then you may be vulnerable to this.\r\n\r\n#### Affected Versions\r\n\r\n- kubelet v1.17.0 - v1.17.2\r\n- kubelet v1.16.0 - v1.16.6\r\n- kubelet v1.15.0 - v1.15.9\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nLimit access to the Kubelet API or patch the Kubelet.\r\n\r\n#### Fixed Versions\r\n\r\n- v1.17.3\r\n- v1.16.7\r\n- v1.15.10\r\n\r\nTo upgrade, refer to the documentation: https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#upgrading-a-cluster\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by: Henrik Schmidt\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig node\r\n/area kubelet",
          "date_published": "2020-03-23T18:34:40Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8551",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2020-8553",
        "url": "https://github.com/kubernetes/kubernetes/issues/126818",
        "published_at": null,
        "updated_at": null,
        "headline": "ingress-nginx auth-type basic annotation vulnerability",
        "content": {
          "excerpt_text": "ingress-nginx auth-type basic annotation vulnerability",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/126818"
          ],
          "content_hash": "sha256:f717cf87ea252a6d6718f4de313a41c7a97d9c6acec0fddb707aaf0b833e3e2c"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "ingress-nginx auth-type basic annotation vulnerability",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2020-8553",
            "issue_number": 126818
          },
          "content_text": "A security issue was discovered in ingress-nginx versions older than v0.28.0. The issue is of medium severity, and upgrading is encouraged to fix the vulnerability.\r\n\r\n**Am I vulnerable?**\r\n\r\nThe vulnerability exists only if the annotation [nginx.ingress.kubernetes.io/auth-type: basic](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#authentication) is used.\r\n\r\n**How do I upgrade?**\r\n\r\nFollow installation instructions [here](https://kubernetes.github.io/ingress-nginx/deploy/upgrade/)\r\n\r\n**Vulnerability Details**\r\n\r\nA vulnerability has been discovered where a malicious user could create a new Ingress definition resulting in the replacement of the password file. The vulnerability requires that the victim namespace and/or secret use a hyphen in the name.\r\n\r\nThis scenario requires privileges in the cluster to create and read ingresses and also create secrets.\r\n\r\nThis issue is filed as CVE-2020-8553.\r\n\r\n/close\r\n",
          "date_published": "2020-02-19T19:00:32Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2020-8553",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11251",
        "url": "https://github.com/kubernetes/kubernetes/issues/87773",
        "published_at": null,
        "updated_at": null,
        "headline": "kubectl cp symlink vulnerability",
        "content": {
          "excerpt_text": "kubectl cp symlink vulnerability",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/87773"
          ],
          "content_hash": "sha256:fc29bbc1102affb337ad8a559f8494bf5ed67550b1e4c306ae4c7ef28d2a62f5"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "kubectl cp symlink vulnerability",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11251",
            "issue_number": 87773
          },
          "content_text": "A security issue was discovered in kubectl versions v1.13.10, v1.14.6, and v1.15.3. The issue is of a medium severity and upgrading of kubectl is encouraged to fix the vulnerability.\r\n\r\n**Am I vulnerable?**\r\n\r\nRun kubectl version --client and if it returns versions v1.13.10, v1.14.6, and v1.15.3, you are running a vulnerable version.\r\n\r\n**How do I upgrade?**\r\n\r\nFollow installation instructions [here](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\r\n\r\n**Vulnerability Details**\r\n\r\nThe details for this vulnerability are very similar to CVE-2019-1002101 and CVE-2019-11246.\r\nA vulnerability has been discovered in kubectl cp that allows a combination of two symlinks to copy a file outside of its destination directory. This could be used to allow an attacker to place a nefarious file using a symlink, outside of the destination tree.\r\n\r\nThis issue is filed as CVE-2019-11251.\r\n\r\nTwo fixes were formulated, one fix to remove symlink support going forwards and a fix with cherry picks made to ensure backwards compatibility.\r\n\r\nSee https://github.com/kubernetes/kubernetes/pull/82143 for the primary fix in v1.16.0 which removes the support of symlinks in kubectl cp. After version 1.16.0, symlink support with kubectl cp is removed, it is recommended instead to use a combination of exec+tar.\r\n\r\nA second fix has been made to 1.15.4 and backported to 1.14.7 and 1.13.11. This changes the kubectl cp un-tar symlink logic, by unpacking the symlinks after all the regular files have been unpacked. This then guarantees that a file can’t be written through a symlink.\r\n\r\nSee https://github.com/kubernetes/kubernetes/pull/82384 for the fix to version 1.15.4. The following Cherry picks were made from this fix to earlier versions of v1.14.7 and v1.13.11:\r\n\r\nSee https://github.com/kubernetes/kubernetes/pull/82502 for version 1.14.7\r\nSee https://github.com/kubernetes/kubernetes/pull/82503 for version 1.13.11\r\n\r\nThank you to Erik Sjölund (@eriksjolund) for discovering this issue, Tim Allclair and Maciej Szulik for both fixes and the patch release managers for including the fix in their releases.\r\n\r\n/close",
          "date_published": "2020-02-03T15:12:22Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11251",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2018-1002102",
        "url": "https://github.com/kubernetes/kubernetes/issues/85867",
        "published_at": null,
        "updated_at": null,
        "headline": "Unvalidated redirect",
        "content": {
          "excerpt_text": "Unvalidated redirect",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/85867"
          ],
          "content_hash": "sha256:31684161f6beaa742eaef6feb2f052b1a41e453322c4358b17b6871cc83c04b1"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Unvalidated redirect",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2018-1002102",
            "issue_number": 85867
          },
          "content_text": "CVSS Rating: [CVSS:3.0/AV:N/AC:H/PR:H/UI:R/S:C/C:L/I:N/A:N/E:F (Low)](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:H/UI:R/S:C/C:L/I:N/A:N/E:F)\r\n\r\nAn attacker-controlled Kubelet can return an arbitrary redirect when responding to certain apiserver requests. Impacted kube-apiservers will follow the redirect as a GET request with client-cert credentials for authenticating to the Kubelet.\r\n\r\n### Am I vulnerable?\r\n\r\nKubernetes API servers with the `StreamingProxyRedirects` [feature](https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/) enabled AND without the `ValidateProxyRedirects` feature are affected.\r\n\r\nAPI servers using SSH tunnels (--ssh-user / --ssh-keyfile) are not affected.\r\n\r\nUsing the default feature gate values, kube-apiserver versions before v1.14 are affected.\r\n\r\n### How do I mitigate this vulnerability?\r\n\r\nFor Kubernetes versions >= v1.10.0, the `ValidateProxyRedirects` can be manually enabled with the `kube-apiserver` flag `--feature-gates=ValidateProxyRedirects=true`.\r\n\r\n#### Fix impact\r\nThe `ValidateProxyRedirects` feature will cause the kube-apiserver to check that redirects go to the same host. If nodes are configured to respond to CRI streaming requests on a different host interface than what the apiserver makes requests on (only the case if not using the built-in dockershim & setting the kubelet flag `--redirect-container-streaming=true`), then these requests will be broken. In that case, the feature can be temporarily disabled until the node configuration is corrected. We suggest setting `--redirect-container-streaming=false` on the kubelet to avoid issues.\r\n\r\n#### Fixed Versions\r\n\r\n- Kubernetes v1.14+ - Fixed by default in https://github.com/kubernetes/kubernetes/pull/72552\r\n- Kubernetes v1.10-v1.14 - Fix available as alpha in https://github.com/kubernetes/kubernetes/pull/66516\r\n\r\n## Additional Details\r\n\r\nIn a future release, we plan to deprecate the `StreamingProxyRedirects` feature, instead opting to handle the redirection locally through the Kubelet. Once the deprecation is complete, we can completely remove apiserver redirect handling (at least for Kubelet requests).\r\n\r\n#### Acknowledgements\r\n\r\nThis vulnerability was reported by Alban Crequy.\r\n\r\n/area security\r\n/kind bug\r\n/committee product-security\r\n/sig api-machinery node\r\n/area apiserver\r\n\r\n/close",
          "date_published": "2019-12-03T22:58:37Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2018-1002102",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11255",
        "url": "https://github.com/kubernetes/kubernetes/issues/85233",
        "published_at": null,
        "updated_at": null,
        "headline": "CSI volume snapshot, cloning and resizing features can result in unauthorized volume data access or mutation",
        "content": {
          "excerpt_text": "CSI volume snapshot, cloning and resizing features can result in unauthorized volume data access or mutation",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/85233"
          ],
          "content_hash": "sha256:c0bb2e4082f5e34ac2c3f6bc3f897ceb7174e35daaf84cd70e1d2fc9ad2e618d"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "CSI volume snapshot, cloning and resizing features can result in unauthorized volume data access or mutation",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11255",
            "issue_number": 85233
          },
          "content_text": "<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/\r\n-->\r\n\r\n**Am I vulnerable?**\r\n\r\nCSI snapshot, cloning and resizing features are affected. Prior to Kubernetes 1.16, these features were all alpha and disabled by default. Starting in Kubernetes 1.16, CSI cloning and resizing features are beta and enabled by default. \r\n\r\nThese features also require CSI drivers to be installed in a Kubernetes cluster and the CSI driver also has to support those features. An unofficial list of CSI drivers and their supported features is available [here](https://kubernetes-csi.github.io/docs/drivers.html), however it is best to check with the CSI driver vendor for the latest information.\r\n\r\nCheck if you have the following Kubernetes feature gates enabled:\r\n\r\n```\r\nVolumeSnapshotDataSource: alpha starting with K8s 1.12\r\nExpandCSIVolumes: alpha starting with K8s 1.14, beta starting with K8s 1.16\r\nVolumePVCDataSource: alpha starting with K8s 1.15, beta starting with K8s 1.16\r\n```\r\n\r\nCheck if you are using CSI drivers in your cluster. If so, the following command’s output will be non-empty:\r\n\r\n```\r\n$ kubectl get nodes -o jsonpath='{.items[*].metadata.annotations.csi\\.volume\\.kubernetes\\.io\\/nodeid}'\r\n      {\"my-csi-plugin\":\"kubernetes-minion-group-433q\"}\r\n```\r\n\r\nThen, check the CSI driver’s pod specifications to see if they are using the following vulnerable versions of sidecars:\r\n\r\n```\r\nexternal-provisioner: v0.4.1-0.4.2, v1.0.0-1.0.1, v1.1.0-1.2.1, v1.3.0\r\nexternal-snapshotter: v0.4.0-0.4.1, v1.0.0-1.0.1, v1.1.0-v1.2.1\r\nexternal-resizer: v0.1.0-0.2.0\r\n```\r\n\r\nAn example query:\r\n```\r\n$ kubectl get pods --all-namespaces -o jsonpath='{..image}' | tr ' ' $'\\n' | grep \"csi-provisioner\\|csi-snapshotter\\|csi-resizer\"\r\n      image: quay.io/k8scsi/csi-provisioner:v1.2.0\r\n```\r\n\r\nNote that the exact container image name may vary across CSI driver vendors. It is recommended to inspect the Pod specifications directly.\r\n\r\n**How do I mitigate the vulnerability?**\r\n\r\nAs a short term mitigation, disable the `VolumeSnapshotDataSource`, `ExpandCSIVolumes`, and `VolumePVCDataSource` Kubernetes feature gates in kube-apiserver and kube-controller-manager. This will cause new PersistentVolumeClaims to be provisioned ignoring the DataSource and resizing requests will also be ignored. Note that this will cause new PVCs that are intended to be provisioned from a snapshot or clone to instead provision a blank disk.\r\n\r\nAlso, to disable taking volume snapshots, either remove the external-snapshotter sidecar from any CSI drivers or revoke the CSI driver’s RBAC permissions on the `snapshot.storage.k8s.io` API group.\r\n\r\nLonger term, upgrade your CSI driver with patched versions of the affected sidecars. Fixes are available in the following sidecar versions:\r\n\r\nexternal-provisioner: \r\nv0.4.3\r\nv1.0.2\r\nv1.2.2\r\nv1.3.1\r\nv1.4.0 \r\n\r\nexternal-snapshotter:\r\nv0.4.2\r\nv1.0.2\r\nv1.2.2\r\n\r\nexternal-resizer\r\nv0.3.0\r\n\r\nFixes for each of the sidecars can be tracked by:\r\nhttps://github.com/kubernetes-csi/external-provisioner/issues/380\r\nhttps://github.com/kubernetes-csi/external-snapshotter/issues/193\r\nhttps://github.com/kubernetes-csi/external-resizer/issues/63\r\n\r\n**How do I upgrade?**\r\n\r\nCheck with your CSI driver vendor for upgrade instructions. No Kubernetes control plane or node upgrades are required unless the CSI driver is bundled into the Kubernetes distribution.\r\n\r\n**Vulnerability details**\r\n\r\nThere are two different vulnerabilities impacting the same features.\r\n\r\nWhen PersistentVolumeClaim and PersistentVolume objects are bound, they have bidirectional references to each other. When dereferencing a PersistentVolumeClaim to get a PersistentVolume, the impacted sidecar controllers were not validating that the PersistentVolume referenced back to the same PersistentVolumeClaim, potentially operating on unauthorized PersistentVolumes for snapshot, cloning and resizing operations.\r\n\r\nA similar issue exists for VolumeSnapshot and VolumeSnapshotContent objects when creating a new PersistentVolumeClaim from a snapshot.\r\n\r\nThe second issue is related to the property that CSI volume and snapshot ids are only required to be unique within a single CSI driver. Impacted sidecar controllers were not validating that the requested source VolumeSnapshot or PersistentVolumeClaim specified were from the same driver processing the request, potentially operating on unauthorized volumes during snapshot, restore from snapshot, or cloning operations.\r\n\r\n",
          "date_published": "2019-11-13T20:57:31Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11255",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11253",
        "url": "https://github.com/kubernetes/kubernetes/issues/83253",
        "published_at": null,
        "updated_at": null,
        "headline": "Kubernetes API Server JSON/YAML parsing vulnerable to resource exhaustion attack",
        "content": {
          "excerpt_text": "Kubernetes API Server JSON/YAML parsing vulnerable to resource exhaustion attack",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/83253"
          ],
          "content_hash": "sha256:2823ebbb5cdd448b50066d088206775b594683174ff8f0b63b0e13f54fc68144"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Kubernetes API Server JSON/YAML parsing vulnerable to resource exhaustion attack",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11253",
            "issue_number": 83253
          },
          "content_text": "CVE-2019-11253 is a denial of service vulnerability in the kube-apiserver, allowing authorized users sending malicious YAML or JSON payloads to cause kube-apiserver to consume excessive CPU or memory, potentially crashing and becoming unavailable. This vulnerability has been given an initial severity of High, with a score of 7.5 ([CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)).\r\n\r\nPrior to v1.14.0, default RBAC policy authorized anonymous users to submit requests that could trigger this vulnerability. Clusters upgraded from a version prior to v1.14.0 keep the more permissive policy by default for backwards compatibility. See the mitigation section below for instructions on how to install the more restrictive v1.14+ policy.\r\n\r\n**Affected versions:**\r\n* Kubernetes v1.0.0-1.12.x\r\n* Kubernetes v1.13.0-1.13.11, resolved in v1.13.12 by https://github.com/kubernetes/kubernetes/pull/83436\r\n* Kubernetes v1.14.0-1.14.7, resolved in v1.14.8 by https://github.com/kubernetes/kubernetes/pull/83435\r\n* Kubernetes v1.15.0-1.15.4, resolved in v1.15.5 by https://github.com/kubernetes/kubernetes/pull/83434\r\n* Kubernetes v1.16.0-1.16.1, resolved in v1.16.2 by https://github.com/kubernetes/kubernetes/pull/83433\r\n\r\nAll four patch releases are now available.\r\n\r\nFixed in master by #83261\r\n\r\n**Mitigation:**\r\n\r\nRequests that are rejected by authorization do not trigger the vulnerability, so managing authorization rules and/or access to the Kubernetes API server mitigates which users are able to trigger this vulnerability.\r\n\r\nTo manually apply the more restrictive v1.14.x+ policy, either as a pre-upgrade mitigation, or as an additional protection for an upgraded cluster, save the [attached file](https://github.com/kubernetes/kubernetes/files/3735508/rbac.yaml.txt) as `rbac.yaml`, and run:\r\n\r\n```sh\r\nkubectl auth reconcile -f rbac.yaml --remove-extra-subjects --remove-extra-permissions \r\n```\r\n\r\n**Note: this removes the ability for unauthenticated users to use `kubectl auth can-i`**\r\n\r\nIf you are running a version prior to v1.14.0:\r\n* in addition to installing the restrictive policy, turn off autoupdate for this clusterrolebinding so your changes aren’t replaced on an API server restart:\r\n    ```sh\r\n    kubectl annotate --overwrite clusterrolebinding/system:basic-user rbac.authorization.kubernetes.io/autoupdate=false\r\n    ```\r\n* after upgrading to v1.14.0 or greater, you can remove this annotation to reenable autoupdate:\r\n    ```sh\r\n    kubectl annotate --overwrite clusterrolebinding/system:basic-user rbac.authorization.kubernetes.io/autoupdate=true\r\n    ```\r\n\r\n=============\r\n\r\n**Original description follows:**\r\n\r\n**Introduction** \r\n\r\nPosting this as an issue following report to the security list who suggested putting it here as it's already public in a Stackoverflow question [here](https://stackoverflow.com/questions/58129150/security-yaml-bomb-user-can-restart-kube-api-by-sending-configmap/58133282#58133282)\r\n\r\n**What happened**:\r\n\r\nWhen creating a ConfigMap object which has recursive references contained in it, excessive CPU usage can occur.  This appears to be an instance of a [\"Billion Laughs\" attack](https://en.wikipedia.org/wiki/Billion_laughs_attack) which is quite well known as an XML parsing issue.\r\n\r\nApplying this manifest to a cluster causes the client to hang for some time with considerable CPU usage.\r\n\r\n```\r\napiVersion: v1\r\ndata:\r\n  a: &a [\"web\",\"web\",\"web\",\"web\",\"web\",\"web\",\"web\",\"web\",\"web\"]\r\n  b: &b [*a,*a,*a,*a,*a,*a,*a,*a,*a]\r\n  c: &c [*b,*b,*b,*b,*b,*b,*b,*b,*b]\r\n  d: &d [*c,*c,*c,*c,*c,*c,*c,*c,*c]\r\n  e: &e [*d,*d,*d,*d,*d,*d,*d,*d,*d]\r\n  f: &f [*e,*e,*e,*e,*e,*e,*e,*e,*e]\r\n  g: &g [*f,*f,*f,*f,*f,*f,*f,*f,*f]\r\n  h: &h [*g,*g,*g,*g,*g,*g,*g,*g,*g]\r\n  i: &i [*h,*h,*h,*h,*h,*h,*h,*h,*h]\r\nkind: ConfigMap\r\nmetadata:\r\n  name: yaml-bomb\r\n  namespace: default\r\n```\r\n**What you expected to happen**:\r\n\r\nIdeally it would be good for a maximum size of entity to be defined, or perhaps some limit on recursive references in YAML parsed by kubectl.\r\n\r\nOne note is that the original poster on Stackoverflow indicated that the resource consumption was in `kube-apiserver` but both tests I did (1.16 client against 1.15 Kubeadm cluster and 1.16 client against 1.16 kubeadm cluster) showed the CPU usage client-side.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\nGet the manifest above and apply to a cluster as normal with `kubectl create -f <manifest>`.  Use `top` or another CPU monitor to observe the quantity of CPU time used.\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n\r\n**test 1** (linux AMD64 client, Kubeadm cluster running in kind)\r\n```\r\nClient Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.0\", GitCommit:\"e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529\", GitTreeState:\"clean\", BuildDate:\"2019-06-25T23:41:27Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n\r\n**test 2** (Linux AMD64 client, Kubeadm cluster running in VMWare Workstation)\r\n```\r\nClient Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:27:17Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n\r\n",
          "date_published": "2019-09-27T16:53:31Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11253",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11250",
        "url": "https://github.com/kubernetes/kubernetes/issues/81114",
        "published_at": null,
        "updated_at": null,
        "headline": "Bearer tokens are revealed in logs (audit finding TOB-K8S-001)",
        "content": {
          "excerpt_text": "Bearer tokens are revealed in logs (audit finding TOB-K8S-001)",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/81114"
          ],
          "content_hash": "sha256:7af130bcece15850cde9501532d0fdf311306c298ddc350e229b48c4d3b99d31"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Bearer tokens are revealed in logs (audit finding TOB-K8S-001)",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11250",
            "issue_number": 81114
          },
          "content_text": "This issue was reported in the [Kubernetes Security Audit Report](https://github.com/kubernetes/community/blob/master/wg-security-audit/findings/Kubernetes%20Final%20Report.pdf)\r\n\r\n**Description**\r\nKubernetes requires an authentication mechanism to enforce users’ privileges. One method of authentication, bearer tokens, are opaque strings used to associate a user with their having successfully authenticated previously. Any user with possession of this token may masquerade as the original user (the “bearer”) without further authentication.\r\n\r\nWithin Kubernetes, the bearer token is captured within the hyperkube kube-apiserver system logs at high verbosity levels (--v 10). A malicious user with access to the system logs on such a system could masquerade as any user who has previously logged into the system.\r\n\r\n**Exploit Scenario**\r\nAlice logs into a Kubernetes cluster and is issued a Bearer token. The system logs her token. Eve, who has access to the logs but not the production Kubernetes cluster, replays Alice’s Bearer token, and can masquerade as Alice to the cluster.\r\n\r\n**Recommendation**\r\nShort term, remove the Bearer token from the log. Do not log any authentication credentials within the system, including tokens, private keys, or passwords that may be used to authenticate to the production Kubernetes cluster, regardless of the logging level.\r\n\r\nLong term, either implement policies that enforce code review to ensure that sensitive data is not exposed in logs, or implement logging filters that check for sensitive data and remove it prior to outputting the log. In either case, ensure that sensitive data cannot be trivially stored in logs. \r\n\r\n**Anything else we need to know?**:\r\n\r\nSee #81146 for current status of all issues created from these findings.\r\n\r\nThe vendor gave this issue an ID of TOB-K8S-001 and it was finding 6 of the report.\r\n\r\nThe vendor considers this issue Medium Severity.\r\n\r\nTo view the original finding, begin on page 31 of the [Kubernetes Security Review Report](https://github.com/kubernetes/community/blob/master/wg-security-audit/findings/Kubernetes%20Final%20Report.pdf)\r\n\r\n**Environment**:\r\n\r\n- Kubernetes version: 1.13.4",
          "date_published": "2019-08-08T02:03:04Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11250",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11248",
        "url": "https://github.com/kubernetes/kubernetes/issues/81023",
        "published_at": null,
        "updated_at": null,
        "headline": "/debug/pprof exposed on kubelet's healthz port",
        "content": {
          "excerpt_text": "/debug/pprof exposed on kubelet's healthz port",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/81023"
          ],
          "content_hash": "sha256:3d08bd21a4b20e443c8d4c3138db3d942ed91b4fde8f95d8a27b0629af2b9ed4"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "/debug/pprof exposed on kubelet's healthz port",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11248",
            "issue_number": 81023
          },
          "content_text": "The debugging endpoint `/debug/pprof` is exposed over the unauthenticated Kubelet healthz port. Versions prior to 1.15.0, 1.14.4, 1.13.8, and 1.12.10 are affected. The issue is of medium severity, but not exposed by the default configuration. If you are exposed we recommend upgrading to at least one of the versions listed.\r\n\r\n**Am I vulnerable?**\r\nBy default, the Kubelet exposes unauthenticated healthz endpoints on port :10248, but only over localhost. If your nodes are using a non-localhost healthzBindAddress (--health-bind-address), and an older version, you may be vulnerable. If your nodes are using the default localhost healthzBindAddress, it is only exposed to pods or processes running in the host network namespace.\r\n\r\nRun `kubectl get nodes` to see whether nodes are running a vulnerable version.\r\n\r\nRun `kubectl get --raw /api/v1/nodes/${NODE_NAME}/proxy/configz` to check whether the \"healthzBindAddress\" is non-local.\r\n\r\n**How do I mitigate the vulnerability?**\r\n* Upgrade to a patched version (1.15.0+, 1.14.4+, 1.13.8+, or 1.12.10+)\r\n* or, update node configurations to set the \"healthzBindAddress\" to \"127.0.0.1\".\r\n\r\nhttps://github.com/kubernetes/kubernetes/pull/79184 fixed in 1.12.10\r\nhttps://github.com/kubernetes/kubernetes/pull/79183 fixed in 1.13.8\r\nhttps://github.com/kubernetes/kubernetes/pull/79182 fixed in 1.14.4\r\nhttps://github.com/kubernetes/kubernetes/pull/78313 fixed in 1.15.0\r\n\r\n**Vulnerability Details**\r\nThe `go pprof` endpoint is exposed over the Kubelet's healthz port. This debugging endpoint can potentially leak sensitive information such as internal Kubelet memory addresses and configuration, or for limited denial of service.\r\n\r\nThanks to Jordan Zebor of F5 Networks for reporting this problem.\r\n\r\n/area security\r\n/close",
          "date_published": "2019-08-06T14:34:33Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11248",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11249",
        "url": "https://github.com/kubernetes/kubernetes/issues/80984",
        "published_at": null,
        "updated_at": null,
        "headline": "Incomplete fixes for CVE-2019-1002101 and CVE-2019-11246, kubectl cp potential directory traversal",
        "content": {
          "excerpt_text": "Incomplete fixes for CVE-2019-1002101 and CVE-2019-11246, kubectl cp potential directory traversal",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/80984"
          ],
          "content_hash": "sha256:aa0bb3a97dd9c5e35c8acb5537b19130eb3197706ce809bd3c0a36f0b44611d0"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Incomplete fixes for CVE-2019-1002101 and CVE-2019-11246, kubectl cp potential directory traversal",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11249",
            "issue_number": 80984
          },
          "content_text": "[CVSS:3.0/AV:N/AC:H/PR:L/UI:R/S:U/C:N/I:H/A:N](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:L/UI:R/S:U/C:N/I:H/A:N)\r\n\r\nA third issue was discovered with the Kubernetes `kubectl cp` command that could enable a directory traversal such that a malicious container could replace or create files on a user’s workstation. The vulnerability is a client-side defect and requires user interaction to be exploited.\r\n \r\n**Vulnerable versions:**\r\nKubernetes 1.0.x-1.12.x\r\nKubernetes 1.13.0-1.13.8\r\nKubernetes 1.14.0-1.14.4\r\nKubernetes 1.15.0-1.15.1\r\n \r\n**Vulnerable configurations:**\r\nAll `kubectl` clients running a vulnerable version and using the `cp` operation.\r\n \r\n**Vulnerability impact:**\r\nA malicious user can potentially create or overwrite files outside of the destination directory of the `kubectl cp` operation.\r\n \r\n**Mitigations prior to upgrading:**\r\nAvoid using `kubectl cp` with any untrusted workloads.\r\n \r\n**Fixed versions:**\r\nFixed in v1.13.9 by #80871\r\nFixed in v1.14.5 by #80870\r\nFixed in v1.15.2 by #80869\r\nFixed in master by #80436\r\n \r\n**Fix impact:**\r\nThe `kubectl cp` function is prevented from creating or modifying files outside the destination directory.\r\n\r\n**Acknowledgements:**\r\nThis issue was discovered by Yang Yang of Amazon, who also provided a patch. Thanks also to the release managers for creating the security releases.",
          "date_published": "2019-08-05T12:44:23Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11249",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11247",
        "url": "https://github.com/kubernetes/kubernetes/issues/80983",
        "published_at": null,
        "updated_at": null,
        "headline": "API server allows access to custom resources via wrong scope",
        "content": {
          "excerpt_text": "API server allows access to custom resources via wrong scope",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/80983"
          ],
          "content_hash": "sha256:f23a5cf9bf2aba0d2dbec748b88ca9ff182e8c03a4a763fcc4f41262d2040de0"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "API server allows access to custom resources via wrong scope",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11247",
            "issue_number": 80983
          },
          "content_text": "[CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:L)\r\n \r\nThe API server mistakenly allows access to a cluster-scoped custom resource if the request is made as if the resource were namespaced. Authorizations for the resource accessed in this manner are enforced using roles and role bindings within the namespace, meaning that a user with access only to a resource in one namespace could create, view update or delete the cluster-scoped resource (according to their namespace role privileges).\r\n \r\n**Vulnerable versions:**\r\nKubernetes 1.7.x-1.12.x\r\nKubernetes 1.13.0-1.13.8\r\nKubernetes 1.14.0-1.14.4\r\nKubernetes 1.15.0-1.15.1\r\n \r\n**Vulnerable configurations:**\r\nAll clusters that have rolebindings to roles and clusterroles that include authorization rules for cluster-scoped custom resources.\r\n \r\n**Vulnerability impact:**\r\nA user with access to custom resources in a single namespace can access custom resources with cluster scope.\r\n \r\n**Mitigations prior to upgrading:**\r\nTo mitigate, remove authorization rules that grant access to cluster-scoped resources within namespaces. For example, RBAC roles and clusterroles intended to be referenced by namespaced rolebindings should not grant access to `resources:[*], apiGroups:[*]`, or grant access to cluster-scoped custom resources.\r\n \r\n \r\n**Fixed versions:**\r\nFixed in v1.13.9 by #80852\r\nFixed in v1.14.5 by #80851\r\nFixed in v1.15.2 by #80850\r\nFixed in master by #80750\r\n \r\n**Fix impact:**\r\nPermission to the correct scope will be required to access cluster-scoped custom resources.\r\n\r\n**Acknowledgements:**\r\nThis issue was discovered by Prabu Shyam of Verizon Media. Thanks to Stefan Schimanski for the fix, to David Eads for the fix review, and to the release managers for creating the security releases.\r\n",
          "date_published": "2019-08-05T12:44:08Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11247",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11245",
        "url": "https://github.com/kubernetes/kubernetes/issues/78308",
        "published_at": null,
        "updated_at": null,
        "headline": "container uid changes to root after first restart or if image is already pulled to the node",
        "content": {
          "excerpt_text": "container uid changes to root after first restart or if image is already pulled to the node",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/78308"
          ],
          "content_hash": "sha256:aa7cdf5814d380eb1a607373413746b737474f6a1b11dc90786d230b41610e22"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "container uid changes to root after first restart or if image is already pulled to the node",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11245",
            "issue_number": 78308
          },
          "content_text": "[CVSS:3.0/AV:L/AC:H/PR:N/UI:N/S:U/C:L/I:L/A:L](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:L/AC:H/PR:N/UI:N/S:U/C:L/I:L/A:L), 4.9 (medium)\r\n\r\nIn kubelet v1.13.6 and v1.14.2, containers for pods that do not specify an explicit `runAsUser` attempt to run as uid 0 (root) on container restart, or if the image was previously pulled to the node. If the pod specified `mustRunAsNonRoot: true`, the kubelet will refuse to start the container as root. If the pod did not specify `mustRunAsNonRoot: true`, the kubelet will run the container as uid 0.\r\n\r\nCVE-2019-11245 will be **fixed** in the following Kubernetes releases:\r\n\r\n* v1.13.7 in https://github.com/kubernetes/kubernetes/pull/78320\r\n* v1.14.3 in https://github.com/kubernetes/kubernetes/pull/78316\r\n\r\nFixed by #78261 in master\r\n\r\n### Affected components:\r\n\r\n* Kubelet\r\n\r\n### Affected versions:\r\n\r\n* Kubelet v1.13.6\r\n* Kubelet v1.14.2\r\n\r\n### Affected configurations:\r\n\r\nClusters with:\r\n* Kubelet versions v1.13.6 or v1.14.2\r\n* Pods that do not specify an explicit `runAsUser: <uid>` or `mustRunAsNonRoot:true`\r\n\r\n### Impact:\r\n\r\nIf a pod is run without any user controls specified in the pod spec (like `runAsUser: <uid>` or `mustRunAsNonRoot:true`), a container in that pod that would normally run as the USER specified in the container image manifest can sometimes be run as root instead (on container restart, or if the image was previously pulled to the node)\r\n\r\n* pods that specify an explicit `runAsUser` are unaffected and continue to work properly\r\n* podSecurityPolicies that force a `runAsUser` setting are unaffected and continue to work properly\r\n* pods that specify `mustRunAsNonRoot:true` will refuse to start the container as uid 0, which can affect availability\r\n* pods that do not specify `runAsUser` or `mustRunAsNonRoot:true` will run as uid 0 on restart or if the image was previously pulled to the node\r\n\r\n### Mitigations:\r\n\r\nThis section lists possible mitigations to use prior to upgrading.\r\n\r\n* Specify `runAsUser` directives in pods to control the uid a container runs as\r\n* Specify `mustRunAsNonRoot:true` directives in pods to prevent starting as root (note this means the attempt to start the container will fail on affected kubelet versions)\r\n* Downgrade kubelets to v1.14.1 or v1.13.5 as instructed by your Kubernetes distribution.\r\n\r\n**original issue description follows**\r\n\r\n**What happened**:\r\n\r\nWhen I launch a pod from a docker image that specifies a USER in the Dockerfile, the container only runs as that user on its first launch.  After that the container runs as UID=0.\r\n\r\n**What you expected to happen**:\r\nI expect the container to act consistently every launch, and probably with the USER specified in the container.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\nTesting with minikube (same test specifying v1.14.1, `kubectl logs test` always returns 11211):\r\n```\r\n$ minikube start --kubernetes-version v1.14.2\r\n😄  minikube v1.1.0 on linux (amd64)\r\n💿  Downloading Minikube ISO ...\r\n 131.28 MB / 131.28 MB [============================================] 100.00% 0s\r\n🔥  Creating virtualbox VM (CPUs=2, Memory=2048MB, Disk=20000MB) ...\r\n🐳  Configuring environment for Kubernetes v1.14.2 on Docker 18.09.6\r\n💾  Downloading kubeadm v1.14.2\r\n💾  Downloading kubelet v1.14.2\r\n🚜  Pulling images ...\r\n🚀  Launching Kubernetes ... \r\n⌛  Verifying: apiserver proxy etcd scheduler controller dns\r\n🏄  Done! kubectl is now configured to use \"minikube\"\r\n$ cat test.yaml\r\n---\r\napiVersion: v1\r\nkind: Pod\r\nmetadata:\r\n  name: test\r\nspec:\r\n  containers:\r\n  - name: test\r\n    image: memcached:latest\r\n    imagePullPolicy: IfNotPresent\r\n    command: [\"/bin/bash\"]\r\n    args:\r\n    - -c\r\n    - 'id -u; sleep 30'\r\n$ kubectl apply -f test.yaml \r\npod/test created\r\n\r\n# as soon as pod starts\r\n$ kubectl logs test\r\n11211\r\n# Wait 30 seconds for container to restart\r\n$ kubectl logs test\r\n0\r\n# Try deleting/recreating the pod\r\n$ kubectl delete pod test\r\npod \"test\" deleted\r\n$ kubectl apply -f test.yaml \r\npod/test created\r\n$ kubectl logs test\r\n0\r\n```\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`): I get the results I expect in v1.13.5 and v1.14.1. The problem exists in v1.13.6 and v1.14.2\r\n- Cloud provider or hardware configuration: minikube v1.1.0 using VirtualBox\r\n- OS (e.g: `cat /etc/os-release`):\r\n- Kernel (e.g. `uname -a`):\r\n- Install tools:\r\n- Network plugin and version (if this is a network-related bug):\r\n- Others:\r\n",
          "date_published": "2019-05-24T16:14:49Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11245",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11243",
        "url": "https://github.com/kubernetes/kubernetes/issues/76797",
        "published_at": null,
        "updated_at": null,
        "headline": "rest.AnonymousClientConfig() does not remove the serviceaccount credentials from config created by rest.InClusterConfig()",
        "content": {
          "excerpt_text": "rest.AnonymousClientConfig() does not remove the serviceaccount credentials from config created by rest.InClusterConfig()",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/76797"
          ],
          "content_hash": "sha256:64bea5bf7039ab37d14f9eabebd8908497a55cebda93e529cdd06758b8db0fd7"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "rest.AnonymousClientConfig() does not remove the serviceaccount credentials from config created by rest.InClusterConfig()",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11243",
            "issue_number": 76797
          },
          "content_text": "CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N\r\n\r\nThe `rest.AnonymousClientConfig()` method returns a copy of the provided config, with credentials removed (bearer token, username/password, and client certificate/key data).\r\n\r\nIn the following versions, `rest.AnonymousClientConfig()` did not effectively clear service account credentials loaded using `rest.InClusterConfig()`:\r\n* v1.12.0-v1.12.4\r\n* v1.13.0\r\n\r\n**What is the impact?**\r\n* `k8s.io/client-go` users that use the `rest.AnonymousClientConfig()` method directly with client config loaded with `rest.InClusterConfig()` receive back a client config which can still send the loaded service account token with requests.\r\n\r\n**How was the issue fixed?**\r\n* In 1.12.5+ and 1.13.1+, `rest.InClusterConfig()` was modified to return a client config that is safe to use with the `rest.AnonymousClientConfig()` method (https://github.com/kubernetes/kubernetes/pull/71713)\r\n* In v1.15.0, the `rest.AnonymousClientConfig()` will also exclude the `config.Transport` and `config.WrapTransport` fields, in addition to the explicit credential-carrying fields. (https://github.com/kubernetes/kubernetes/pull/75771)\r\n\r\n**How do I resolve the issue?**\r\n* Upgrade `k8s.io/client-go` to `kubernetes-1.12.5`, `kubernetes-1.13.1`, `kubernetes-1.14.0`, or higher\r\n* or manually clear the `config.WrapTransport` and `config.Transport` fields in addition to calling `rest.AnonymousClientConfig()`\r\n\r\nThanks to Oleg Bulatov of Red Hat for reporting this issue.\r\n\r\n/area security\r\n/kind bug\r\n/sig auth\r\n/sig api-machinery\r\n/assign\r\n/close",
          "date_published": "2019-04-18T21:31:53Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11243",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-11244",
        "url": "https://github.com/kubernetes/kubernetes/issues/76676",
        "published_at": null,
        "updated_at": null,
        "headline": "`kubectl --http-cache=<world-accessible dir>` creates world-writeable cached schema files",
        "content": {
          "excerpt_text": "`kubectl --http-cache= ` creates world-writeable cached schema files",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/76676"
          ],
          "content_hash": "sha256:07442186dfbc5c854b0f7e9c8fb75475501fc8f2a198f59d34c4a9fafce1b4f8"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "`kubectl --http-cache=<world-accessible dir>` creates world-writeable cached schema files",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-11244",
            "issue_number": 76676
          },
          "content_text": "In kubectl v1.8.0+, schema info is cached in the location specified by `--cache-dir` (defaulting to `$HOME/.kube/http-cache`), written with world-writeable permissions (rw-rw-rw-).\r\n\r\nIf `--cache-dir` is specified and pointed at a different location accessible to other users/groups, the written files may be modified by other users/groups and disrupt the kubectl invocation.\r\n\r\nCVSS score: CVSS:3.0/AV:L/AC:H/PR:L/UI:R/S:U/C:L/I:L/A:N (3.3, low)\r\n\r\n**What versions are affected?**\r\nkubectl v1.8.0+\r\n\r\n**What configurations are affected?**\r\nInvocations that point `--cache-dir` at world-writeable locations\r\n\r\n**Impact**\r\nMalformed responses written to the cache directory can disrupt the kubectl invocation\r\n\r\n**Workaround**\r\nUse the default `--http-cache` location in the $HOME directory or point it at a directory that is only accessible to desired users/groups.\r\n\r\n\r\n\r\n(original description follows) ====\r\nWhat happened: The files inside of \".kube/http-cache\" are world writeable (rw-rw-rw-). While the default for these files appears to be the home directory, using the \"--cache-dir\" flag could put these files into a place where world writeable files would allow any user / process to modify the cache files. Modification of the cache files could influence the kubectl utility in a negative way for other users.\r\n\r\nWhat you expected to happen: Apply stricter file permissions to the http-cache files.\r\n\r\nHow to reproduce it (as minimally and precisely as possible): Run any generic kubectl command which is successful and then list the cache directory ~/.kube/http-cache/*\r\n \r\n$ kubectl get pods --all-namespaces\r\n$ ls -la ~/.kube/http-cache/*\r\n\r\nAnything else we need to know?: I estimate this is a low severity security issue with a CVSS score of \"3.3 / CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N\" - https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N\r\n\r\nEnvironment: Linux\r\n \r\nKubernetes version (use kubectl version):Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.6\", GitCommit:\"ab91afd7062d4240e95e51ac00a18bd58fddd365\", GitTreeState:\"clean\", BuildDate:\"2019-02-26T12:49:28Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.6\", GitCommit:\"ab91afd7062d4240e95e51ac00a18bd58fddd365\", GitTreeState:\"clean\", BuildDate:\"2019-02-26T12:49:28Z\", GoVersion:\"go1.10.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n\r\nCloud provider or hardware configuration: AWS. Running kube api server in hyperkube.\r\n\r\nOS (e.g: cat /etc/os-release):\r\nNAME=\"CentOS Linux\"\r\nVERSION=\"7.1808 (Core)\"\r\nID=\"centos\"\r\nID_LIKE=\"rhel fedora\"\r\nVERSION_ID=\"7\"\r\nPRETTY_NAME=\"CentOS Linux 7.1808 (Core)\"\r\nANSI_COLOR=\"0;31\"\r\nCPE_NAME=\"cpe:/o:centos:centos:7\"\r\nHOME_URL=\"https://www.centos.org/\"\r\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\r\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\r\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\r\nREDHAT_SUPPORT_PRODUCT=\"centos\"\r\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\r\nOSTREE_VERSION=7.1808\r\n \r\nKernel (e.g. uname -a): Linux hackit.internal 3.10.0-862.11.6.el7.x86_64 #1 SMP Tue Aug 14 21:49:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n \r\nInstall tools: Manual installation.\r\n \r\nOthers: n/a\r\n",
          "date_published": "2019-04-16T20:14:25Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-11244",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2019-1002100",
        "url": "https://github.com/kubernetes/kubernetes/issues/74534",
        "published_at": null,
        "updated_at": null,
        "headline": "json-patch requests can exhaust apiserver resources",
        "content": {
          "excerpt_text": "json-patch requests can exhaust apiserver resources",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/74534"
          ],
          "content_hash": "sha256:94ab47d56e4e878589417abc33b1c6a673dcce1937e7c86ceb565b8f4174306f"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "json-patch requests can exhaust apiserver resources",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2019-1002100",
            "issue_number": 74534
          },
          "content_text": "CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H) (6.5, medium)\r\n\r\nUsers that are authorized to make patch requests to the Kubernetes API Server can send a specially crafted patch of type “json-patch” (e.g. `kubectl patch --type json` or `\"Content-Type: application/json-patch+json\"`) that consumes excessive resources while processing, causing a Denial of Service on the API Server.\r\n\r\nThanks to Carl Henrik Lunde for reporting this problem.\r\n\r\nCVE-2019-1002100 is **fixed** in the following Kubernetes releases:\r\n\r\n* [v1.11.8](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md/#v1118)\r\n* [v1.12.6](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md/#v1126)\r\n* [v1.13.4](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.13.md/#v1134)\r\n\r\n### Affected components:\r\n* Kubernetes API server\r\n\r\n### Affected versions:\r\n* Kubernetes v1.0.x-1.10.x\r\n* Kubernetes v1.11.0-1.11.7 (fixed in [v1.11.8](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md/#v1118))\r\n* Kubernetes v1.12.0-1.12.5 (fixed in [v1.12.6](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md/#v1126))\r\n* Kubernetes v1.13.0-1.13.3 (fixed in [v1.13.4](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.13.md/#v1134))\r\n\r\n### Mitigations:\r\n* Remove ‘patch’ permissions from untrusted users.\r\n\r\nNote: If you are using binaries or packages provided by a distributor (not the ones provided in the open source release artifacts), you should contact them to determine what versions resolve this CVE. Distributors may choose to provide support for older releases beyond the ones maintained by the open source project.\r\n\r\n### Post-mortem:\r\n* [Document](https://github.com/kubernetes/kubernetes/files/3005552/PM-CVE-2019-1002100.pdf)\r\n",
          "date_published": "2019-02-25T19:39:09Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2019-1002100",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2018-1002105",
        "url": "https://github.com/kubernetes/kubernetes/issues/71411",
        "published_at": null,
        "updated_at": null,
        "headline": "proxy request handling in kube-apiserver can leave vulnerable TCP connections",
        "content": {
          "excerpt_text": "proxy request handling in kube-apiserver can leave vulnerable TCP connections",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/71411"
          ],
          "content_hash": "sha256:13e75eda927c68fd6404b50df485fc7e4a8e60d791f42496cf55e4fd287d2d25"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "proxy request handling in kube-apiserver can leave vulnerable TCP connections",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2018-1002105",
            "issue_number": 71411
          },
          "content_text": "[CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H) (9.8, critical)\r\n\r\nWith a specially crafted request, users that are authorized to establish a connection through the Kubernetes API server to a backend server can then send arbitrary requests over the same connection directly to that backend, authenticated with the Kubernetes API server’s TLS credentials used to establish the backend connection.\r\n\r\nThanks to Darren Shepherd for reporting this problem.\r\n\r\nCVE-2018-1002105 is **fixed** in the following Kubernetes releases:\r\n\r\n* [v1.10.11](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md/#v11011)\r\n* [v1.11.5](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md/#v1115)\r\n* [v1.12.3](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md/#v1123)\r\n* [v1.13.0-rc.1](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.13.md/#v1130-rc1)\r\n\r\n### Affected components:\r\n\r\n* Kubernetes API server\r\n\r\n### Affected versions:\r\n\r\n* Kubernetes v1.0.x-1.9.x\r\n* Kubernetes v1.10.0-1.10.10 (fixed in [v1.10.11](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md/#v11011))\r\n* Kubernetes v1.11.0-1.11.4 (fixed in [v1.11.5](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md/#v1115))\r\n* Kubernetes v1.12.0-1.12.2 (fixed in [v1.12.3](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md/#v1123))\r\n\r\nNote: If you are using binaries or packages provided by a distributor (not the ones provided in the open source release artifacts), you should contact them to determine what versions resolve this CVE. Distributors may choose to provide support for older releases beyond the ones maintained by the open source project.\r\n\r\n### Affected configurations:\r\n\r\n* Clusters >= 1.6.x that run aggregated API servers (like the metrics server) that are directly accessible from the Kubernetes API server’s network. If there are aggregated API servers configured in a cluster, the following command will return the names of the associated APIService objects (if no names are listed, or the kube-apiserver is an older version that does not have the apiservices API, then the cluster has no aggregated API servers configured):\r\n    ```\r\n    kubectl get apiservices \\\r\n      -o 'jsonpath={range .items[?(@.spec.service.name!=\"\")]}{.metadata.name}{\"\\n\"}{end}'\r\n    ```\r\n* Clusters >= 1.0.x that grant pod exec/attach/portforward permissions to users that are not expected to have full access to kubelet APIs\r\n\r\n### Vulnerability impact:\r\n\r\n* An API call to any aggregated API server endpoint can be escalated to perform any API request against that aggregated API server, as long as that aggregated API server is directly accessible from the Kubernetes API server’s network. **[Default RBAC policy](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#discovery-roles) allows all users (authenticated and unauthenticated) to perform discovery API calls that allow this escalation against any aggregated API servers configured in the cluster.**\r\n* A pod exec/attach/portforward API call can be escalated to perform any API request against the kubelet API on the node specified in the pod spec (e.g. listing all pods on the node, running arbitrary commands inside those pods, and obtaining the command output). **Pod exec/attach/portforward permissions are included in the admin/edit RBAC roles intended for namespace-constrained users.**\r\n\r\n### Mitigations:\r\n\r\nThis section lists possible mitigations to use prior to upgrading. Note that many of the mitigations are likely to be disruptive, and upgrading to a fixed version is strongly recommended.\r\n\r\n#### Mitigations for the anonymous user -> aggregated API server escalation include:\r\n* suspend use of aggregated API servers (note that this will disrupt users of the APIs provided by the aggregated server)\r\n* disable anonymous requests by passing `--anonymous-auth=false` to the kube-apiserver (note that this may disrupt load balancer or kubelet health checks of the kube-apiserver, and breaks `kubeadm join` setup flows)\r\n* remove *all* anonymous access to *all* aggregated APIs (including discovery permissions granted by the [default discovery role bindings](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#discovery-roles))\r\n\r\n#### Mitigations for the authenticated user -> aggregated API server escalation include:\r\n* suspend use of aggregated API servers (note that this will disrupt users of the APIs provided by the aggregated server)\r\n* remove *all* access to *all* aggregated APIs (including discovery permissions granted by the [default discovery role bindings](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#discovery-roles)) from users that should not have full access to the aggregated APIs (note that this may disrupt users and controllers that make use of discovery information to map API types to URLs)\r\n\r\n#### Mitigation for the authorized pod exec/attach/portforward -> kubelet API escalation:\r\n* Remove pod exec/attach/portforward permissions from users that should not have full access to the kubelet API\r\n\r\n### Detection:\r\n\r\nThere is no simple way to detect whether this vulnerability has been used. Because the unauthorized requests are made over an established connection, they do not appear in the Kubernetes API server audit logs or server log. The requests do appear in the kubelet or aggregated API server logs, but are indistinguishable from correctly authorized and proxied requests via the Kubernetes API server.\r\n\r\n### Post-mortem:\r\n\r\n* [Document](https://github.com/kubernetes/kubernetes/files/2700818/PM-CVE-2018-1002105.pdf)\r\n* [Recorded meeting](https://youtu.be/1M4oXPgxYyE)",
          "date_published": "2018-11-26T11:07:36Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2018-1002105",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2018-1002101",
        "url": "https://github.com/kubernetes/kubernetes/issues/65750",
        "published_at": null,
        "updated_at": null,
        "headline": "smb mount security issue",
        "content": {
          "excerpt_text": "smb mount security issue",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/65750"
          ],
          "content_hash": "sha256:aaeb5b1f880a5aa6304a1b2b20cb9a84125a9e7ce6f29a2b6a3b4fdaa6c0aa07"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "smb mount security issue",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2018-1002101",
            "issue_number": 65750
          },
          "content_text": "This issue is tracked under CVE-2018-1002101\r\n\r\n<!-- This form is for bug reports and feature requests ONLY!\r\n\r\nIf you're looking for help check [Stack Overflow](https://stackoverflow.com/questions/tagged/kubernetes) and the [troubleshooting guide](https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/).\r\n\r\nIf the matter is security related, please disclose it privately via https://kubernetes.io/security/.\r\n-->\r\n\r\n**Is this a BUG REPORT or FEATURE REQUEST?**:\r\n/kind bug\r\n\r\n> Uncomment only one, leave it on its own line:\r\n>\r\n> /kind bug\r\n> /kind feature\r\n\r\n\r\n**What happened**:\r\nuser PowerShell Environment Variables to store user input string to prevent command line injection, the env var in PowerShell would be taken as literal values and not as executable vulnerable code, this kind of fix is common for command line injection issue (called: parameterized way)\r\n\r\n**What you expected to happen**:\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\n\r\n\r\n**Anything else we need to know?**:\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n- Cloud provider or hardware configuration:\r\n- OS (e.g. from /etc/os-release):\r\n- Kernel (e.g. `uname -a`):\r\n- Install tools:\r\n- Others:\r\n\r\n/sig windows\r\n/sig storage\r\n/assign",
          "date_published": "2018-07-03T08:06:15Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2018-1002101",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2018-1002100",
        "url": "https://github.com/kubernetes/kubernetes/issues/61297",
        "published_at": null,
        "updated_at": null,
        "headline": "Kubectl copy doesn't check for paths outside of it's destination directory.",
        "content": {
          "excerpt_text": "Kubectl copy doesn't check for paths outside of it's destination directory.",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/61297"
          ],
          "content_hash": "sha256:e6cc46cfae22e4d4aa6c7fc7394d353ec18dfdcccd546432cc6c28c2523e451c"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Kubectl copy doesn't check for paths outside of it's destination directory.",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2018-1002100",
            "issue_number": 61297
          },
          "content_text": "**Is this a BUG REPORT or FEATURE REQUEST?**: Bug\r\n\r\n/kind bug\r\n\r\n**What happened**:\r\nkubectl cp <pod-name>:/some/remote/dir /some/local/dir\r\n\r\nIf the container returns a malformed tarfile with paths like:\r\n\r\n'/some/remote/dir/../../../../tmp/foo' kubectl writes this to `/tmp/foo` instead of `/some/local/dir/tmp/foo`\r\n\r\n**What you expected to happen**:\r\n\r\nI expect kubectl to clean up the path and write to `/some/local/dir/tmp/foo`\r\n\r\n**Notes**\r\nOriginal credit to @hansmi (Michael Hanselmann) for originally reporting the bug.\r\n\r\nTracked as  CVE-2018-1002100\r\n",
          "date_published": "2018-03-16T19:24:46Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2018-1002100",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2017-1002102",
        "url": "https://github.com/kubernetes/kubernetes/issues/60814",
        "published_at": null,
        "updated_at": null,
        "headline": "atomic writer volume handling allows arbitrary file deletion in host filesystem",
        "content": {
          "excerpt_text": "atomic writer volume handling allows arbitrary file deletion in host filesystem",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/60814"
          ],
          "content_hash": "sha256:c9398c1be033791cb20d345d30d415ac01d934fad1339e058c1f27593044f10c"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "atomic writer volume handling allows arbitrary file deletion in host filesystem",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2017-1002102",
            "issue_number": 60814
          },
          "content_text": "[CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:H)\r\n\r\nThis vulnerability allows containers using a secret, configMap, projected or downwardAPI volume to trigger deletion of arbitrary files and directories on the nodes where they are running.\r\n\r\nThanks to Joel Smith of Red Hat for reporting this problem.\r\n\r\n**Vulnerable versions:**\r\n* Kubernetes 1.3.x-1.6.x\r\n* Kubernetes 1.7.0-1.7.13\r\n* Kubernetes 1.8.0-1.8.8\r\n* Kubernetes 1.9.0-1.9.3\r\n\r\n**Vulnerable configurations:**\r\n* Clusters that run untrusted containers with secret, configMap, downwardAPI or projected volumes mounted (including auto-added service account token mounts).\r\n\r\n**Vulnerability impact:**\r\nA malicious container running in a pod with a secret, configMap, downwardAPI or projected volume mounted (including auto-added service account token mounts) can cause the Kubelet to remove any file or directory on the host filesystem.\r\n\r\n**Mitigations prior to upgrading:**\r\nDo not allow containers to be run with secret, configMap, downwardAPI and projected volumes (note that this prevents use of service account tokens in pods, and requires use of  [`automountServiceAccountToken: false`](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server))\r\n\r\n**Fixed versions:**\r\n* Fixed in v1.7.14 by #60516\r\n* Fixed in v1.8.9 by #60515\r\n* Fixed in v1.9.4 by #60258\r\n* Fixed in master by #58720 (included in v1.10.0-beta.1 and up, will be in v1.10.0)\r\n\r\n**Fix impact:**\r\nSecret, configMap, downwardAPI and projected volumes will be mounted as read-only volumes. Applications that attempt to write to these volumes will receive read-only filesystem errors. Previously, applications were allowed to make changes to these volumes, but those changes were reverted at an arbitrary interval by the system. Applications should be re-configured to write derived files to another location.\r\n",
          "date_published": "2018-03-05T20:55:20Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2017-1002102",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2017-1002101",
        "url": "https://github.com/kubernetes/kubernetes/issues/60813",
        "published_at": null,
        "updated_at": null,
        "headline": "subpath volume mount handling allows arbitrary file access in host filesystem",
        "content": {
          "excerpt_text": "subpath volume mount handling allows arbitrary file access in host filesystem",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/60813"
          ],
          "content_hash": "sha256:f21353d954f48bd3760eee4ea47d3f6d902690c93139933fa69cc9ed634ba9b3"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "subpath volume mount handling allows arbitrary file access in host filesystem",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2017-1002101",
            "issue_number": 60813
          },
          "content_text": "[CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)\r\n\r\nThis vulnerability allows containers using [subpath volume mounts](https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath) with any volume type (including non-privileged pods, subject to file permissions) to access files/directories outside of the volume, including the host’s filesystem.\r\n\r\nThanks to Maxim Ivanov for reporting this problem.\r\n\r\n**Vulnerable versions:**\r\n* Kubernetes 1.3.x-1.6.x\r\n* Kubernetes 1.7.0-1.7.13\r\n* Kubernetes 1.8.0-1.8.8\r\n* Kubernetes 1.9.0-1.9.3\r\n\r\n**Vulnerable configurations:**\r\n* Clusters that allow untrusted users to control pod spec content, and prevent host filesystem access via hostPath volumes (or other volume types) using PodSecurityPolicy (or custom admission plugins)\r\n* Clusters that make use of [subpath volume mounts](https://kubernetes.io/docs/concepts/storage/volumes/#using-subpath) with untrusted containers or containers that can be compromised\r\n\r\n**Vulnerability impact:**\r\nA specially crafted pod spec combined with malicious container behavior can allow read/write access to arbitrary files outside volumes specified in the pod, including the host’s filesystem. This can be accomplished with any volume type, including emptyDir, and can be accomplished with a non-privileged pod (subject to file permissions).\r\n\r\n**Mitigations prior to upgrading:**\r\nPrevent untrusted users from creating pods (and pod-creating objects like deployments, replicasets, etc), or [disable all volume types](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems) with PodSecurityPolicy (note that this prevents use of service account tokens in pods, and requires use of  [`automountServiceAccountToken: false`](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server))\r\n\r\n**Fixed versions:**\r\n* Fixed in v1.7.14 by #61047\r\n* Fixed in v1.8.9 by #61046\r\n* Fixed in v1.9.4 by #61045\r\n* Fixed in master by #61044 (included in v1.10.0-beta.3, will be in v1.10.0)\r\n\r\n**Action Required:**\r\nIn addition to upgrading, PodSecurityPolicy objects designed to limit container permissions must completely [disable hostPath volumes](https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems), as the allowedHostPaths feature does not restrict symlink creation and traversal. Future enhancements (tracked in issue #61043) are required to limit hostPath use to read only volumes or exact path matches before a PodSecurityPolicy can effectively restrict hostPath usage to a given subpath.\r\n\r\n**Known issues:**\r\n* Status and availability of fixes for regressions in subPath volume mount handling are tracked in https://github.com/kubernetes/kubernetes/issues/61563",
          "date_published": "2018-03-05T20:53:58Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2017-1002101",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2017-1002100",
        "url": "https://github.com/kubernetes/kubernetes/issues/47611",
        "published_at": null,
        "updated_at": null,
        "headline": "Azure PV should be Private scope not Container scope",
        "content": {
          "excerpt_text": "Azure PV should be Private scope not Container scope",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/47611"
          ],
          "content_hash": "sha256:667a899292b4c881cd12cc4f811836e1ecbbb2696c24c6f1e550106ab7edef4a"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "Azure PV should be Private scope not Container scope",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2017-1002100",
            "issue_number": 47611
          },
          "content_text": "",
          "date_published": "2017-06-15T18:59:13Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2017-1002100",
          "status": "fixed"
        }
      },
      {
        "source": "kubernetes_cve",
        "id": "CVE-2017-1000056",
        "url": "https://github.com/kubernetes/kubernetes/issues/43459",
        "published_at": null,
        "updated_at": null,
        "headline": "PodSecurityPolicy admission plugin authorizes incorrectly",
        "content": {
          "excerpt_text": "PodSecurityPolicy admission plugin authorizes incorrectly",
          "lang": "en"
        },
        "provenance": {
          "fetched_at": "2026-02-06T18:49:31Z",
          "evidence_urls": [
            "https://github.com/kubernetes/kubernetes/issues/43459"
          ],
          "content_hash": "sha256:a12d914bab6d7692a313c6c268a6a78e8a665a28b5650337f360142f198cecc9"
        },
        "risk": {
          "score": 0.2,
          "reasons": [
            "missing_content"
          ]
        },
        "source_payload": {
          "html": "PodSecurityPolicy admission plugin authorizes incorrectly",
          "_kubernetes_io": {
            "google_group_url": "https://groups.google.com/g/kubernetes-announce/search?q=CVE-2017-1000056",
            "issue_number": 43459
          },
          "content_text": "A PodSecurityPolicy admission plugin vulnerability allows users to make use of any PodSecurityPolicy object, even ones they are not authorized to use.\r\n\r\nCVE: CVE-2017-1000056\r\n\r\n* Fixed in [v1.5.5](https://github.com/kubernetes/kubernetes/releases/tag/v1.5.5) in https://github.com/kubernetes/kubernetes/commit/7fef0a4f6a44ea36f166c39fdade5324eff2dd5e\r\n* Fixed in release-1.5 branch in https://github.com/kubernetes/kubernetes/pull/43491\r\n* Fixed in master in https://github.com/kubernetes/kubernetes/pull/43489\r\n\r\n**Who is affected?**\r\nOnly Kubernetes 1.5.0-1.5.4 installations that do _all_ of the following:\r\n* Enable the PodSecurityPolicy API (which is not enabled by default):\r\n      `--runtime-config=extensions/v1beta1/podsecuritypolicy=true`\r\n* Enable the PodSecurityPolicy admission plugin (which is not enabled by default):\r\n      `--admission-control=...,PodSecurityPolicy,...`\r\n* Use authorization to limit users' ability to use specific PodSecurityPolicy objects\r\n\r\nkubeadm and GKE do not allow enabling PodSecurityPolicy in 1.5, so are not affected by this vulnerability.\r\n\r\nkube-up.sh and kops do not enable PodSecurityPolicy by default, so are not affected by this vulnerability. A modified kube-up.sh or kops deployment could have enabled it.\r\n\r\n**What is the impact?**\r\nA user that is authorized to create pods can make use of any existing PodSecurityPolicy, even ones they are not authorized to use.\r\n\r\n**How can I mitigate this prior to installing 1.5.5?**\r\n1. Export existing PodSecurityPolicy objects:\r\n      `kubectl get podsecuritypolicies -o yaml > psp.yaml`\r\n\r\n2. Review and delete any PodSecurityPolicy objects you do not want all pod-creating users to be able to use (NOTE: Privileged users that were making use of those policies will also lose access to those policies). For example:\r\n      `kubectl delete podsecuritypolicies/my-privileged-policy`\r\n\r\n3. After upgrading to 1.5.5, re-create the exported PodSecurityPolicy objects:\r\n      `kubectl create -f psp.yaml`",
          "date_published": "2017-03-21T15:22:29Z",
          "external_url": "https://www.cve.org/cverecord?id=CVE-2017-1000056",
          "status": "fixed"
        }
      }
    ],
    "updated": [],
    "removed": [],
    "flagged": []
  },
  "counts": {
    "new": 87,
    "updated": 0,
    "removed": 0,
    "flagged": 0
  },
  "integrity_reset": false,
  "integrity_risk": 0.0
}
